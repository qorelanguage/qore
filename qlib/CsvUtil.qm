# -*- mode: qore; indent-tabs-mode: nil -*-
# @file CsvUtil.qm Qore user module for working with CSV files

/*  CsvUtil.qm Copyright 2012 - 2016 Qore Technologies, sro

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.
*/

# minimum required Qore version
%requires qore >= 0.8.13

# assume local var scope, do not use "$" for vars, members, and method calls
%new-style
%strict-args
%require-types
%enable-all-warnings

module CsvUtil {
    version = "1.6";
    desc = "user module for working with CSV files";
    author = "Petr Vanek <petr@yarpen.cz>, David Nichols <david@qore.org>";
    url = "http://qore.org";
    license = "MIT";
}

/* see release notes below for version history
*/

/** @mainpage CsvUtil Module

    @tableofcontents

    @section csvutilintro Introduction to the CsvUtil Module

    The %CsvUtil module provides functionality for parsing CSV-like files.

    To use this module, use \c "%requires CsvUtil" in your code.

    All the public symbols in the module are defined in the CsvUtil namespace

    Currently the module provides the following classes:
    - @ref CsvUtil::AbstractCsvIterator "AbstractCsvIterator": base abstract iterator class for iterating line-based CSV data
    - @ref CsvUtil::AbstractCsvWriter "AbstractCsvWriter": a base class for new CSV writer implementations
    - @ref CsvUtil::CsvIterator "CsvIterator": iterator class allowing for generic CSV input data to be processed line by line on a record basis
    - @ref CsvUtil::CsvWriter "CsvWriter": generic stream-based CSV writer

    Furthermore, the following specialized classes are implemented based on the above and are provided for convenience and backwards-compatibility:
    - @ref CsvUtil::CsvDataIterator "CsvDataIterator": iterator class allowing for CSV string data to be processed line by line on a record basis
    - @ref CsvUtil::CsvFileIterator "CsvFileIterator": iterator class allowing for CSV files to be processed line by line on a record basis
    - @ref CsvUtil::CsvFileWriter "CsvFileWriter": CSV file writer
    - @ref CsvUtil::CsvStringWriter "CsvStringWriter": CSV in-memory writer

    Note that the @ref CsvUtil::CsvIterator "CsvIterator" class can be used to parse arbitrary text data; the field separator character can be specified in the @ref CsvUtil::CsvIterator::constructor() "constructor", as well as the quote character and end of line sequence.  See the @ref CsvUtil::CsvIterator::constructor() "constructor documentation" for more information.

    <b>Examples:</b>
    @code{.py}
#!/usr/bin/env qore

%new-style
%strict-args
%require-types
%enable-all-warnings

%requires CsvUtil

FileInputStream input("example-file.csv");
CsvIterator i(input);
FileOutputStream output("example-file-copy.csv");
CsvWriter writer(output, ("headers": ("cc", "serno", "desc", "received")));

while (i.next()) {
    printf("%d: %y\n", i.index(), i.getValue());
    writer.writeLine(i.getValue());
}
    @endcode

    If \c "example-file.csv" is:
    @verbatim
UK,1234567890,"Sony, Xperia S",31052012
UK,1234567891,"Sony, Xperia S",31052012
UK,1234567892,"Sony, Xperia S",31052012
UK,1234567893,"Sony, Xperia S",31052012
    @endverbatim

    The data is read verbatim, each value is returned as a string, header names are generated numerically; the output is:
    @verbatim
1: {0: "UK", 1: "1234567890", 2: "Sony, Xperia S", 3: "31052012"}
2: {0: "UK", 1: "1234567891", 2: "Sony, Xperia S", 3: "31052012"}
3: {0: "UK", 1: "1234567892", 2: "Sony, Xperia S", 3: "31052012"}
4: {0: "UK", 1: "1234567893", 2: "Sony, Xperia S", 3: "31052012"}
    @endverbatim

    Also the \c "example-file-copy.csv" will contain data from the original file formatted as CSV.

    @anchor complex_example
    If header names are provided and field types are specified, the output looks different:
    @code{.py}
#!/usr/bin/env qore

%new-style
%strict-args
%require-types
%enable-all-warnings

%requires CsvUtil

FileInputStream input("example-file.csv");
CsvIterator i(input, NOTHING, ("headers": ("cc", "serno", "desc", "received"), "fields": ("serno": "int", "received": ("type": "date", "format": "DDMMYYYY"))));
while (i.next())
    printf("%d: %y\n", i.index(), i.getValue());
    @endcode

    Now the hash keys in each record returned are those given in the @ref CsvUtil::CsvFileIterator::constructor() "constructor", and the fields \c "serno" and \c "received" are given other data types; this produces:
    @verbatim
1: {cc: "UK", serno: 1234567890, desc: "Sony, Xperia S", received: 2012-05-31 00:00:00 Thu +02:00 (CEST)}
2: {cc: "UK", serno: 1234567891, desc: "Sony, Xperia S", received: 2012-05-31 00:00:00 Thu +02:00 (CEST)}
3: {cc: "UK", serno: 1234567892, desc: "Sony, Xperia S", received: 2012-05-31 00:00:00 Thu +02:00 (CEST)}
4: {cc: "UK", serno: 1234567893, desc: "Sony, Xperia S", received: 2012-05-31 00:00:00 Thu +02:00 (CEST)}
    @endverbatim

    Use the \c "header_lines" and \c "header_names" @ref abstractcsviterator_options "options" to automatically read the header names from the file if present.  Use the \c "fields" @ref abstractcsviterator_options "option" to describe the fields and perform transformations on the data read.  For more information, see the @ref CsvUtil::CsvFileIterator "CsvFileIterator" class.

    @section csvutil_multitype Multi-type support

    The %CsvUtil module supports multi-type records, meaning that different input lines may have different structures, and input record type
    resolution is performed at run-time using predefined rules.
    %CsvUtil classes have two contructors, a backwards-compatible constructor variant, which accepts field definition in options and supports only a single record type, and a new constructor avariant, which ccepts field specifications and options passed as separate parameters.

    When used with multi-type definitions, the @ref CsvUtil::AbstractCsvIterator::getValue() method returns
    records in an extended form.  In this case, the return value of @ref CsvUtil::AbstractCsvIterator::getValue()
    is a hash with the following keys:
    - \c "type": the resolve record type name
    - \c "record": a hash of record values

    As this is not backwards compatible, this mode is enabled using the \c "extended_record" option.

    If no record type resolution rules or logic is defined, then record types are resolved automatically based on their
    unique number of fields.  If the number of fields is not unique (i.e. two or more records have the same number of
    fields), then a rule must exist to resolve the record type.

    Typically the value of a particular field determines the record type, however even multiple fields could be used.  Record type detection configuration is supplied by the \c "value" (field value equality test) or \c "regex" (regular expression test) keys in the
    @ref abstractcsviterator_option_field_hash "field specification hash" for the record in question.  If multiple fields in a record
    definintion have \c "value" or \c "regex" keys, then all fields must match the input data in order for the input
    line to match the record.

    The above record type resolution logic is executed in
    @ref CsvUtil::AbstractCsvIterator::identifyTypeImpl() "AbstractCsvIterator::identifyTypeImpl()",
    which executes any \c "regex" or \c "value" tests on the input line in the order of the field definitions in the
    @ref abstractcsviterator_option_field_hash "record description hash".

    Record type resolution is performed as follow:
    - \c "value": Matches the full value of the field; if an integer \c "value" value is used, then integer comparisons are done, otherwise string comparisons are performed.
    - \c "regex": Matches the full value of the field with regular expression.

    When there are no record-matching keys in the field hashes for any record and the input record field number are
    not unique, then
    @ref CsvUtil::AbstractCsvIterator::identifyTypeImpl() "AbstractCsvIterator::identifyTypeImpl()"
    must be overridden in a subclass to provide custom record matching logic.

    @note
    - It is an error to have both \c "regex" and \c "value" keys in a @ref abstractcsviterator_option_field_hash "field specification hash"
    - If multiple fields have configuration for input line matching (i.e. \c "regex" and \c "value" keys), then all
      fields with this configuration must match for the record to be matched
    - since version 1.5.

    @code{.py}
#!/usr/bin/env qore

%new-style
%strict-args
%require-types
%enable-all-warnings

%requires CsvUtil

const spec = (
    "header": (
        "type": ("type": "int", "value": 1),
        "invoice_no": "string",
        "date": ("type": "date", "format": "YYYYMMDD"),
    ),
    "item": (
        "type": ("type": "int", "value": 2),
        "item_no": "string",
        "item": "string",
        "pcs": "int",
        "price": "number",
    ),
    "footer": (
        "type": ("type": "int", "value": 3),
        "total": "number",
    ),
);

const opts = {};

FileInputStream input("example-multi-file.csv");
CsvIterator i(input, NOTHING, spec, ("extended_record": True) + opts);

FileOutputStream output("example-multi-file-copy.csv");
CsvWriter writer(output, spec, ("write-headers": False, "optimal-quotes" : True, "quote_escape" : "\"") + opts);
while (i.next()) {
    printf("%d: %y\n", i.index(), i.getValue());
    writer.writeLine(i.getValue());
}
    @endcode


    If \c "example-multi-file.csv" is:
    @verbatim
1,2016-01,20160401
2,123,"Sony, Xperia S",1,100
2,124,"Nokia, Lumia",2,150
3,250
    @endverbatim

    The data is read verbatim, each value is returned as a string, header names are generated numerically; the output is:
    @verbatim
1: {type: "header", record: {type: 1, invoice_no: "2016-01", date: 2016-04-01 00:00:00.000000 Fri +02:00 (CEST)}}
2: {type: "item", record: {type: 2, item_no: "123", item: "Sony, Xperia S", pcs: 1, price: 100}}
3: {type: "item", record: {type: 2, item_no: "124", item: "Nokia, Lumia", pcs: 2, price: 150}}
4: {type: "footer", record: {type: 3, total: 250}}
    @endverbatim

    Also the \c "example-multi-file-copy.csv" will contain data from the original file formatted as CSV.

    @section csvutil_relnotes Release Notes

    @subsection csvutil_v1_6 Version 1.6
    - added support for streams; the following stream-based classes have been added:
      - @ref CsvUtil::CsvIterator "CsvIterator": provides a more generic interface than @ref CsvUtil::CsvDataIterator "CsvDataIterator" and @ref CsvUtil::CsvFileIterator "CsvFileIterator"
      - @ref CsvUtil::CsvWriter "CsvWriter": provides a more generic interface than @ref CsvUtil::CsvStringWriter "CsvStringWriter" and @ref CsvUtil::CsvFileWriter "CsvFileWriter"
    - fixed a bug in an error message validating input data (<a href="https://github.com/qorelanguage/qore/issues/1062">issue 1062</a>)

    @subsection csvutil_v1_5_1 Version 1.5.1
    - fixed a bug in @ref CsvUtil::AbstractCsvIterator::identifyTypeImpl() "AbstractCsvIterator::identifyTypeImpl()" generating an error message (<a href="https://github.com/qorelanguage/qore/issues/1355">issue 1355</a>)

    @subsection csvutil_v1_5 Version 1.5
    - fixed a bug handling the global option \c "eol"
    - converted to new-style
    - if "headers" are not given in the @ref CsvUtil::AbstractCsvWriter::constructor() but "fields" are, then set the headers from the field descriptions automatically
    - added write() methods returning the generated strings to the @ref CsvUtil::CsvStringWriter class for API compatibility with the corresponding FixedLengthDataWriter methods
    - implemented support for @ref Qore::SQL::SQLStatement "SQLStatement" as an iterator source for @ref CsvUtil::AbstractCsvWriter::write()
    - implemented the \c "datamap" and \c "info_log" options for CSV generation
    - implemented options with underscores to replace options with dashes:
      - @ref CsvUtil::AbstractCsvWriter
        - \c "date-format" is now \c "date_format"
        - \c "optimal-quotes" is now \c "optimal_quotes"
        - \c "verify-columns" is now \c "verify_columns"
        - \c "write-headers" is now \c "write_headers"
      - @ref CsvUtil::AbstractCsvIterator
        - \c "ignore-empty" is now \c "ignore_empty"
        - \c "ignore-whitespace" is now \c "ignore_whitespace"
        - \c "header-names" is now \c "header_names"
        - \c "header-lines" is now \c "header_lines"
        - \c "verify-columns" is now \c "verify_columns"
    - implemented multi-type line support
    - two constructors for backward CsvUtil compatability and similarity with FixedLengthUtil API
    - implemented new options \c "header_reorder"; @ref CsvUtil::AbstractCsvIterator \c "date_format",\c "extended_record"
    - implemented options for field specification: \c "index", \c "default", \c "header", \c "value", \c "regex"
    - fixed a UTC bug for default date 1970-01-01Z

    @subsection csvutil_v1_4 Version 1.4
    - fixed the \c "format" field option when used with \c "*date" field types
    - implemented the \c "tolwr" parser option
    - changed the default field type when parsing and generating CSV files from \c "string" to \c "*string"

    @subsection csvutil_v1_3 Version 1.3
    - added the \c "write-headers" option to @ref CsvUtil::AbstractCsvWriter and subclasses to enable headers to be suppressed
    - added the \c "optimal-quotes" option to @ref CsvUtil::AbstractCsvWriter and subclasses to enable more efficient csv output (now the default output option); to revert back to the previous behavior (where all fields are quoted regardless of data type or content), set to @ref Qore::False "False" in the constructor

    @subsection csvutil_v1_2 Version 1.2
    - fixed @ref CsvUtil::CsvDataIterator::next() when header_lines > 0 and working with empty input data
    - implemented support for the \c "*int", \c "*float", \c "*number", and \c "*date" types
    - implemented support for allowing subclasses of @ref CsvUtil::CsvFileIterator to implement support for other custom types
    - fixed \c "date" type handling with empty input; now returns 1970-01-01Z (use "*date" to map empty input to NOTHING)
    - added the @ref CsvUtil::CsvStringWriter, @ref CsvUtil::AbstractCsvWriter, and @ref CsvUtil::CsvFileWriter classes
    - if "headers" are not given in the @ref CsvUtil::CsvFileIterator::constructor() but "fields" are, then set the headers from the field descriptions automatically

    @subsection csvutil_v1_1 Version 1.1
    - bug fixes to header and fields option processing
    - fixed @ref CsvUtil::CsvFileIterator::index() to return the line index
    - added @ref CsvUtil::CsvFileIterator::lineNumber() to return the current line number in the file

    @subsection csvutil_v1_0 Version 1.0
    - initial version of module
*/

class CsvHelper {
    private {
        const C_OPT1 = 0x1;
        const C_OPT2 = 0x2;
        #! supported type codes (hash for quick lookups)
        const Types = (
            "int": True,
            "*int": True,
            "float": True,
            "*float": True,
            "number": True,
            "*number": True,
            "string": True,
            "*string": True,
            "date": True,
            "*date": True,
        );

        #! supported field description attribute codes
        const FieldAttrs = ("type", "format", "timezone", "code", "header");

        #! flag to convert all header names to lower case
        bool tolwr = False;

        #! default date->string format
        string date_format;

        #! hash of field information (types, formats, and possible code), hash key = column name or number (starting with 0)
        hash m_specs;

        #! the exeption \c "err" string
        string errname;

        # reorder data according headers set by options.headers or read from CsvHeader
        bool headerReorder = True;

    }

    #! @param n_errname class name used in exception to identify class
    constructor (string n_errname) {
        errname = n_errname;
    }

    #! returns True if specification hash defines more types
    private bool isMultiType() {
        return m_specs && m_specs.size() > 1;
    }

    #! validate field type
    private checkType(string fld_errs, string key, string value) {
        if (!Types{value})
            throw "CSV-TYPE-ERROR", sprintf("%s: unknown field type %y for field %y (supported types: %y)", fld_errs, value, key, Types.keys());
    }

    # get spec from options.fields for old Csv. Check spec param for new Csv
    private hash getSpec(*hash fields, string fld_errs, int C_OPTx) {
        hash spec = hash();
        if (fields) {
            if (fields.typeCode() != NT_HASH)
                throw errname, sprintf("%s: expecting a hash value; got %y (type %s) instead", fld_errs, fields, fields.type());

            hash checkIdx = hash();
            # iterate hash to process field descriptions
            foreach hash hi in (fields.pairIterator()) {
                hash h;
                h.idx = $#;
                h.header = hi.key;
                switch (hi.value.typeCode()) {
                    case NT_STRING: {
                        checkType(fld_errs, hi.key, hi.value);
                        h.type = hi.value;
                        break;
                    }
                    case NT_HASH: {
                        if (hi.value.empty())
                            throw errname, sprintf("%s: empty hash passed as description for field %y", fld_errs, hi.key);
                        foreach hash fh in (hi.value.pairIterator()) {
                            bool found = True;
                            switch (fh.key) {
                                case "type": {
                                    checkType(fld_errs, hi.key, fh.value);
                                    h.type = fh.value;
                                    break;
                                }
                                case "header":
                                case "format": {
                                    if (fh.value.typeCode() != NT_STRING)
                                        throw errname, sprintf("%s: field %y \"%s\" attributes expects a string value; got %y instead", fld_errs, hi.key, fh.key, fh.value.type());
                                    h{fh.key} = fh.value;
                                    break;
                                }
                                case "timezone": {
                                    h.timezone = new TimeZone(fh.value);
                                    break;
                                }
                                case "code": {
                                    if (!fh.value.callp())
                                        throw errname, sprintf("%s: field %y \"%s\" attributes expects a callable value to process the field value; got %y instead", fld_errs, hi.key, fh.key, fh.value.type());
                                    h.code = fh.value;
                                    break;
                                }
                                default: {
                                    found = False;
                                }
                            }
                            if (!found && C_OPTx == C_OPT2) {
                                found = True;
                                switch (fh.key) {
                                    case "value":
                                    case "default":
                                        h{fh.key} = fh.value;
                                        break;
                                    case "index":
                                        if (int(fh.value) != fh.value)
                                            throw errname, sprintf("%s: field %y \"%s\" does not contain an integer value; %n vs. %n", fld_errs, hi.key, fh.key, int(fh.value), fh.value);
                                        h.idx = int(fh.value);
                                        if (h.idx < 0 || h.idx >= fields.size()) {
                                            throw errname, sprintf("%s: field %y \"%s\" has value %d out off range 0..%d", fld_errs, hi.key, fh.key, h.idx, fields.size()-1);
                                        }
                                        break;
                                    case "regex":
                                        if (fh.value.typeCode() != NT_STRING) {
                                            throw errname, sprintf("%s: field %y \"%s\" attributes expects a string value; got %y instead", fld_errs, hi.key, fh.key, fh.value.type());
                                        }
                                        h{fh.key} = fh.value;
                                        break;
                                    default:
                                        found = False;
                                }
                            }
                            if (!found) {
                                throw errname, sprintf("%s: unknown field attribute value %y given for field %y (supported attribute values: %y)", fld_errs, fh.key, hi.key, FieldAttrs);

                            }
                        }
                        if (!h.type)
                            h.type = "*string";
                        if (h.type != "date" && h.type != "*date") {
                            foreach string f in ("timezone", "format") {
                                if (h{f})
                                    throw errname, sprintf("%s: field %y is type %y, but the %y attribute was also given, which is only valid for \"date\" fields", fld_errs, hi.key, h.type, f);
                            }
                        }
                        break;
                    }
                    default: {
                        throw errname, sprintf("%s: invalid value passed as the field description for field %y; expecting \"string\" or \"hash\"; got %y instead", fld_errs, hi.key, hi.value.type());
                    }
                }
                if (exists checkIdx{h.idx}) {
                    throw errname, sprintf("%s: field %y \"index\" causes index violation %d", fld_errs, hi.key, h.idx);
                }
                if (tolwr) {
                    h.header = h.header.lwr();
                }

                checkIdx{h.idx} = True;
                spec.(hi.key) = h;
            }
        }
        return spec;
    }

    private hash getSpec1(*hash fields) {
        return (CSV_TYPE_SINGLE: getSpec(fields, "while processing the hash value for option key \"fields\"", C_OPT1));
    }

    private hash getSpec2(hash spec) {
        spec = spec ?? (CSV_TYPE_SINGLE: hash());
        foreach string i in (spec.keyIterator()) {
            spec{i} = getSpec(spec{i}, sprintf("while processing the hash value for spec key \"%s\"", i), C_OPT2);
        }
        return spec;
    }

    /** Process headers and add missing field specification, consider resordering fields in specification

        Return: list of field names in order of Csv record
    */
    private list adjustFieldsFromHeaders(string type, *list headers) {

        hash spec = m_specs{type} ?? hash();
        list csv_order = ();
        if (headers && tolwr)
            headers = (map $1.lwr(), headers);

        # look for header name if specified
        hash fld_by_hdr = hash();
        hash hdr_idxs = map {$1: $#}, headers;

        m_specs{type} = hash();

        foreach string f in (spec.keyIterator()) {
            fld_by_hdr{spec{f}.header} = f;
            if (!headerReorder) {
                # keep existing spec
                if (exists hdr_idxs{spec{f}.header}) {
                    spec{f}.idx = hdr_idxs{spec{f}.header};
                    m_specs{type}{f} = spec{f};
                    push csv_order, f;
                    remove hdr_idxs{spec{f}.header};
                }
            }
        }

        # change field specificiation to follow header order
        foreach string h in (headers) {
            if (!exists hdr_idxs{h}) {
                # header already in spec
                continue;
            }
            string f = fld_by_hdr{h} ?? h;
            m_specs{type}{f} = spec{f} ?? ("type": "*string", "header": h);
            m_specs{type}{f}.idx = hdr_idxs{h};
            push csv_order, f;
            remove hdr_idxs{h};
        }
        return csv_order;
    }

} # class CsvHelper

#! the CsvUtil namespace contains all the objects in the CsvUtil module
public namespace CsvUtil {
    #! Unix end of line character sequence (for new OS X too)
    public const EOL_UNIX = "\n";
    #! MS DOS/Windows end of line character sequence
    public const EOL_WIN = "\r\n";
    #! Old (pre-OSX) Macintosh end of line character sequence
    public const EOL_MACINTOSH = "\r";

    # helper list of end of line values
    const EOLS = (EOL_UNIX, EOL_WIN, EOL_MACINTOSH, );

    #! Record type when non matching any type
    public const CSV_TYPE_UNKNOWN = "<unknown>";
    #! Record type when multi-type is disabled
    public const CSV_TYPE_SINGLE = "<single>";


    #! the AbstractCsvIterator class is an abstract base class that allows abstract CSV data to be iterated
    /**
        @section abstractcsviterator_options AbstractCsvIterator Constructor Option Hash Overview
        The AbstractCsvIterator class constructor takes an optional hash with possible keys given in the following table.  Note that
        key names are case-sensitive, and data types are soft (conversions are made when possible).

        <b>AbstractCsvIterator Options</b>
        |!Option|!Data Type|!Description
        |\c "date_format"|@ref string_type "string"|the default date format for \c "date" fields (see @ref date_formatting "date formatting" for the value in this case)
        |\c "encoding"|@ref string_type "string"|the @ref character_encoding "character encoding" for the file (and for tagging string data read); if the value of this key is not a string then it will be ignored
        |\c "separator"|@ref string_type "string"|the string separating the fields in the file (default: \c ",")
        |\c "quote"|@ref string_type "string"|the field quote character (default: \c '\"')
        |\c "eol"|@ref string_type "string"|the end of line character(s) (default: auto-detect); if the value of this key is not a string then it will be ignored
        |\c "ignore_empty"|@ref bool_type "bool"|if @ref Qore::True "True" (the default) then empty lines will be ignored; this option is processed with @ref Qore::parse_boolean() "parse_boolean()"
        |\c "ignore_whitespace"|@ref bool_type "bool"|if @ref Qore::True "True" (the default) then leading and trailing whitespace will be stripped from non-quoted fields; this option is processed with @ref Qore::parse_boolean() "parse_boolean()"
        |\c "header_names"|@ref bool_type "bool"|if @ref Qore::True "True" then the object will parse the header names from the first header row, in this case \c "header_lines" must be &gt; 0. In case of multi-type lines \c "header_names" is mandatory @ref Qore::False "False".
        |\c "header_lines"|@ref int_type "int"|the number of headers lines in the file (must be &gt; 0 if \c "header_names" is @ref Qore::True "True")
        |\c "header_reorder"|@ref bool_type "bool"|if @ref Qore::True "True" (default value) then if \"headers\" are provided by options or read from file then data fields are reordered to follow headers. It has major effect on return value of @ref AbstractCsvIterator::getRecordList() function and also minor on hash result of AbstractCsvIterator::getRecord() when a program code depends on order of keys. If @ref Qore::False "False" then fields not yet specified are pushed at the end of field definition.
        |\c "verify_columns"|@ref bool_type "bool"|if @ref Qore::True "True" (the default is @ref Qore::False "False") then if a line is parsed with a different column count than other lines, a \c CSVFILEITERATOR-DATA-ERROR exception is thrown
        |\c "timezone"|@ref string_type "string"|the timezone to use when parsing dates (will be passed to @ref Qore::TimeZone::constructor())
        |\c "tolwr"|@ref bool_type "bool"|if @ref Qore::True "True" then all header names will be converted to lower case letters

        <b>AbstractCsvIterator Single-type-only Options </b>
        |!Option|!Data Type|!Description
        |\c "headers"|@ref list_type "list" of @ref string_type "strings"|list of header / column names for the data iterated; if this is present, then \c "header_names" must be @ref Qore::False "False".
        |\c "fields"|@ref hash|the keys are column names (or numbers in case column names are not used) and the values are either strings (one of @ref abstractcsviterator_option_field_types giving the data type for the field) or a @ref abstractcsviterator_option_field_hash describing the field; also sets \a headers if not set automatically with \c "header_names"; if no field type is given, the default is \c "*string"

        <b>AbstractCsvIterator Multi-type-only Options </b>
        |!Option|!Data Type|!Description
        |\c "extended_record"|@ref boolean|if @ref Qore::True "True" then get functions will use extended hash with \"type\" and \"record\" members to provide type to calling party, Default: @ref Qore::False "False"

        @note the following options separated by dashes are still supported for backwards-compatibility:
        - \c "date-format"
        - \c "ignore-empty"
        - \c "ignore-whitespace"
        - \c "header-names"
        - \c "header-lines"
        - \c "verify-columns"

        @subsection abstractcsviterator_option_field_types Option Field Types
        Fields are defined in order how the data are expected by user program. In this order are
        data returned by get functions. There are two exception, the former \c "headers" options sorts definition
        that data correspond to \c "headers" field order and the later when header names are read from Csv file header.

        <b>AbstractCsvIterator Option Field Types</b>
        |!Name|!Description
        |\c "int"|the value will be unconditionally converted to an @ref integer "integer" using the @ref Qore::int() function
        |\c "*int"|the value will be converted to @ref nothing if empty, otherwise it will be converted to an @ref integer "integer" using the @ref Qore::int() function
        |\c "float"|the value will be unconditionally converted to a @ref float "floating-point value" using the @ref Qore::float() function
        |\c "*float"|the value will be converted to @ref nothing if empty, otherwise it will be converted to a @ref float "floating-point value" using the @ref Qore::float() function
        |\c "number"|the value will be unconditionally converted to an @ref number "arbitrary-precision number value" using the @ref Qore::number() function
        |\c "*number"|the value will be converted to @ref nothing if empty, otherwise it will be converted to an @ref number "arbitrary-precision number value" using the @ref Qore::number() function
        |\c "string"|(the default) the value remains a string; no transformation is done on the input data
        |\c "*string"|the value will be converted to @ref nothing if empty, otherwise, it remains a string
        |\c "date"|in this case dates are parsed directly with the @ref Qore::date() function (and therefore are tagged automatically with the current @ref time_zones "time zone"); to specify another date format, use the @ref abstractcsviterator_option_field_hash "hash format" documented below
        |\c "*date"|the value will be converted to @ref nothing if empty, otherwise dates are parsed directly with the @ref Qore::date() function (and therefore are tagged automatically with the current @ref time_zones "time zone"); to specify another date format, use the @ref abstractcsviterator_option_field_hash "hash format" documented below

        @subsection abstractcsviterator_option_field_hash Option Field Hash
        See @ref complex_example "here" for an example of using the hash field description in the @ref CsvUtil::CsvFileIterator::constructor() "constructor()".

        <b>AbstractCsvIterator Option Field Hash and Spec Hash</b>
        Field specification is provided via options \"fields\" for old-style constructor or as separate parameter in new-style constructor supporting multi-type.

        |!Key|!Value Description
        |\c "type"|one of the @ref abstractcsviterator_option_field_types "option type values" giving the field type
        |\c "format"|used only with the \c "date" type; this is a @ref date_mask "date/time format mask" for parsing dates
        |\c "timezone"|used only with the \c "date" type; this value is passed to @ref Qore::TimeZone::constructor() and the resulting timezone is used to parse the date (this value overrides any default time zone for the object; use only in the rare case that date/time values from different time zones are present in different columns of the same file)
        |\c "code"|this is a @ref closure "closure" or @ref call_reference "call reference" that takes a single argument of the value (after formatting with any optional \c "type" formats) and returns the value that will be output for the field

        <b>Extra AbstractCsvIterator Spec Hash Options</b>
        |!Key|!Data Type|!Value Description
        |\c value|@ref string_type "string"|the value to use to compare to input data when determining the record type; if \c "value" is defined for a field, then \c "regex" cannot be defined (for iterator only)
        |\c regex|@ref string_type "string"|the regular expression to use to apply to input data lines when determining the record type (for iterator only)
        |\c header|@ref string_type "string"|field name as defined in Csv header line. It enables remapping from Csv to own name
        |\c index|@ref int_type "int"|index of field in Csv file. It enables mapping when Csv has not header
        |\c default|@ref any_type "any"|Default output value (for writers only)

     */
    public class AbstractCsvIterator inherits Qore::AbstractIterator, private CsvHelper {
        private {
            #! valid options for the object (a hash for quick lookups of valid keys)
            const Options = (
                "date_format": C_OPT1|C_OPT2,
                "date-format": C_OPT1|C_OPT2,
                "encoding": C_OPT1|C_OPT2,
                "eol": C_OPT1|C_OPT2,
                "extended_record": C_OPT2,
                "fields": C_OPT1,
                "header-lines": C_OPT1|C_OPT2,
                "header_lines": C_OPT1|C_OPT2,
                "header-names": C_OPT1|C_OPT2,
                "header_names": C_OPT1|C_OPT2,
                "header_reorder": C_OPT1|C_OPT2,
                "headers": C_OPT1,
                "ignore-empty": C_OPT1|C_OPT2,
                "ignore_empty": C_OPT1|C_OPT2,
                "ignore-whitespace": C_OPT1|C_OPT2,
                "ignore_whitespace": C_OPT1|C_OPT2,
                "quote": C_OPT1|C_OPT2,
                "separator": C_OPT1|C_OPT2,
                "timezone": C_OPT1|C_OPT2,
                "tolwr": C_OPT1|C_OPT2,
                "verify-columns": C_OPT1|C_OPT2,
                "verify_columns": C_OPT1|C_OPT2,
                );

            # field separator
            string separator = ",";

            # field content delimiter
            string quote = "\"";

            # number of header lines
            softint headerLines = 0;

            # flag to use string names from the first header row if possible
            bool headerNames = False;

            # True if empty lines should be ignored
            bool ignoreEmptyLines = True;

            # Flag to trim the field content (trim leading and trailing whitespace) from unquoted fields
            bool ignoreWhitespace = True;

            # the @ref Qore::TimeZone to use when parsing dates (default: current time zone)
            *TimeZone timezone;

            # verify the column count for every row; if a row does not match, then throw a \c CSVFILEITERATOR-DATA-ERROR exception
            bool checkElementCounts = False;

            # getRecord/getValue returns extended hash
            bool extendedRecord = False;

            # column count for verifying column counts
            int cc;

            # current record count for the index() method
            int rc = 0;

            # to resolve record type by rules
            hash m_resolve_by_rule;

            # to resolve record type by number of fields
            hash m_resolve_by_count;

            # list of idx to field transformarions, in order of spec
            hash m_resolve_by_idx;

            # fake specs based on the first non-header row
            bool fakeHeaderNames;

            # data source iterator
            AbstractLineIterator lineIterator;
        }

        #! creates the AbstractCsvIterator with an option hash in single-type mode
        /**
            @param li source line iterator
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header-names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(AbstractLineIterator li, *hash opts): CsvHelper("ABSTRACTCSVITERATOR-ERROR") {
            lineIterator = li;
            processCommonOptions(opts, C_OPT1);

            if (headerNames && opts.headers)
                throw errname, sprintf("\"header_names\" is True but \"headers\" has a value (%y)", opts.headers);

            processSpec(getSpec1(opts.fields));

            if (opts.headers) {
                # set headers automatically from field names if not set
                prepareFieldsFromHeaders(opts.headers);
            }
        }

        #! creates the AbstractCsvIterator with an option hash in multi-type mode
        /**
            @param li source line iterator
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information
         */
        # NOTE: when declared as *hash then always calls this constructor
        constructor(AbstractLineIterator li, hash spec, hash opts): CsvHelper("ABSTRACTCSVITERATOR-ERROR") {
            lineIterator = li;
            processCommonOptions(opts, C_OPT2);
            foreach hash i in (opts.pairIterator()) {
                switch (i.key) {
                    case "extended_record": {
                        extendedRecord = parse_boolean(i.value);
                        break;
                    }
                }
            }
            if (headerNames && isMultiType())
                throw errname, sprintf("\"header_names\" is True but multi-type is specified (%y)", m_specs);
            processSpec(getSpec2(spec));
            # potential prepareFieldsFromHeaders() call does not support rule adjusting
            if (headerNames && m_resolve_by_rule)
                throw errname, sprintf("\"header_names\" is True but a resolve rule is specified (%y)", m_specs);
        }

        #! process common options and and assing internal fields
        private processCommonOptions(*hash opts, int C_OPTx) {
            foreach hash i in (opts.pairIterator()) {
                if (!exists Options.(i.key) || ((Options.(i.key) & C_OPTx) == 0))
                    throw errname, sprintf("unknown option %y passed to AbstractCsvIterator::constructor() (valid options: %y)", i.key, (select Options.keys(), (Options.$1 & C_OPTx) != 0));
                switch (i.key) {
                    case "date_format":
                    case "date-format": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        date_format = i.value;
                        break;
                    }
                    case "separator": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        separator = i.value;
                        break;
                    }
                    case "quote": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        quote = i.value;
                        break;
                    }
                    case "ignore-empty":
                    case "ignore_empty": {
                        ignoreEmptyLines = parse_boolean(i.value);
                        break;
                    }
                    case "ignore-whitespace":
                    case "ignore_whitespace": {
                        ignoreWhitespace = parse_boolean(i.value);
                        break;
                    }
                    case "verify-columns":
                    case "verify_columns": {
                        checkElementCounts = parse_boolean(i.value);
                        break;
                    }
                    case "header-lines":
                    case "header_lines": {
                        try {
                            headerLines = i.value;
                        }
                        catch (hash ex) {
                            throw errname, sprintf("expecting integer value or a value that can be converted to an integer for option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        }
                        break;
                    }
                    case "header-names":
                    case "header_names": {
                        headerNames = parse_boolean(i.value);
                        break;
                    }
                    case "header_reorder":
                        headerReorder = parse_boolean(i.value);
                        break;
                    case "timezone": {
                        timezone = new TimeZone(i.value);
                        break;
                    }
                    case "tolwr": {
                        tolwr = parse_boolean(i.value);
                        break;
                    }
                }
            }
            if (headerNames && !headerLines)
                throw errname, sprintf("\"header_names\" is True but \"header_lines\" is 0; there must be at least 1 header line to get header names");
        }

        #! process specification and assing internal data for resolving
        private processSpec(hash spec) {
            m_specs           = spec;

            m_resolve_by_rule = hash();
            m_resolve_by_count = hash();
            m_resolve_by_idx = hash();
            fakeHeaderNames = False;

            # setup type resolving from spec
            foreach string k in (m_specs.keyIterator()) {
                if (m_specs{k}.typeCode() != NT_HASH)
                    throw errname, sprintf("expecting a record description hash assigned to record key %y; got type %y instead (value: %y)", k, m_specs{k}.type(), m_specs{k});

                list rec_rule = ();
                m_resolve_by_idx{k} = ();
                foreach string c in (m_specs{k}.keyIterator()) {
                    hash fld_rule;
                    if (exists m_specs{k}{c}.regex) {
                        if (exists m_specs{k}{c}.value) {
                            throw errname, sprintf("Both value and regex used in field rule for field %y, record: %y", c, k);
                        }
                        fld_rule.regex = m_specs{k}{c}.regex;
                    } else if (exists m_specs{k}{c}.value) {
                        fld_rule.value = m_specs{k}{c}.value;
                    }
                    if (fld_rule) {
                        fld_rule.idx = m_specs{k}{c}.idx;
                        rec_rule += fld_rule;
                    }
                    push m_resolve_by_idx{k}, c;
                }
                int cnt = m_specs{k}.size();
                if (rec_rule) {
                    # filter specified
                    m_resolve_by_rule{cnt}{k} = rec_rule;
                } else {
                    # no spec filter, check potential conflict later
                    if (!m_resolve_by_count{cnt}) {
                        m_resolve_by_count{cnt} = ();
                    }
                    m_resolve_by_count{cnt} += list(k);
                }
            }
        }

        #! match headers provided at Csv header or in options, never called for multi-type because header_names is False */
        private prepareFieldsFromHeaders(*list headers) {
            # add missing m_specs from headers
            string k = m_specs.firstKey();
            if (m_specs{k}) {
                m_resolve_by_count{m_specs{k}.size()} = select m_resolve_by_count{m_specs{k}.size()}, $1 != k;
            }
            m_resolve_by_idx{k} = adjustFieldsFromHeaders(k, headers);

            if (!m_resolve_by_count{headers.size()}) {
                m_resolve_by_count{headers.size()} = ();
            }
            push m_resolve_by_count{headers.size()}, k;
        }

        bool valid() {
            return lineIterator.valid();
        }

        #! Moves the current line / record position to the next line / record; returns @ref False if there are no more lines to iterate
        /** This method will return @ref True again after it returns @ref False once if the file being iterated has data that can be iterated, otherwise it will always return @ref False. The iterator object should not be used to retrieve a value after this method returns @ref False.
            @return @ref False if there are no lines / records to iterate (in which case the iterator object is invalid and should not be used); @ref True if successful (meaning that the iterator object is valid)

            @note that if headers are not given as an option to the constructor, then they are detected and set the first time AbstractCsvIterator::next() is run on a file (see @ref getHeaders())
         */
        bool next() {
            # try to parse any header and skip to data if we haven't started iterating yet
            if (!valid()) {
                if (headerLines) {
                    if (headerNames) {
                        # return False if there is no data to iterate
                        if (!lineIterator.next())
                            return False;

                        list h = getLineAndSplit();
                        if (!h)
                            return False;
                        prepareFieldsFromHeaders(h);
                    }
                    # skip the rest of the header rows
                    while (lineNumber() < headerLines) {
                        if (!lineIterator.next())
                            return False;
                    }
                }
            }
            bool b = lineIterator.next();
            if (b) {
                # skip empty lines
                if (ignoreEmptyLines) {
                    while (b && (lineIterator.getValue().empty())) {
                        b = lineIterator.next();
                    }
                }

                # generate fake header names with index positions if no header data is already available, note: multi-type has headers
                if (b && (!m_specs || (m_specs.size() == 1 && exists m_specs{CSV_TYPE_SINGLE} && m_specs{CSV_TYPE_SINGLE}.size() == 0))) {
                    list l = getLineAndSplit();
                    list h = ();
                    map h += string($#), l;
                    prepareFieldsFromHeaders(h);
                    fakeHeaderNames = True;
                }
            }

            if (b)
                ++rc;
            else
                rc = 0;

            return b;
        }

        #! Returns the given column value for the current row
        /** @param name the name of the field (header name) in record

            @return the value of the given header for the current record

            @throw INVALID-ITERATOR this error is thrown if the iterator is invalid; make sure that the next() method returns True before calling this method
            @throw ABSTRACTCSVITERATOR-FIELD-ERROR invalid or unknown field name given
         */
        any memberGate(string name) {
            hash h = getRecord(True);
            if (!h.record.hasKey(name))
                throw "ABSTRACTCSVITERATOR-FIELD-ERROR", sprintf("the requested header %y does not exist (known headers: %y)", name, keys m_specs{h.type} );

            return h.record{name};
        }

        #! Returns the current record as a hash
        /** @par Example:
            @code{.py}
hash h = i.getValue();
            @endcode

            @return the current record as a hash; when the \c "extended_record" option is set, then the return value is a hash with the following keys:
            - \c "type": the record type
            - \c "record": a hash of the current record

            @throw INVALID-ITERATOR this error is thrown if the iterator is invalid; make sure that the next() method returns True before calling this method
         */
        hash getValue() {
            return getRecord();
        }

        #! Returns the current record as a hash
        /** @par Example:
            @code{.py}
hash h = i.getRecord();
            @endcode

            @param extended specifies if result is an extended hash including \c "type" and \c "record".

            @return the current record as a hash; if \a extended is @ref True, then the return value is a hash with the following keys:
            - \c "type": the record type
            - \c "record": a hash of the current record

            @throw INVALID-ITERATOR this error is thrown if the iterator is invalid; make sure that the next() method returns @ref True before calling this method
         */
        hash getRecord(bool extended) {
            hash h = parseLine();
            if (extended) {
                return ("type": h.type, "record": h.spec_fields);
            } else {
                return h.spec_fields;
            }
        }

        #! Returns the current record as a hash
        /** @par Example:
            @code{.py}
hash h = i.getRecord();
            @endcode

            @return the current record as a hash; when the \c "extended_record" option is set, then the return value is a hash with the following keys:
            - \c "type": the record type
            - \c "record": a hash of the current record

            @throw INVALID-ITERATOR this error is thrown if the iterator is invalid; make sure that the next() method returns @ref True before calling this method
         */
        hash getRecord() {
            return getRecord(extendedRecord);
        }

        #! Returns the current record as a list
        /** @par Example:
            @code{.py}
list l = i.getRecordList();
            @endcode

            When \"extended_record\" option is set then result is extended hash including \"type\" and \"record\".
            @return the current record as a list of field values; when the \c "extended_record" option is set, then the return value is a hash with the following keys:
            - \c "type": the record type
            - \c "record": a list of field values for the current record

            @throw INVALID-ITERATOR this error is thrown if the iterator is invalid; make sure that the next() method returns True before calling this method
         */
        any getRecordList() {
            hash h = parseLine();
            if (extendedRecord) {
                return ("type": h.type, "record": h.all_fields);
            } else {
                return h.all_fields;
            }
        }

        #! Returns the current separator string
        /** @par Example:
            @code{.py}
string sep = i.getSeparator();
            @endcode

            @return the current separator string
         */
        string getSeparator() {
            return separator;
        }

        #! Returns the current quote string
        /** @par Example:
            @code{.py}
string quote = i.getQuote();
            @endcode

            @return the current quote string
         */
        string getQuote() {
            return quote;
        }

        #! Returns the current record headers or @ref nothing if no headers have been detected or saved yet
        /** @par Example:
            @code{.py}
*list l = i.getHeaders();
            @endcode

            @note if headers are not saved against the object in the @ref constructor(), then they are written to the object after the first call to @ref next()
         */
        *list getHeaders() {
            return getHeaders(m_specs.firstKey());  # single-type
        }

        #! Returns a list of headers for the given record or @ref nothing if the record is not recognized
        /** @par Example:
            @code{.py}
*list l = i.getHeaders(my_type);
            @endcode
         */
        *list getHeaders(string type) {
            return map ($1.value.header), m_specs{type}.pairIterator();
        }

        #! Returns the row index being iterated, which does not necessarily correspond to the line number when there are header rows and blank lines are skipped
        /** @par Example:
            @code{.py}
int index = i.index();
            @endcode

            @return the row index being iterated, which does not necessarily correspond to the line number when there are header rows and blank lines are skipped

            @see lineNumber()

            @since %CsvUtil 1.1
        */
        int index() {
            return rc;
        }

        #! Returns the current iterator line number in the file (the first line is line 1) or 0 if not pointing at a valid element
        /** @par Example:
            @code{.py}
while (i.next()) {
    printf("+ line %d: %y\n", i.lineNumber(), i.getValue());
}
            @endcode

            @return returns the current iterator line number in the data (the first line is line 1) or 0 if not pointing at a valid element

            @see index()

            @since %CsvUtil 1.1
        */
        int lineNumber() {
            return lineIterator.index();
        }

        private any handleType(hash fh, *string val) {
            any rv;
            string type = fh.type;
            # if it's an "or nothing" type and there is no value, then return nothing
            if (type =~ /^\*/) { #/){
                if (val.empty())
                    return NOTHING;
                splice type, 0, 1;
            }

            switch (type) {
                case "int": {
                    rv = int(val);
                    break;
                }
                case "float": {
                    rv = float(val);
                    break;
                }
                case "number": {
                    rv = number(val);
                    break;
                }
                case "date": {
                    if (val.empty())
                        rv = 1970-01-01Z;
                    else {
                        TimeZone tz;
                        if (fh.timezone)
                            tz = fh.timezone;
                        else if (timezone)
                            tz = timezone;
                        *string fmt = fh.format ?? date_format;
                        if (fmt)
                            rv = tz ? tz.date(val, fmt) : date(val, fmt);
                        else
                            rv = tz ? tz.date(val) : date(val);
                    }
                    break;
                }
                default:
                    rv = val;
                    break;
            }

            return rv;
        }

        #! Read line split by separator/quote into list
        private list getLineAndSplit() {
            string s = lineIterator.getValue();
            if (s) {
                return s.split(separator, quote, ignoreWhitespace);
            } else {
                return ();
            }
        }

        #! Identify a fixed-length line type using identifyTypeImpl(); may be overridden if necessary.
        /**
            @param rec Input line record to be identified

            @return the name of the record corresponding to the input line

            @throw ABSTRACTCSVITERATOR-ERROR input line cannot be matched to a known record
        */
        string identifyType(list rec) {
            *string type = identifyTypeImpl(rec);
            if (type != CSV_TYPE_UNKNOWN) {
                if (!type)
                    throw errname, sprintf("The input line could not be identified: %y", rec);
                if (!m_specs.hasKey(type))
                    throw errname, sprintf("Line identified to be of type %y that is not present in the spec: %y", type, rec);
            }
            return type;
        }

        #! Identify a input record, given the raw line string. This method performs a lookup to a precalculated table based on number of records (see constructor()). In case different criteria are needed, eg. when two line types in a spec have the same record number and no unique resolving rule are specified, this method needs to be overridden, otherwise it will throw an exception because the precalculated mapping will be empty.
        /**
            @param rec Input line record to be identified

            @return the record name or @ref nothing if the input cannot be matched

            @throw ABSTRACTCSVITERATOR-ERROR input line cannot be matched to a known record
        */
        private *string identifyTypeImpl(list rec) {
            *string rv;
            int cnt = rec.size();
            if (!m_resolve_by_rule{cnt} && !m_resolve_by_count{cnt} && checkElementCounts)
                throw errname, sprintf("Line of unexpected field count %d found; known counts: %y (record: %y)", cnt, sort(map ($1.toInt()), (m_resolve_by_rule + m_resolve_by_count).keyIterator()), rec);

            if (m_resolve_by_rule{cnt}) {
                # try match type by filter spec
                foreach string k in (m_resolve_by_rule{cnt}.keyIterator()) {
                    list rec_rule = m_resolve_by_rule{cnt}{k};
                    bool found = True;  # flt has always at least one item
                    foreach hash fld_rule in (rec_rule) {
                        if (exists fld_rule.regex) {
                            # we do not limit regex to field length to support multi field regex
                            if (!rec[fld_rule.idx].regex(fld_rule.regex)) {
                                found = False;
                                break;
                            }
                        } else {
                            if (fld_rule.value.typeCode() == NT_INT) {
                                # special care about int type,  0 == "000" should evaluate as True
                                if (!rec[fld_rule.idx].intp() || rec[fld_rule.idx].toInt() != fld_rule.value) {
                                    found = False;
                                    break;
                                }
                            } else {
                                if (rec[fld_rule.idx] != fld_rule.value) {
                                    found = False;
                                    break;
                                }
                            }
                        }
                    }
                    if (found) {
                        rv = k;
                        break;
                    }
                }
            }
            if (!rv && m_resolve_by_count{cnt}) {
                if (m_resolve_by_count{cnt}.size() == 1) {
                    rv = m_resolve_by_count{cnt}[0];
                }
                if (m_resolve_by_count{cnt}.size() > 1)
                    throw errname, sprintf("Line with recourd count %d was not automatically matched since the following records have this length: %y; you need to provide your own identifyTypeImpl() method or specify rules (record: %y)", cnt, m_resolve_by_count{cnt}, rec);
            }
            if (!rv && !fakeHeaderNames && m_specs.size() == 1 && exists m_specs{CSV_TYPE_SINGLE}) {
                # where there is only one type then process it, e.g. when optional fields are not mentioned at the end of line
                rv = CSV_TYPE_SINGLE;
            }
            if (!rv && !checkElementCounts) {
                rv = CSV_TYPE_UNKNOWN;
            }
            return rv;
        }

        #! Parses a line in the file and returns a processed list of the fields
        private hash parseLine() {
            list values = getLineAndSplit();
            string type = identifyType(values);
            hash r;
            list l;
            if (type == CSV_TYPE_UNKNOWN) {
                r = map {$#: $1}, values;
                l = values;
            } else {
                foreach string f in (m_resolve_by_idx{type}) {
                    # cherry-pick well-known fields
                    hash fh = m_specs{type}{f};
                    reference val = \values[fh.idx];

                    # first apply type transformations
                    val = handleType(fh, val);

                    # execute any callable value on the processed value
                    if (fh.code) {
                        val = fh.code(val);
                    }
                    r{f} = val;
                    push l, val;
                }
            }
            return ("type": type, "spec_fields": r, "all_fields": l);
        }
    }

    #! The CsvIterator class allows CSV sources to be iterated on a record basis.  The source of the input data is either a @ref Qore::AbstractLineIterator "AbstractLineIterator" object or an @ref Qore::InputStream "InputStream" object.
    /** @see
        - @ref abstractcsviterator_options
        - @ref abstractcsviterator_option_field_types
        - @ref abstractcsviterator_option_field_hash
     */
    public class CsvIterator inherits CsvUtil::AbstractCsvIterator {
        #! Creates the CsvIterator in single-type mode with general line iterator to read and an option hash
        /** @param li line iterator of CSV file to read
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(Qore::AbstractLineIterator li, *hash opts) : AbstractCsvIterator(li, opts) {
        }

        #! Creates the CsvIterator in multi-type mode with general line iterator to read and optionally an option hash
        /** @param li line iterator of CSV file to read
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(Qore::AbstractLineIterator li, hash spec, hash opts) : AbstractCsvIterator(li, spec, opts) {
        }

        #! Creates the CsvIterator from an @ref Qore::InputStream "InputStream", the input encoding, and optionally an option hash
        /** @param input the @ref Qore::InputStream "InputStream" providing data to iterate
            @param encoding the encoding of the input stream
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(Qore::InputStream input, string encoding = "UTF-8", *hash opts) : AbstractCsvIterator(new InputStreamLineIterator(input, encoding, opts.eol), opts) {
        }

        #! Creates the CsvIterator in multi-type mode from an @ref Qore::InputStream "InputStream", the record specification, the input encoding, and optionally an option hash
        /** @param input the @ref Qore::InputStream "InputStream" providing data to iterate
            @param encoding the encoding of the input stream
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(Qore::InputStream input, string encoding = "UTF-8", hash spec, hash opts) : AbstractCsvIterator(new InputStreamLineIterator(input, encoding, opts.eol), spec, opts) {
        }

        any memberGate(string name) {
            return AbstractCsvIterator::memberGate(name);
        }
    }

    #! The CsvFileIterator class allows CSV files to be iterated on a record basis
    /** The class is deprecated as @ref CsvIterator provides more flexibility.
        @see
        - @ref CsvUtil::CsvIterator "CsvIterator" for a stream-based class providing the same functionality as this class in a more generic way
        - @ref abstractcsviterator_options
        - @ref abstractcsviterator_option_field_types
        - @ref abstractcsviterator_option_field_hash
     */
    public class CsvFileIterator inherits CsvUtil::AbstractCsvIterator {
        private {
            #! the path of the file being iterated
            string m_file_path;
        }

        #! Creates the CsvFileIterator in single-type mode with the path of the file to read and an option hash
        /** @param path the path to the CSV file to read
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(string path, *hash opts) : AbstractCsvIterator(new InputStreamLineIterator(new FileInputStream(path), opts.encoding, opts.eol), opts) {
            m_file_path = path;
        }

        #! Creates the CsvFileIterator in multi-type mode with the path of the file to read and optionally an option hash
        /** @param path the path to the CSV file to read
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information
         */
        constructor(string path, hash spec, hash opts) : AbstractCsvIterator(new InputStreamLineIterator(new FileInputStream(path), opts.encoding, opts.eol), spec, opts) {
            m_file_path = path;
        }

        #! calls AbstractCsvIterator::memberGate()
        any memberGate(string name) {
            return AbstractCsvIterator::memberGate(name);
        }

        #! Returns the character encoding for the file
        string getEncoding() {
            return cast<InputStreamLineIterator>(lineIterator).getEncoding();
        }

        #! Returns the file path/name used to open the file
        string getFileName() {
            return m_file_path;
        }

        #! Returns a @ref stat_hash "stat hash" of the underlying file
        hash hstat() {
            return Qore::hstat(m_file_path);
        }

        #! Returns a @ref stat_list "stat list" of the underlying file
        list stat() {
            return Qore::stat(m_file_path);
        }
    } # CsvFileIterator class

    #! The CsvDataIterator class allows arbitrary CSV string data to be iterated on a record basis
    /** The class is deprecated as @ref CsvIterator provides more flexibility.
        @see
        - @ref CsvUtil::CsvIterator "CsvIterator" for a stream-based class providing the same functionality as this class in a more generic way
        - @ref abstractcsviterator_options
        - @ref abstractcsviterator_option_field_types
        - @ref abstractcsviterator_option_field_hash
     */
    public class CsvDataIterator inherits CsvUtil::AbstractCsvIterator {

        #! Creates the CsvDataIterator with the input data and optionally an option hash
        /** @param data the input data to iterate
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information

            @throw ABSTRACTCSVITERATOR-ERROR invalid or unknown option; invalid data type for option; \c "header_names" is @ref Qore::True "True" and \c "header_lines" is 0 or \c "headers" is also present; unknown field type
         */
        constructor(string data, *hash opts) : AbstractCsvIterator(new DataLineIterator(data, opts.eol), opts) {
        }

        #! Creates the CsvDataIterator in multi-type mode with the path of the file to read and an option hash
        /** @param path the path to the CSV file to read
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts a hash of optional options; see @ref abstractcsviterator_options for more information
         */
        constructor(string data, hash spec, hash opts) : AbstractCsvIterator(new DataLineIterator(data, opts.eol), spec, opts) {
        }

        any memberGate(string name) {
            return AbstractCsvIterator::memberGate(name);
        }

    }

    #! The AbstractCsvWriter class provides a parent for all CSV writers
    /**
        Any inherited class must provide concrete implementations for the following abstract method, where the real physical write action must be implemented.

        @code{.py} private writeRawLine(list values) @endcode

        @section csvwriter_options AbstractCsvWriter Constructor Option Hash Overview
        The AbstractCsvWriter class constructor takes an optional hash with possible keys given in the following table.
        Note that key names are case-sensitive, and data types are soft (conversions are made when possible).

        <b>AbstractCsvWriter Options</b>
        |!Option|!Data Type|!Description
        |\c "block"|@ref int_type "int"|the block size when generating output based on a @ref Qore::SQL::SQLStatement "SQLStatement" source (default: \c 1000)
        |\c "date_format"|@ref string_type "string"|the default mask for date values formatting
        |\c "encoding"|@ref string_type "string"|the @ref character_encoding "character encoding" for the file (and for tagging string data read); if the value of this key is not a string then it will be ignored
        |\c "eol"|@ref string_type "string"|the end of line character(s) (default: auto-detect); if the value of this key is not a string then it will be ignored
        |\c "info_log"|@ref code_type "code"|a call reference / closure for informational logging when performing bulk generation with write(Qore::SQL::SQLStatement); must take a single string argument
        |\c "optimal_quotes"|@ref bool_type "bool"|set to @ref Qore::False "False" to disable optimal quoting; when optimal quoting is disabled, all fields are quoted regardless of type or content, when it is enabled, then fields are quoted only if they require quoting (i.e. they contain a quote or separator character); the default is @ref Qore::True "True"
        |\c "quote"|@ref string_type "string"|the field quote character (default: \c '\"')
        |\c "quote_escape"|@ref string_type "string"|the escape character(s) used for \c "quote" (default: \c '\\')
        |\c "separator"|@ref string_type "string"|the string separating the fields in the file (default: \c ",")
        |\c "verify_columns"|@ref bool_type "bool"|if @ref Qore::True "True" (the default is @ref Qore::False "False") then if a line is parsed with a different column count than other lines, a \c CSVFILEWRITER-DATA-ERROR exception is thrown
        |\c "write_headers"|@ref bool_type "bool"|set to @ref Qore::False "False" to suppress the output of headers; the default is @ref Qore::True "True", meaning to output headers if they are present. The value is @ref Qore::False "False" for multi-type lines.

        <b>AbstractCsvIterator Single-type-only Options </b>
        |!Option|!Data Type|!Description
        |\c "datamap"|@ref hash_type "hash"|a hash mapping actual data key names to the output field names, for use in case the data field names differ; does not have to include every data or output key; keys not present will be assumed to be mapped 1:1
        |\c "fields"|@ref hash_type "hash"|describes the data to be output; see @ref abstractcsviterator_option_field_hash "option field hash" and @ref abstractcsviterator_option_field_types "option field types" for more information on the possible values of this option; if no field type is given, the default is \c "*string"
        |\c "headers"|@ref list_type "list" of @ref string_type "strings"|list of header / column names for the data iterated.
        |\c "header_reorder"|@ref bool_type "bool"|if @ref Qore::True "True" (default value) then if \"headers\" are provided by options then fields are reordered to follow headers. It has effect on expected field order as passed to write function via list. If @ref Qore::False "False" then fields not yet specified are pushed at the end of field definition.

        @note the following options with dashes in their names are supported for backwards-compatibility:
        - \c "date-format"
        - \c "optimal-quotes"
        - \c "verify-columns"
        - \c "write-headers"
     */
    public class AbstractCsvWriter inherits private CsvHelper {
        private {
            #! valid options for the object (a hash for quick lookups of valid keys)
            const Options = (
                "block": C_OPT1|C_OPT2,
                "datamap": C_OPT1,
                "date_format": C_OPT1|C_OPT2,
                "date-format": C_OPT1|C_OPT2,
                "encoding": C_OPT1|C_OPT2,
                "eol": C_OPT1|C_OPT2,
                "fields": C_OPT1,
                "headers": C_OPT1,
                "header_reorder": C_OPT1,
                "info_log": C_OPT1|C_OPT2,
                "optimal_quotes": C_OPT1|C_OPT2,
                "optimal-quotes": C_OPT1|C_OPT2,
                "quote": C_OPT1|C_OPT2,
                "quote_escape": C_OPT1|C_OPT2,
                "separator": C_OPT1|C_OPT2,
                "verify_columns": C_OPT1|C_OPT2,
                "verify-columns": C_OPT1|C_OPT2,
                "write_headers": C_OPT1|C_OPT2,
                "write-headers": C_OPT1|C_OPT2,
                );

            #! output file character encoding
            string encoding;

            #! field separator
            string separator = ",";

            #! field content delimiter
            string quote = "\"";

            #! quote escape character
            string m_quoteEscapeChar = "\\";

            #! end of line sequence
            string eol = EOL_UNIX;

            #! verify the column count for every row; if a row does not match, then throw a \c CSVFILEITERATOR-DATA-ERROR exception
            bool checkElementCounts = False;

            #! the latest line number
            int lineNo = 0;

            #! block size for bulk DML
            int block = 1000;

            #! base template for value format
            string baseTemplate;

            #! this flag determines if any stored headers are output
            bool write_headers = True;

            #! stores the optimal quotes option
            bool optimal_quotes = True;

            #! a closure/call reference for informational logging when using write(SQLStatement)
            *code info_log;

            #! mapping output field by name
            hash m_out_by_name;

            #! mapping output field by index
            hash m_out_by_idx;
        }

        #! Creates the AbstractCsvWriter in single-type mode
        /**
            @param n_errname a string to construct child class error message. For example: value 'FOO' will result in exception names 'CSVFOOWRITER-ERROR'
            @param n_opts @ref csvwriter_options

            @throw CSV<errname>ITER-ERROR in the case of incorrect options
         */
        constructor(string n_errname, *hash n_opts): CsvHelper(sprintf("CSV%sWRITER-ERROR", n_errname)) {

            processCommonOptions(n_opts, C_OPT1);

            # set headers automatically from field names if not set
            if (n_opts.fields && !n_opts.headers)
                n_opts.headers = n_opts.fields.keys();

            m_specs = getSpec1(n_opts.fields);

            if (n_opts.datamap) {
                if (n_opts.datamap.typeCode() != NT_HASH)
                    throw errname, sprintf("expecting a hash value to option %y; got %y (type %s) instead", n_opts.datamap.key, n_opts.datamap, n_opts.datamap.type());
                # ensure that all the values are strings
                foreach hash h in (n_opts.datamap.pairIterator()) {
                    if (h.value.typeCode() != NT_STRING)
                        throw errname, sprintf("\"datamap\" key %y has a non-string value; got type %y", h.key, h.value.type());
                }

                string k = m_specs.firstKey();
                foreach hash h in (n_opts.datamap.pairIterator()) {
                    if (!exists m_specs{k}{h.key}) {
                        m_specs{k}{h.key} = ("type": "*string", "idx": m_specs{k}.size());
                    }
                    m_specs{k}{h.key}.header = tolwr ? h.value.lwr() : h.value;
                }
            }
            if (n_opts.headers) {
                adjustFieldsFromHeaders(m_specs.firstKey(), n_opts.headers);
            }
            processSpec();
        }

        #! Creates the AbstractCsvWriter in single-type mode
        /**

            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param n_errname a string to construct child class error message. For example: value 'FOO' will result in exception names 'CSVFOOWRITER-ERROR'
            @param n_opts @ref csvwriter_options

            @throw CSV<errname>WRITER-ERROR in the case of incorrect options
         */
        constructor(string n_errname, hash spec, hash n_opts): CsvHelper(sprintf("CSV%sWRITER-ERROR", n_errname)) {
            m_specs = getSpec2(spec);
            processCommonOptions(n_opts, C_OPT2);
            processSpec();
        }

        #! Process options and set internal variables
        private processCommonOptions(*hash n_opts, int C_OPTx) {
            date_format = 'DD/MM/YYYY hh:mm:SS';  # different default value in writer
            if (n_opts.encoding.typeCode() == NT_STRING) {
                encoding = n_opts.encoding;
                # ensure that the default value for the encoding is used (to handle case + encoding aliases); also validates that
                # the encoding is known and supported
                string str = convert_encoding(encoding, encoding);
                encoding = str.encoding();
            }
            else
                encoding = get_default_encoding();

            foreach hash i in (n_opts.pairIterator()) {
                if (!exists Options.(i.key) && (Options.(i.key) & C_OPTx) == 0)
                    throw errname, sprintf("unknown option %y passed to %s::constructor() (valid options: %y)", i.key, self.className(), (select Options.keys(), (Options.$1 & C_OPTx) != 0));

                # if the option is not set, then ignore it
                if (!exists i.value || i.value === NULL)
                    continue;

                switch (i.key) {
                    case "block": {
                        if (!i.value.intp())
                            throw errname, sprintf("expecting an integer value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        block = i.value.toInt();
                        if (block < 1)
                            throw errname, sprintf("expecting a positive integer value to option %y; got %y instead", i.key, i.value);
                        break;
                    }
                    case "separator": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        separator = i.value;
                        break;
                    }
                    case "quote": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        quote = i.value;
                        break;
                    }
                    case "quote_escape": {
                        if (i.value.typeCode() != NT_STRING) {
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        }
                        m_quoteEscapeChar = i.value;
                        break;
                    }
                    case "eol": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        if (!inlist(i.value, EOLS))
                            throw errname, sprintf("expecting a known end of line value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        eol = i.value;
                        break;
                    }
                    case "date_format":
                    case "date-format": {
                        if (i.value.typeCode() != NT_STRING)
                            throw errname, sprintf("expecting a string value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        date_format = i.value;
                        break;
                    }
                    case "verify_columns":
                    case "verify-columns": {
                        checkElementCounts = parse_boolean(i.value);
                        break;
                    }
                    case "write_headers":
                    case "write-headers": {
                        write_headers = parse_boolean(i.value);
                        break;
                    }
                    case "optimal_quotes":
                    case "optimal-quotes": {
                        optimal_quotes = parse_boolean(i.value);
                        break;
                    }
                    case "info_log": {
                        if (!i.value.callp())
                            throw errname, sprintf("expecting a callable value to option %y; got %y (type %s) instead", i.key, i.value, i.value.type());
                        info_log = i.value;
                        break;
                    }
                    case "header_reorder": {
                        headerReorder = parse_boolean(i.value);
                        break;
                    }
                }

            }
            # make eg. '"%s",' template
            baseTemplate = sprintf("%s%%s%s%s", quote, quote, separator);
        }

        #! Process specification and set internal variable for mapping
        private processSpec() {
            if (write_headers && isMultiType()) {
                throw errname, sprintf("\"write_headers\" is True but \"headers\" defined as multi-type (%y)", m_specs);
            }
            foreach string k in (m_specs.keyIterator()) {
                list ll;
                if (m_specs{k}) {
                    int i = 0;
                    foreach hash f in (m_specs{k}.pairIterator()) {
                        ll += ("out_idx": f.value.idx ?? 0, "field": f.key, "idx": i);
                        i++;
                    }
                    code sort_func = int sub (hash l, hash r) { return l.out_idx <=> r.out_idx; };
                    ll = sort(ll, sort_func);
                    m_out_by_name{k} = map ($1.field), ll;
                    m_out_by_idx{k} = map ($1.idx), ll;
                }
            }
        }

        #! Write csv headers
        private writeHeaders() {
            if (write_headers && m_specs.size() == 1 && m_specs.firstValue().size() > 0) {
                string type = m_specs.firstKey();
                list values = map (m_specs{type}{$1}.header ?? $1), m_out_by_name{type};
                writeRawLine(values);
            }
        }

        #! Write a line with a list of values; data are checked against column rules
        /**
            @param values a list with values.

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints
         */
        writeLine(list values) {
            writeLine(CSV_TYPE_SINGLE, values);
        }

        #! Write a line with headers-values hash
        /**
            @param values a hash with keys as column headers in single-type format or with hash with \"type\" and \"record\" members for multi-type. The format is automatically detected.

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints
         */
        writeLine(hash values) {
            if (exists values.type && exists values.record) {
                writeLine(values.type, values.record);
            } else {
                writeLine(CSV_TYPE_SINGLE, values);
            }
        }

        #! Write a line with headers-values list
        /**
            @param type record type
            @param values as list of values

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints
         */
        writeLine(string type, list values) {
            lineNo++;
            if (checkElementCounts && m_specs{type} && values.size() != m_specs{type}.size())
                throw errname, sprintf("Line (%d), Header size (%d) and line size (%d) are different (enforced by the \"verify_columns\" option)", lineNo, m_specs{type}.size(), values.size());

            list rawValues = ();
            for(int j = 0; j < values.size(); j++) {
                int i = j;
                #! format date to string by options. Priority: 1) column definition 2) standard format
                string dateFmt = date_format;
                if (m_out_by_idx{type} && j < m_out_by_idx{type}.size()) {
                    # get correct input value
                    i = m_out_by_idx{type}[j];
                    hash spec = m_specs{type}{m_out_by_name{type}[j]};
                    switch (spec.type) {
                        case "int": {
                            if (int(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain an integer value %n vs %n", lineNo, j, int(values[i]), values[i]);
                            break;
                        }
                        case "*int": {
                            if (!values[i].empty() && int(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain an integer value %n vs %n", lineNo, j, int(values[i]), values[i]);
                            break;
                        }
                        case "float": {
                            if (float(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a float value %n vs %n", lineNo, j, float(values[i]), values[i]);
                            break;
                        }
                        case "*float": {
                            if (!values[i].empty() && float(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a float value %n vs %n", lineNo, j, float(values[i]), values[i]);
                            break;
                        }
                        case "number": {
                            if (number(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a number value %n vs %n", lineNo, j, number(values[i]), values[i]);
                            break;
                        }
                        case "*number": {
                            if (!values[i].empty() && number(values[i]) != values[i])
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a number value %n vs %n", lineNo, j, number(values[i]), values[i]);
                            break;
                        }
                        case "date": {
                            if (values[i].typeCode() != NT_DATE)
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a date value (%s), %y", lineNo, j, values[i].type(), values[i]);
                            dateFmt = spec.format ?? date_format;
                            break;
                        }
                        case "*date": {
                            if (!values[i].empty() && values[i].typeCode() != NT_DATE)
                                throw errname, sprintf("Line (%d), Column (%d) does not contain a date value (%s)", lineNo, j, values[i].type());
                            dateFmt = spec.format ?? date_format;
                            break;
                        }
                    }
                }

                # format date as requested
                if (values[i].typeCode() == NT_DATE) {
                    values[i] = format_date(dateFmt, values[i]);
                }
                push rawValues, values[i];
            }

            writeRawLine(rawValues);

        }

        #! Write a line for a specific record from a hash to the output
        /**
            @param type record type
            @param values a hash of values.

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints
         */
        writeLine(string type, hash values) {
            if (!m_specs{type})
                throw errname, sprintf("Type '%s' not defined header in AbstractCsvWriter instance to bind the hash key", type);
            list line;
            foreach string i in (m_specs{type}.keyIterator()) { # (m_out_by_name{type}) {
                if (!values.hasKey(i))
                    if (exists m_specs{type}{i}.default) {
                        push line, m_specs{type}{i}.default;
                    } else {
                        push line, NOTHING;
                    }
                else {
                    push line, values{i};
                }
            }
            writeLine(type, line);
        }

        #! Stream an iterator into the output
        /**
            @param iterator an iterator to stream data into file

            The iterator has to return @ref list or @ref hash from the @ref Qore::AbstractIterator::getValue() "getValue()" method.

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints or when @ref Qore::AbstractIterator::getValue() "getValue()" does not return list or hash
         */
        write(Qore::AbstractIterator iterator) {
            while (iterator.next()) {
                any row = iterator.getValue();
                switch (row.typeCode()) {
                    case NT_HASH:
                        writeLine(row);
                        break;
                    case NT_LIST:
                        writeLine(row);
                        break;
                    default:
                        throw errname, sprintf("Iterator's getValue returned %s, expected list or hash", row.type());
                }
            }
        }

        #! Stream an iterator into the output
        /**
            @param iterator an @ref Qore::SQL::SQLStatement "SQLStatement" iterator to stream data into file; @ref Qore::SQL::SQLStatement::fetchColumns() "SQLStatement::fetchColumns()" is used to leverage bulk DML for more efficient SQL I/O

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints

            @note if any \c "info_log" option is set in the constructor; it is used here to log each block of SQL data used to generate the corresponding number of lines; log messages look like: \c "query input generated bulk output lines: 1000"
         */
        write(Qore::SQL::SQLStatement iterator) {
            while (*hash h = iterator.fetchColumns(block)) {
                int n = h.firstValue().lsize();
                if (!n)
                    break;
                map writeLine($1), h.contextIterator();
                if (info_log)
                    info_log(sprintf("query input generated bulk output lines: %d", n));
            }
        }

        #! Stream the contents of the list into the output
        /**
            @param l a list of input data to format as CSV output

            The list has to contain @ref list or @ref hash elements that can be formatted according to the CSV definition

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints or when the list elements have the wrong type or values
         */
        write(list l) {
            write(l.iterator());
        }

        #! This method must be overridden in child classes to provide the output implementation
        abstract private writeRawLine(list values);

        #! Prepare a string (line with EOF) with formatting and escaping.
        /**
            @param values a list with values

            @return string a formatted and escaped line with a trailing EOL string; if an \c encoding option was given to the constructor; the return value always has the given encoding
        */
        private string prepareRawLine(list values) {
            string rv = prepareRawLineIntern(values);
            return encoding && rv.encoding() != encoding ? convert_encoding(rv, encoding) : rv;
        }

        private string prepareRawLineIntern(list values) {
            if (!optimal_quotes) {
                # make full line template
                string template = strmul(baseTemplate, elements values, 1) + eol;
                # escape separators in strings
                list row = map replace(string($1), quote, m_quoteEscapeChar + quote), values;

                return vsprintf(template, row);
            }

            list l = ();
            foreach any v in (values) {
                if (v.typeCode() == NT_STRING) {
                    if (v.find(quote) >= 0) {
                        v = replace(v, quote, m_quoteEscapeChar + quote);
                        v = sprintf("\"%s\"", v);
                    }
                    else if (v.find(separator) >= 0)
                        v = sprintf("\"%s\"", v);
                    l += v;
                    continue;
                }
                l += string(v);
            }
            return (foldl $1 + separator + $2, l) + eol;
        }

    } # AbstractCsvWriter class

    #! The CsvWriter class for safe CSV data creation
    public class CsvWriter inherits AbstractCsvWriter {
        private {
            #! the output stream for the CSV data
            StreamWriter output;
        }

        #! creates the CsvWriter in single-type mode with the @ref Qore::OutputStream "OutputStream" and an optional option hash
        /**
            @param output the @ref Qore::OutputStream "OutputStream" for the CSV data generated
            @param opts @ref csvwriter_options

            @throw CSVFILEITER-ERROR in the case of incorrect options
        */
        constructor(Qore::OutputStream output, *hash opts) : AbstractCsvWriter("STREAM", opts) {
            # we do not use the encoding option with the StreamWriter constructor() here, because we always generate output data
            # with the output encoding in any case
            self.output = new StreamWriter(output);
            writeHeaders();
        }

        #! creates the CsvWriter in multi-type mode with the @ref Qore::OutputStream "OutputStream" and an option hash
        /**
            @param output the @ref Qore::OutputStream "OutputStream" for the CSV data generated
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts @ref csvwriter_options

            @throw CSVFILEITER-ERROR in the case of incorrect options
        */
        constructor(Qore::OutputStream output, hash spec, hash opts) : AbstractCsvWriter("STREAM", spec, opts) {
            # we do not use the encoding option with the StreamWriter constructor() here, because we always generate output data
            # with the output encoding in any case
            self.output = new StreamWriter(output);
            writeHeaders();
        }

        #! renders the line and writes it to the output stream
        private writeRawLine(list values) {
            output.print(prepareRawLine(values));
        }
    }

    #! The CsvFileWriter class for safe CSV file creation
    /**
        @see
        - @ref CsvUtil::CsvWriter "CsvWriter" for a stream-based class providing the same functionality as this class in a more generic way
     */
    public class CsvFileWriter inherits AbstractCsvWriter {
        private {
            #! the file to write
            Qore::File file;
        }

        #! creates the CsvFileWriter in single-type mode with the path of the file to create and an optional option hash
        /**
            @param path a file name (with path optionally) to write
            @param opts @ref csvwriter_options

            The file is created with @ref Qore::O_CREAT "O_CREAT", @ref Qore::O_TRUNC "O_TRUNC", @ref Qore::O_WRONLY "O_WRONLY" and \c 0644 access.

            @throw CSVFILEITER-ERROR in the case of incorrect options
        */
        constructor(string path, *hash opts) : AbstractCsvWriter("FILE", opts) {
            openFile(path);
        }

        #! creates the CsvFileWriter in multi-type mode with the path of the file to create and an optional option hash
        /**
            @param path a file name (with path optionally) to write
            @param spec a hash of field and type definition; see @ref abstractcsviterator_option_field_hash for more information
            @param opts @ref csvwriter_options

            The file is created with @ref Qore::O_CREAT "O_CREAT", @ref Qore::O_TRUNC "O_TRUNC", @ref Qore::O_WRONLY "O_WRONLY" and \c 0644 access.

            @throw CSVFILEITER-ERROR in the case of incorrect options
        */
        constructor(string path, hash spec, hash opts) : AbstractCsvWriter("FILE", spec, opts) {
            openFile(path);
        }

        private openFile(string path) {
            # we do not use the encoding option with the File constructor() here, because we always generate output data
            # with the output encoding in any case
            file = new File();
            file.open2(path, O_CREAT | O_TRUNC | O_WRONLY, 0644);
            writeHeaders();
        }

        private writeRawLine(list values) {
            file.write(prepareRawLine(values));
        }
    } # CsvFileWriter

    #! The CsvStringWriter class for in-memory string CSV creation
    /**
        @see
        - @ref CsvUtil::CsvWriter "CsvWriter" for a stream-based class providing the same functionality as this class in a more generic way
     */
    public class CsvStringWriter inherits AbstractCsvWriter {
        private {
            # a csv content
            string content;
        }

        #! creates the CsvStringWriter single-type mode with content in the memory
        /**
            @param opts @ref csvwriter_options

            @throw CSVSTRINGITER-ERROR in the case of incorrect options
        */
        constructor(*hash opts) : AbstractCsvWriter("STRING", opts) {
            initContent();
        }

        #! creates the CsvStringWriter single-type mode with content in the memory
        /**
            @param spec a hash of field and type definitions; see @ref abstractcsviterator_option_field_hash for more information
            @param opts @ref csvwriter_options

            @throw CSVSTRINGITER-ERROR in the case of incorrect options
        */
        constructor(hash spec, hash opts) : AbstractCsvWriter("STRING", spec, opts) {
            initContent();
        }

        private initContent() {
            writeHeaders();
        }

        private writeRawLine(list values) {
            content += prepareRawLine(values);
        }

        #! Stream iterator and return a CSV-formatted output string
        /**
            @param iterator an iterator to stream data

            @return the CSV-formatted output string corresponding to the input data

            The iterator has to contain @ref list or @ref hash as a return value of \c getValue() method.

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints or when \c getValue does not return list or hash
         */
        string write(Qore::AbstractIterator iterator) {
            AbstractCsvWriter::write(iterator);
            return content;
        }

        #! Stream the contents of the list and return CSV-formatted output as a string
        /**
            @param l a list of input data to format as CSV output

            @return the CSV-formatted output string corresponding to the input data

            The list has to contain @ref list or @ref hash elements that can be formatted according to the CSV definition

            @throw CSVFILEWRITER-DATA-ERROR when the data does not fit defined column constraints or when the list elements have the wrong type or values
         */
        string write(list l) {
            AbstractCsvWriter::write(l);
            return content;
        }

        #! Get the current in-memory content as a string
        string getContent() {
            return content;
        }
    } # CsvStringWriter
} # CsvUtil namespace

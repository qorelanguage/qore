# -*- mode: qore; indent-tabs-mode: nil -*-
#! @file Mapper.qm data mapping module

/*  Mapper.qm Copyright 2014 - 2017 Qore Technologies, s.r.o.

    Permission is hereby granted, free of charge, to any person obtaining a
    copy of this software and associated documentation files (the "Software"),
    to deal in the Software without restriction, including without limitation
    the rights to use, copy, modify, merge, publish, distribute, sublicense,
    and/or sell copies of the Software, and to permit persons to whom the
    Software is furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in
    all copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.
*/

# minimum required Qore version
%requires qore >= 0.8.13

# require type definitions everywhere
%require-types

# enable all warnings
%enable-all-warnings

# do not use "$" for vars
%new-style

module Mapper {
    version = "1.3.1";
    desc = "user module providing basic data mapping infrastructure";
    author = "David Nichols <david@qore.org>";
    url = "http://qore.org";
    license = "MIT";
}

/*  Version History
*/

/** @mainpage Mapper Module

    @tableofcontents

    @section mapperintro Mapper Module Introduction

    This module provides classes that help with structured data mapping, meaning the transformation of data in one or more input
    formats to a different output format.

    Classes provided by this module:
    - @ref Mapper::Mapper "Mapper": the base data mapping class
    - @ref Mapper::AbstractMapperIterator "AbstractMapperIterator": an abstract base class for iterator mapper classes
    - @ref Mapper::MapperIterator "MapperIterator": a class that automatically applies a data mapper to iterated data

    @section mapperexamples Mapper Examples

    The following is an example map hash with comments:
    @code{.py}
const DataMap = (
    # output field: "id" mapper from the "Id" element of any "^attributes^" hash in the input record
    "id": "^attributes^.Id",
    # output field: "name": maps from an input field with the same name (no translations are made)
    "name": True,
    # output field: "explicit_count": maps from the input "Count" field, if any value is present then it is converted to an integer
    "explicit_count": ("type": "int", "name": "Count"),
    # output field: "implicit_count": runs the given code on the input record and retuns the result, the code returns the number of "Products" sub-records
    "implicit_count": int sub (any ignored, hash rec) { return rec.Products.size(); },
    # output field: "order_date": converts the "OrderDate" string input field to a date in the specified format
    "order_date": ("name": "OrderDate", "date_format": "DD.MM.YYYY HH:mm:SS.us"),
);
    @endcode

    If this map is applied to the following data in the following way:
    @code{.py}
const MapInput = ((
    "^attributes^": ("Id": 1),
    "name": "John Smith",
    "Count": 1,
    "OrderDate": "02.01.2014 10:37:45.103948",
    "Products": ((
        "ProductName": "Widget 1",
        "Quantity": 1,
        ),
    )), (
    "^attributes^": ("Id": 2),
    "name": "Steve Austin",
    "Count": 2,
    "OrderDate": "04.01.2014 19:21:08.882634",
    "Products": ((
        "ProductName": "Widget X",
        "Quantity": 4,
        ), (
        "ProductName": "Widget 2",
        "Quantity": 2,
        ),
    )),
);

Mapper mapv(DataMap);
list l = mapv.mapAll(MapInput);
printf("%N\n", l);
    @endcode

    The result will be:
    @verbatim
list: (2 elements)
  [0]=hash: (5 members)
    id : 1
    name : "John Smith"
    explicit_count : 1
    implicit_count : 1
    order_date : 2014-01-02 10:37:45.103948 Thu +01:00 (CET)
  [1]=hash: (5 members)
    id : 2
    name : "Steve Austin"
    explicit_count : 2
    implicit_count : 2
    order_date : 2014-01-04 19:21:08.882634 Sat +01:00 (CET))
    @endverbatim

    @section mapperkeys Mapper Specification Format

    The mapper hash is made up of target (ie output) field names (note that dotted output field names result in a nested hash output unless the \a allow_output_dot option is set) as the key values assigned to field specifications as follows:
    - @ref Qore::True "True": this is a shortcut meaning map from an input field with the same name
    - a @ref string_type "string": giving the input field name directly (equivalent to a hash with the \c "name" key)
    - a @ref closure "closure" or @ref call_reference "call reference": meaning map from a field of the same name an apply the given code to give the value for the mapping (equivalent to a hash with the \c "code" key); the @ref closure "closure" or @ref call_reference "call reference" must accept the following arguments:
      - @ref any_type "any" <i>value</i>: the input field value (with the same name as the output field; to use a different name, see the \a code hash option below)
      - @ref hash_type "hash" <i>rec</i>: the current input record
    - a @ref hash_type "hash" describing the mapping; the following keys are all optional (an empty hash means map from an input field with the same name with no translations):
      - \c "code": a closure or call reference to process the field data; cannot be used with the \c "constant" or \c "index" keys
      - \c "constant": the value of this key will be returned as a constant value; this key cannot be used with the \c "name", \c "struct", \c "code", \c "index" or \c "default" keys
      - \c "index": gives current index/count of the row. The initial int value is the start offset. So value 0 means that mapped values will be: 0, 1, ..., N; 1 means: 1, 2, ..., N; etc.
      - \c "date_format": gives the format for converting an input string to a date; see @ref date_formatting for the format of this string; note that this also implies \c "type" = \c "date"
      - \c "default": gives a default value for the field in case no input or translated value is provided
      - \c "mand": assign to boolean @ref Qore::True "True" if the field is mandatory and an exception should be thrown if no input data is supplied
      - \c "maxlen": an integer giving the maximum output string field length in bytes
      - \c "name": the value of this key gives the name of the input field; only use this if the input record name is different than the output field name; note that if this value contains \c "." characters and the \a allow_dot option is not set (see @ref mapperoptions), then the value will be treated like \c "struct" (the \c "struct" key value will be created automatically); cannot be used with the \c "constant" ior \c "index" keys
      - \c "number_format": gives the format for converting an input string to a number; see @ref Qore::parse_number() for the format of this string; note that this also implies \c "type" = \c "number"
      - \c "runtime": a reference to @ref mapper_runtime_handling current status. The value is key in the current runtime structure.
      - \c "struct": the value of this key gives the location of the input field in an input hash in dot notation, ex: \c "element.name" would look for the field's value in the \c "name" key of the \c "element" hash in the input record; cannot be used with the \c "constant" or \c "index" keys; this option is only necessary in place of the "name" option if the \a allow_dot option is set, otherwise use \c "name" instead
      - \c "trunc": assign to boolean @ref Qore::True "True" if the field should be truncated if over the maximum field length; this key can only be set to @ref Qore::True "True" if the \c "maxlen" key is also given
      - \c "type": this gives the output field type, can be:
        - \c "date": date/time field
        - \c "int": fields accepts only integer values (any non-integer values on input will cause an exception to be thrown when mapping; note: also \c "integer" is accepted as an alias for \c "int")
        - \c "number": field accepts only numeric values (any non-numeric values on input will cause an exception to be thrown when mapping); numeric values are left in their original types, any other type is converted to a @ref number_type "arbitrary-precision numeric" value
        - \c "string": field accepts string values; in this case any other value will be converted to a string in the output

    @section mapperoptions Mapper Options

    Mapper objects accept the following options in the option hash:
    - \c "allow_dot": if @ref Qore::True "True" (as evaluated by @ref Qore::parse_boolean() "parse_boolean()") then field names with \c "." characters do not imply a structured internal element lookup; in this case input field names may have \c "." characters in them, use the \c "struct" key to use structured internal element loopups (see @ref mapperkeys \c "struct" docs for more info)
    - \c "allow_output_dot": if @ref Qore::True "True" (as evaluated by @ref Qore::parse_boolean() "parse_boolean()") then output field names with \c "." characters do not imply a structured/hash output element; in this case output field names may have \c "." characters in them
    - \c "date_format": gives the global format for converting a string to a date; see @ref date_formatting for the format of this string; this is applied to all fields of type \c "date" unless the field has a \c "date_format" value that overrides this global setting
    - \c "encoding": the output character encoding; if not present then \c "UTF-8" is assumed
    - \c "info_log": an optional info logging callback; must accept a string format specifier and sprintf()-style arguments
    - \c "input": an optional hash describing the input records where each key is a possible input field name (where dot notation indicates a multi-level hash) and each value is a hash describing the field with the following optional keys:
      - \c "desc": this gives the description of the input field
    - \c "input_log": an optional input data logging callback; must accept a hash giving the input data hash
    - \c "input_timezone": an optional string or integer (giving seconds east of UTC) giving the time zone for parsing input data (ex: \c "Europe/Prague"), if not set defaults to the current TimeZone (see @ref Qore::TimeZone::get())
    - \c "name": the name of the mapper for use in logging and error strings
    - \c "number_format": gives the global format for converting a string to a number; see @ref Qore::parse_number() for the format of this string; this is applied to all fields of type \c "number" unless the field has a \c "number_format" value that overrides this global setting
    - \c "output": an optional hash describing the output data structure; each hash key is a output field name (where dot notation indicates a multi-level hash) and each value is an optional hash describing the output field taking an optional \c "desc" key and a subset of @ref mapperkeys "mapper field hash keys" as follows:
      - \c "desc": a description of the output field
      - \c "mand": @ref Qore::True "True" if the field is mandatory and an exception should be thrown if no input data is supplied
      - \c "maxlen": an integer giving the maximum length of a string field in bytes
      - \c "type": this gives the output field type, can be:
        - \c "date": date/time field
        - \c "int": fields accepts only integer values (any non-integer values on input will cause an exception to be thrown when mapping; note: also \c "integer" is accepted as an alias for \c "int")
        - \c "number": field accepts only numeric values (any non-numeric values on input will cause an exception to be thrown when mapping); numeric values are left in their original types, any other type is converted to a @ref number_type "arbitrary-precision numeric" value
        - \c "string": field accepts string values; in this case any other value will be converted to a string in the output
    - \c "output_log": an optional output data logging callback; must accept a hash giving the output data hash
    - \c "runtime": an initial runtime structure for @ref mapper_runtime_handling
    - \c "timezone": an optional string or integer (giving seconds east of UTC) giving the time zone definition for output data (ex: \c "Europe/Prague"), if not set defaults to the current TimeZone (see @ref Qore::TimeZone::get())
    - \c "trunc_all": if @ref Qore::True "True" (as evaluated by @ref Qore::parse_boolean() "parse_boolean()") then any field without a \c "trunc" key (see @ref mapperkeys \c "trunc" description) will automatically be truncated if a \c "maxlen" attribute is set for the field

    @note
    - if the \c "input" option is given, then only those defined fields can be referenced as input fields in the @ref mapperkeys "mapper hash"; all possible input fields should be defined here if this option is used
    - if the \c "output" option is given, then only those defined fields can be referenced as output fields, additionally the types given in the output definition cannot be overridden in the @ref mapperkeys "mapper hash"; all possible output fields should be defined here if this option is used

    @section mapper_runtime_handling Mapper Runtime Options

    Runtime options for @ref Mapper::Mapper "Mapper" objects allow the programmer to use constant values provided at runtime
    in the @ref Mapper::Mapper "Mapper" output.

    For example, runtime options can be useful in the following cases:
        - storing one date/time value for all output hashes of the @ref Mapper::Mapper "Mapper"
        - using a value from a database sequence value for the lifetime of the @ref Mapper::Mapper "Mapper" object

    @par Example:
    @code{.py}
hash mapv = (
    "foo": ("constant": "bar"),
     # ...
    "date_begin": ("runtime": "start_date"), # references runtime option "start_date"
    "group": ("runtime": "group_id"),        # references runtime option "group_id"
);
hash opts = (
    "timezone": "Europe/Prague",
    # ...
    "runtime": (
        "start_date": now_us(), # set runtime option "start_date"
        "group_id": 0,          # set runtime option "group_id" to 0
    ),
);
Mapper m(mapv, opts);        # runtime options are active now
m.mapData(input1);           # output record hash date_begin = start_date = timestamp of the opts creation and group = 0
    @endcode

    The runtime options are basically the same as setting constants in the mapper before providing runtime data to the mapper. As such, the runtime options can be changed only before the first input hash is processed by a @ref Mapper::Mapper "Mapper".

    Note that the @ref Mapper::Mapper::setRuntime() "Mapper::setRuntime()" and @ref Mapper::Mapper::replaceRuntime() "Mapper::replaceRuntime()" methods are deprecated - please use @ref Mapper::Mapper "Mapper" construction options to set runtime values instead. The methods are deprecated since runtime options duplicate existing functionality and are confusing and error-prone to use.

    @section mapperrelnotes Release Notes

    @subsection mapperv1_3_1 Mapper v1.3.1
    - fixed bugs handling mapper fields with no input records in list mode as passed from the \c TableMapper module (<a href="https://github.com/qorelanguage/qore/issues/1736">issue 1736</a>)

    @subsection mapperv1_3 Mapper v1.3
    - internal updates to allow for TableMapper insert performance improvements (<a href="https://github.com/qorelanguage/qore/issues/1626">issue 1626</a>)

    @subsection mapperv1_2 Mapper v1.2
    - significantly improved mapper performance with identity (i.e. 1:1) and constant mappings (<a href="https://github.com/qorelanguage/qore/issues/1620">issue 1620</a>)

    @subsection mapperv1_1 Mapper v1.1
    - implemented \c "constant" field tag giving a constant value for the output of a field
    - implemented structured output for dotted output field names and the \c "allow_output_dot" option to suppress this behavior
    - implemented \c "default" field tag giving a default value if no input value is specified
    - moved field length checks after all transformations have been applied
    - implemented a global \c "date_format" mapper option
    - implemented the \c "number_format" field option and a global option of the same name
    - fixed bugs in the \c "timezone" and \c "input_timezone" options, documented those options
    - changed the behavior of the \c "number" field type: now leaves numeric values in their original type, converts all other types to a number
    - removed the deprecated \c "crec" option
    - implemented the \c "input" option with input record validation
    - implemented the \c "output" option with output record validation
    - implemented the \c "info_log" option and removed the \c "trunc" option
    - added runtime option handling (@ref mapper_runtime_handling):
      - \c "runtime" mapper option
      - @ref Mapper::Mapper::getRuntime()
      - @ref Mapper::Mapper::replaceRuntime()
      - @ref Mapper::Mapper::setRuntime()
    - implemented \c "index" field tag for current row index
    - improved the @ref Mapper::Mapper::mapAll() method by adding support for hashes of lists to better support input from bulk DML (@ref Qore::SQL::SQLStatement::fetchColumns() "SQLStatement::fetchColumns()")

    @subsection mapperv1_0 Mapper v1.0
    - Initial release
*/

#! the Mapper namespace contains all the definitions in the Mapper module
public namespace Mapper {
    #! this class is a base class for mapping data; see @ref mapperexamples for usage examples
    public class Mapper {
        public {
            #! field keys that conflict with "constant" and "index"
            const ConstantConflictList = ("name", "struct", "code", "default");

            #! constructor option keys (can be extended by subclassing and reimplementing optionKeys())
            const OptionKeys = (
                "allow_dot": "allows input fields to have a dot in their name without implying a structured format",
                "allow_output_dot": "allows output fields to have a dot in their name without implying a structured format",
                "date_format": "gives the default format for parsing dates from strings; ex: \"MM/DD/YYYY HH:mm:SS\"",
                "encoding": "gives the default output character encoding for string fields",
                "info_log": "a call reference / closure for informational logging",
                "input": "a hash describing the input record",
                "input_log": "a call reference / closure for input record logging",
                "input_timezone": "the default timezone to assume when parsing input dates",
                "name": "the name of the Mapper object",
                "number_format": "the default number format when parsing number fields from strings; ex: \".,\"",
                "output": "a hash describing the output record",
                "output_log": "a call reference / closure for input record logging",
                "timezone": "the default output timezone for date/time values",
                "runtime": "runtime options as a hash (see also setRuntime(), replaceRuntime())",
                "empty_strings_to_nothing": "converts out record's empty strings and into NOTHING - actually the value is deleted",
                );

            #! default known mapper hash field keys (can be extended by subclassing and reimplementing validKeys())
            const ValidKeys = (
                "name": True,
                "struct": True,
                "constant": True,
                "index" : True,
                "code": True,
                "default": True,
                "maxlen": True,
                "trunc": True,
                "mand": True,
                "number": True,
                "type": True,
                "date_format": True,
                "number_format": True,
                "runtime" : True,
                "empty_strings_to_nothing" : True,
                );

            #! default known field types (can be extended by subclassing and reimplementing validTypes() and mapFieldType())
            const ValidTypes = (
                "number": True,
                "integer": True,
                "int": True, # is an alias for "integer"
                "date": True,
                "string": True,
                );

            #! output option keys
            const OutputKeys = (
                "desc": True,
                "mand": True,
                "maxlen": True,
                "type": True,
                );
        }

        private {
            #! the hash providing output field names and mappings
            hash mapc;

            #! the hash with a subset of the mappings used dynamically
            hash mapd;

            #! the hash of output records for key order
            hash mapo;

            #! the output character encoding; if not given then the output encoding is assumed to be UTF-8
            string encoding = "utf-8";

            #! the optional name for the object (for example a table name); will be prepended to field names in error messages
            *string name;

            #! an optional info logging callback; must accept a sprintf()-style format specifier and optional arguments
            *code info_log;

            #! an optional input data logging callback; must accept a hash giving the input data hash
            *code input_log;

            #! an optional output data logging callback; must accept a hash giving the output data hash
            *code output_log;

            #! an optional timezone for output date fields
            *Qore::TimeZone timezone;

            #! the timezone for input fields in case of parsing text values; if not set defaults to the current TimeZone (see @ref Qore::TimeZone::get())
            Qore::TimeZone input_timezone = TimeZone::get();

            #! truncate all option
            bool trunc_all = False;

            #! do not assume \a struct when field names have a \c "." in them; instead allow input field names to have a \c "." in them
            bool allow_dot = False;

            #! do not assume structured/hash output when output field names have a \c "." in them; instead allow output field names to have a \c "." in them
            bool allow_output_dot = False;

            #! the global date format for parsing dates
            *string date_format;

            #! the global number format for parsing numbers
            *string number_format;

            #! an optional description of possible input hash keys
            *hash input;

            #! an optional description of the output data structure
            *hash output;

            #! count of records mapped
            int count = 0;

            #! current runtime values
            /** @since Mapper 1.1
             */
            *hash m_runtime;

            #! flag to enforce deletion of the empty string in the output record
            /** @since Mapper 1.1
             */
            bool m_empty_strings_to_nothing = False;

            #! map of fields to be mapped 1:1 input -> output
            hash identh;

            #! list of fields to be mapped 1:1 input -> output
            *list identl;

            #! map of constant fields
            hash consth;

            #! map of constant runtime fields
            hash rconsth;
        }

        #! builds the object based on a hash providing field mappings, data constraints, and optionally custom mapping logic
        /** @par Example:
            @code{.py}
const DataMap = (
    # output field: "id" mapper from the "Id" element of any "^attributes^" hash in the input record
    "id": "^attributes^.Id",
    # output field: "name": maps from an input field with the same name (no translations are made)
    "name": True,
    # output field: "explicit_count": maps from the input "Count" field, if any value is present then it is converted to an integer
    "explicit_count": ("type": "int", "name": "Count"),
    # output field: "implicit_count": runs the given code on the input record and retuns the result, the code returns the number of "Products" sub-records
    "implicit_count": int sub (any ignored, hash rec) { return rec.Products.size(); },
    # output field: "order_date": converts the "OrderDate" string input field to a date in the specified format
    "order_date": ("name": "OrderDate", "date_format": "DD.MM.YYYY HH:mm:SS.us"),
);

Mapper mapv(DataMap);
            @endcode

            @param mapv a hash providing field mappings; each hash key is the name of the output field; each value is either @ref Qore::True "True" (meaning no translations are done; the data is copied 1:1) or a hash describing the mapping; see @ref mapperkeys for detailed documentation for this option
            @param opts an optional hash of options for the mapper; see @ref mapperoptions for a description of valid mapper options

            @throw MAP-ERROR the map hash has a logical error (ex: \c "trunc" key given without \c "maxlen", invalid map key)
         */
        constructor(hash mapv, *hash opts) {
            setup(mapv, opts);

            # check map for logical errors
            checkMap();
        }

        #! private constructor for subclasses
        private constructor() {
        }

        #! sets up the mapper object before checking the mapper hash
        private setup(hash mapv, *hash opts) {
            name = opts.name;
            info_log = opts.info_log;
            input_log = opts.input_log;
            output_log = opts.output_log;

            # validate input record definition
            if (opts.input) {
                if (opts.input.typeCode() != NT_HASH)
                    error("\"input\" option passed to %s::constructor() is not type \"hash\"; got type %y instead", self.className(), opts.input.type());
                input = opts.input;
                foreach hash h in (input.pairIterator()) {
                    switch (h.value.typeCode()) {
                        case NT_STRING: input{h.key} = ("desc": h.value); break;
                        case NT_HASH: break;
                        default: error("\"input\" key %y passed to %s::constructor() assigned to type %y (value %y); expecting \"hash\"", h.key, self.className(), h.value.type(), h.value);
                    }
                }
            }

            # validate output record definition
            if (opts.output) {
                if (opts.output.typeCode() != NT_HASH)
                    error("\"output\" option passed to %s::constructor() is not type \"hash\"; got type %y instead", self.className(), opts.output.type());
                output = opts.output;
                foreach hash h in (output.pairIterator()) {
                    if (h.value === True || !exists h.value) {
                        output{h.key} = {};
                        continue;
                    }
                    if (h.value.typeCode() != NT_HASH)
                        error("\"output\" key %y passed to %s::constructor() assigned to type %y (value %y); expecting \"hash\"", h.key, self.className(), h.value.type(), h.value);
                    foreach string k in (keys h.value) {
                        if (!OutputKeys{k})
                            error("\"output\" key %y passed to %s::constructor() has unknown key %y (valid keys: %y)", h.key, self.className(), k, OutputKeys.keys());
                    }
                }
            }

            if (opts.trunc_all)
                trunc_all = parse_boolean(opts.trunc_all);

            if (!mapv)
                error("empty map passed to %s::constructor()", self.className());

            mapc = mapv;
            hash ck = optionKeys();
            foreach string k in (keys opts) {
                if (!ck{k})
                    error("unknown option key %y passed to %s::constructor(); recognized option keys: %y", getFieldName(k), self.className(), ck.keys());
            }

            if (opts.encoding)
                encoding = opts.encoding;

            if (opts.allow_dot)
                allow_dot = parse_boolean(opts.allow_dot);

            if (opts.allow_output_dot)
                allow_output_dot = parse_boolean(opts.allow_output_dot);

            if (opts) {
                checkTimezoneOption(opts, "timezone");
                checkTimezoneOption(opts, "input_timezone");
            }

            if (opts.date_format)
                date_format = opts.date_format;

            if (opts.number_format)
                number_format = opts.number_format;

            # runtime options
            if (opts.runtime) {
                if (opts.runtime.typeCode() != NT_HASH) {
                    error("input key 'runtime' passed to %s::constructor() assigned to type %y (value %y); expecting \"hash\"",
                          self.className(), opts.runtime.type(), opts.runtime);
                }
                m_runtime = opts.runtime;
            }

            if (opts.empty_strings_to_nothing) {
                m_empty_strings_to_nothing = parse_boolean(opts.empty_strings_to_nothing);
            }
        }

        #! verifies the input map in the constructor
        private checkMap() {
            map checkMapField($1, \mapc.$1), keys mapc;
            mapd = mapc;
            if (identh) {
                identl = keys identh;
                mapd -= identl;
            }
            if (consth) {
                mapd -= keys consth;
            }
            if (rconsth) {
                mapd -= keys rconsth;
            }
        }

        #! convert a field definition to a hash if possible
        private convertToHash(int t, string k, reference fh) {
            switch (t) {
                # convert to a hash if the value of the column is a string (giving the source key name)
                case NT_STRING: fh = ("name": fh); break;
                case NT_CALLREF:
                case NT_CLOSURE: fh = ("code": fh); break;
                case NT_BOOLEAN: if (fh) {
                    fh = {};
                    break;
                }
                case NT_NOTHING: {
                    fh = {};
                    break;
                }
                default: error("unsupported type %y assigned to output field %y", fh.type(), getFieldName(k));
            }
        }

        #! raises an error if an invalid input field name is declared; only call this if "input" is defined
        private checkInputField(string k, string name) {
            string n = allow_dot ? name : name.split('.')[0];
            if (!input.hasKey(n))
                error("output field %y requires unknown input field %y; valid input fields are: %y", getFieldName(k), name, input.keys());
        }

        #! perform per-field pre-processing on the passed map in the constructor
        /** @param k the field name
            @param fh a reference to the field's value in the map
        */
        private checkMapField(string k, reference fh) {
            *hash outf;
            # check output name
            if (output) {
                if (!output.hasKey(k))
                    error("output field %y is not a defined output field; known output fields: %y", getFieldName(k), output.keys());
                # get output definition, if any
                outf = output{k};
            }

            # check field description
            int t = fh.typeCode();
            if (t != NT_HASH)
                convertToHash(t, k, \fh);
            if (fh.name) {
                if (fh.struct)
                    error("output field %y has both 'name' (%y) and 'struct' (%y) values; only one can be given to identify the input field", getFieldName(k), fh.name, fh.struct);
                if (input && !fh.hasKey("constant") && !fh.code && !exists fh.index)
                    checkInputField(k, fh.name);
                if (!allow_dot && fh.name =~ /\./)
                    fh.struct = (remove fh.name).split(".");
                else {
                    # add to ident list if the input and output fields are identical
                    if (fh.name == k && !fh.date_format && !fh.number_format && !fh.trunc && !trunc_all && !fh.subclass && !fh.code)
                        identh{k} = True;
                }
            }
            else if (fh.runtime) {
                if (!m_runtime.hasKey(fh.runtime))
                    error("output field %y requires unregistered runtime key %y", getFieldName(k), fh.runtime);
            }
            else if (!fh.struct && input && !exists fh.constant && !fh.code && !exists fh.index)
                checkInputField(k, k);
            if (exists fh.constant && exists fh.index) {
                error("output field %y has both 'constant' and 'index' which is not valid", getFieldName(k));
            }
            if (exists fh.constant || exists fh.index) {
                *list cl = map $1, fh.keys(){ConstantConflictList};
                string fieldType = exists fh.constant ? "constant" : "index";
                if (cl)
                    error("output field %y has key %y which conflicts with following key(s): %y", fieldType, getFieldName(k), cl);
            }

            switch (fh.struct.typeCode()) {
                case NT_NOTHING: break;
                case NT_STRING: fh.struct = fh.struct.split("."); # then fall down to next case
                case NT_LIST: {
                    if (!fh.struct)
                        error("output field %y has an empty 'struct' key", getFieldName(k));
                    if (fh.struct.size() == 1) {
                        fh.name = (remove fh.struct)[0];
                        if (input)
                            checkInputField(k, fh.name);
                    }
                    else if (input && !exists fh.constant && !fh.code && !exists fh.index)
                        checkInputField(k, (foldl $1 + "." + $2, fh.struct));
                    break;
                }
                default: error("output field %y has an invalid struct key assigned to type %y (%y)", getFieldName(k), fh.struct.type(), fh);
            }

            if (fh.date_format) {
                if (fh.date_format.typeCode() != NT_STRING)
                    error("field %y has a 'date_format' key assigned to type '%s'; expecting 'string'", getFieldName(k), fh.date_format.type());
                if (exists fh.type) {
                    if (fh.type != "date")
                        error("field %y has a 'date_format' key but the field's type is '%s'", getFieldName(k), fh.type);
                }
                else
                    fh.type = "date";
            }

            if (fh.number_format) {
                if (fh.number_format.typeCode() != NT_STRING)
                    error("field %y has a 'number_format' key assigned to type '%s'; expecting 'string'", getFieldName(k), fh.number_format.type());
                if (exists fh.type) {
                    if (fh.type != "number")
                        error("field %y has a 'number_format' key but the field's type is '%s'", getFieldName(k), fh.type);
                }
                else
                    fh.type = "number";
            }

            # check for contradictory definitions and assign values according to the output definition
            if (outf) {
                foreach string ok in (keys outf) {
                    # ignore the "desc" key
                    if (ok == "desc")
                        continue;
                    if (exists fh{ok} && outf{ok} != fh{ok})
                        error("field %y has the %y key set to %y but the output definition has %y set to %y", getFieldName(k), ok, fh{ok}, ok, outf{ok});
                    fh{ok} = outf{ok};
                }
            }

            if (fh.trunc && !fh.maxlen)
                error("output field %y has the 'trunc' key set to True but has no 'maxlen' key", getFieldName(k));

            if (fh.maxlen && !exists fh.trunc && trunc_all)
                fh.trunc = True;

            hash vk = validKeys();
            hash vt = validTypes();

            foreach string hk in (keys fh)
                if (!vk{hk})
                    error("output field %y in map hash contains unknown key '%s' (valid keys: %y)", getFieldName(k), hk, vk.keys());

            # convert old "number" tag to new "type" tag
            if (fh.number) {
                if (exists fh.type)
                    error("output field %y has both 'type' and deprecated 'number' tags", getFieldName(k));
                fh.type = "number";
                delete fh.number;
            }
            else if (exists fh.type) {
                if (!vt.(fh.type))
                    error("output field %y contains an invalid type value '%s' (valid types: %y)", getFieldName(k), fh.type, vt.keys());
                switch (fh.type) {
                    case "date": {
                        if (!timezone)
                            fh.typeCode = NT_DATE;
                        break;
                    }
                    case "string": {
                        fh.typeCode = NT_STRING;
                        break;
                    }
                    case "integer":
                    case "int": {
                        fh.typeCode = NT_INT;
                        break;
                    }
                }
            }

            if (exists fh.code && !fh.code.callp())
                error("output field %y has a code argument assigned to type '%s'", getFieldName(k), fh.code.type());

            if (exists fh."default" && fh.type) {
                hash rec{k} = fh."default";
                try {
                    mapFieldType(k, fh, \rec{k}, rec);
                }
                catch (hash ex) {
                    error("output field %y has default value %y that is not acceptable for the field's type (%y): %s: %s", getFieldName(k), fh."default", fh.type, ex.err, ex.desc);
                }
            }

            # check if the output field should be a hash
            if (!allow_output_dot && k =~ /\./) {
                fh.ostruct = k.split(".");
                mapo{fh.ostruct[0]} = NOTHING;
            }
            else {
                # add to consth if a constant value is included
                # refs #1754 if constant is 0, we cannot simply check with if(fh.constant)
                if (exists fh.constant)
                    consth{k} = fh.constant;
                if (exists fh.runtime)
                    rconsth{k} = fh.runtime;
                mapo{k} = NOTHING;
            }
        }

        #! verifies a timezone constructor option
        private checkTimezoneOption(hash opts, string rn) {
            any val = opts{rn};
            if (!exists val)
                return;
            if (val instanceof TimeZone) {
                self{rn} = val;
                return;
            }

            switch (val.typeCode()) {
                case NT_STRING:
                case NT_INT: self{rn} = new TimeZone(val); break;
                default: error("type %y assigned to the %s option (expecting TimeZone, string, or int)", val.type(), rn);
            }
        }

        #! set the @ref mapper_runtime_handling "runtime option" with \a "key" to value \a "value"
        /** @param key a string with valid runtime key
            @param value anything passed to the current runtime \c key

            @note this method cannot be called once data has been supplied to the Mapper; this method can only be used to initialize the Mapper with constant mappings before the Mapper processes any data

            @see
            - @ref mapper_runtime_handling
            - replaceRuntime()
            - setRuntime()

            @since %Mapper 1.1

            @deprecated use @ref Mapper::constructor() "Mapper construction options" to set
                        the runtime options.

            @throw RUNTIME-OPTION-CHANGED the option has changed during while already
                   processing the data.
         */
        setRuntime(string key, any value) {
            if (count > 0 && exists m_runtime{key} && m_runtime{key} != value) {
                throw "RUNTIME-OPTION-CHANGED", sprintf("the runtime option %y "
                        "has changed %y -> %y while already %y input rows have been "
                        "processed", key, m_runtime{key}, value, count);
            }
            m_runtime{key} = value;
        }

        #! adds @ref mapper_runtime_handling "runtime options" to the current runtime option hash
        /**
            @param runtime a hash of runtime options to add to the current @ref mapper_runtime_handling "runtime option hash"

            @note this method cannot be called once data has been supplied to the Mapper; this method can only be used to initialize the Mapper with constant mappings before the Mapper processes any data

            @see
            - @ref mapper_runtime_handling
            - replaceRuntime()
            - setRuntime()

            @since %Mapper 1.1

            @deprecated use @ref Mapper::constructor() "Mapper construction options" to set
                        the runtime options.

            @throw RUNTIME-OPTION-CHANGED the option has changed during while already
                   processing the data.
         */
        setRuntime(hash runtime) {
            if (count > 0 && m_runtime + runtime != m_runtime) {
                throw "RUNTIME-OPTION-CHANGED", sprintf("the runtime options "
                        "has changed %y -> %y while already %y input rows have been "
                        "processed", m_runtime, m_runtime + runtime, count);
            }
            m_runtime += runtime;
        }

        #! replaces @ref mapper_runtime_handling "runtime options"
        /**
            @param runtime a hash of runtime options to use to replace the current @ref mapper_runtime_handling "runtime option hash"

            @note this method cannot be called once data has been supplied to the Mapper; this method can only be used to initialize the Mapper with constant mappings before the Mapper processes any data

            @see
            - @ref mapper_runtime_handling
            - getRuntime()
            - setRuntime()

            @since %Mapper 1.1

            @deprecated use @ref Mapper::constructor() "Mapper construction options" to set
                        the runtime options.

            @throw RUNTIME-OPTION-CHANGED the option has changed during while already
                   processing the data.
         */
        replaceRuntime(*hash runtime) {
            if (count > 0 && runtime != m_runtime) {
                throw "RUNTIME-OPTION-CHANGED", sprintf("the runtime options "
                        "has changed %y -> %y while already %y input rows have been "
                        "processed", m_runtime, runtime, count);
            }
            m_runtime = runtime;
        }

        #! get current @ref mapper_runtime_handling "runtime option" value for a key
        /**
            @param key the runtime option key
            @returns a runtime value if the key exists in the current @ref mapper_runtime_handling "runtime option hash" and is set

            @see
            - @ref mapper_runtime_handling
            - replaceRuntime()
            - setRuntime()

            @since %Mapper 1.1
         */
        any getRuntime(string key) {
            return m_runtime{key};
        }

        #! returns a descriptive name of the given field if possible, otherwise returns the field name itself
        string getFieldName(string fname) {
            return name ? sprintf("%s.%s", name, fname) : fname;
        }

        #! returns a list of valid field keys for this class (can be overridden in subclasses)
        /** @return a list of valid field keys for this class (can be overridden in subclasses)
        */
        hash validKeys() {
            return ValidKeys;
        }

        #! returns a list of valid field types for this class (can be overridden in subclasses)
        /** @return a list of valid types for this class (can be overridden in subclasses)
        */
        hash validTypes() {
            return ValidTypes;
        }

        #! returns a list of valid constructor options for this class (can be overridden in subclasses)
        /** @return a list of valid constructor options for this class (can be overridden in subclasses)
        */
        hash optionKeys() {
            return OptionKeys;
        }

        #! returns the value of the \c "input" option
        *hash getInputRecord() {
            return input;
        }

        #! returns the value of the \c "output" option
        *hash getOutputRecord() {
            return output;
        }

        #! maps all input records and returns the mapped data as a list of output records
        /** this method applies the @ref mapData() method to all input records and returns the resulting list
            @param recs the list of input records

            @return the mapped data as a list of output records

            @throw MISSING-INPUT a field marked mandatory is missing
            @throw STRING-TOO-LONG a field value exceeds the maximum value and the 'trunc' key is not set
            @throw INVALID-NUMBER the field is marked as numeric but the input value contains non-numeric data
        */
        list mapAll(list recs) {
            return map mapData($1), recs;
        }

        #! maps all input records and returns the mapped data as a list of output records
        /** this method applies the @ref mapData() method to all input records and returns the resulting list
            @param recs a hash of lists of input records

            @return the mapped data as a list of output records

            @throw MISSING-INPUT a field marked mandatory is missing
            @throw STRING-TOO-LONG a field value exceeds the maximum value and the 'trunc' key is not set
            @throw INVALID-NUMBER the field is marked as numeric but the input value contains non-numeric data
        */
        list mapAll(hash recs) {
            return map mapData($1), recs.contextIterator();
        }

        #! processes the input record and returns a hash of the mapped values where the keys in the hash returned are the target field names; the order of the fields in the hash returned is the same order as the keys in the map hash.
        /** @param rec the record to translate

            @return a hash of field values in the target format based on the input data and processed according to the logic in the map hash

            @throw MISSING-INPUT a field marked mandatory is missing
            @throw STRING-TOO-LONG a field value exceeds the maximum value and the 'trunc' key is not set
            @throw INVALID-NUMBER the field is marked as numeric but the input value contains non-numeric data

            @note
            - each time this method is executed successfully, the record count is updated (see @ref getCount() and @ref resetCount())
            - uses mapDataIntern() to map the data, then logOutput() is called for each output row
        */
        hash mapData(hash rec) {
            hash h = mapDataIntern(rec);
            logOutput(h);
            return h;
        }

        #! processes the input record and returns a hash of the mapped values where the keys in the hash returned are the target field names; the order of the fields in the hash returned is the same order as the keys in the map hash.
        /** @param rec the record to translate

            @return a hash of field values in the target format based on the input data and processed according to the logic in the map hash

            @throw MISSING-INPUT a field marked mandatory is missing
            @throw STRING-TOO-LONG a field value exceeds the maximum value and the 'trunc' key is not set
            @throw INVALID-NUMBER the field is marked as numeric but the input value contains non-numeric data

            @note
            - each time this method is executed successfully, the record count is updated (see @ref getCount() and @ref resetCount())
            - this is the same as mapData() except no output logging is performed
        */
        private hash mapDataIntern(hash rec) {
            if (input_log)
                input_log(rec);

            # hash of mapped data to be added to h; mapo provides the output field order
            hash h = mapo;

            # first copy all 1:1 mappings to the output hash
            if (identl)
                h += rec{identl};

            # copy all constant mappings to the output hash
            if (consth)
                h += consth;

            # copy all runtime constant mappings to the output hash
            map h{$1.key} = m_runtime{$1.value}, rconsth.pairIterator();

            # iterate through dynamic target fields
            map mapFieldIntern(\h, $1, rec, False, 0), keys mapd;

            # increment record count
            ++count;

            return h;
        }

        #! maps a single field to the target
        /**
          * Performs the actual mapping
          *
          * @param h the hash to be updated with the mapped key/value pair;
          *          Depending on the mapper specification and the input, it can
          *          contain a bulk record (hash of lists) or a hash of both list
          *          and non-list keys (these are considered a "constants" in the
          *          output record.
          * @param key the column name (hash key) to be mapped (target field)
          * @param rec input record - either single record of hash of lists (batch);
          *                           to increase performance, the input type
          *                           (single record vs. batch) is determined by
          *                           the \a do_list parameter. In case of
          *                           bulk input, all the lists are supposed to
          *                           have the same length \a list_size
          * @param do_list - whether the input record \a rec is single record or
          *                  bulk format (hash of lists)
          * @param list_size - size of the lists in case the input is in bulk
          *                    format (all lists must have the same length,
          *                    asserted inside the method).
          *
          * @note it is assumed that list_size > 0 whenever do_list is Qore::True
          * @note if do_list == Qore::True, the 'rec' can contain a mix of lists
          *       and non-list values - the non-list values are used as constants
          *       in the mapping - as if expanded to lists with all values identical.
          */
        private nothing mapFieldIntern(reference h, string key, hash rec, bool do_list, int list_size) {
            # FIXME: assert(!do_list || list_size > 0);
            # FIXME can add the assert for equal length of the lists --PQ 22-Mar-2017
            hash m = mapc{key};

            # closure to get the current record hash from a hash of lists;
            # rec is not bound here for performance reasons (so it will remain unlocked);
            # NOTE that we still need the NT_LIST check here since even with do_list
            # we can get constants in 'rec' (aka non-lists).
            code getrec = hash sub (hash rc, int offset) {
                return map {$1.key : $1.value.typeCode() == NT_LIST ?
                                        $1.value[offset] :
                                        $1.value}, rc.pairIterator();
            };

            # get source field name
            string name = m.name ?? key;

            # get source record value
            any v;
            if (exists m.constant)
                v = m.constant;
            else if (exists m.index) {
                v = do_list ?
                    (map m.index + count + $#, xrange(0, list_size - 1)) :
                    m.index + count;
            }
            else if (exists m.runtime) {
                # actually runtime should not happen with do_list since
                # do_list = True is only used from TableMapper that is handling
                # runtime outside mapFieldIntern()
                v = m_runtime{m.runtime};
            }
            else if (m.struct) {
                v = rec;
                map v = v{m.struct[$1]}, xrange(0, m.struct.size() - 1);
            }
            else
                v = rec{name} ?? NOTHING; # mitigate NULL -> NOTHING

            bool v_is_list = v.typeCode() == NT_LIST;
            if (v_is_list) {
                if (do_list) {
                    if (list_size != v.size())
                        error2("MAPPER-FIELD-LIST-ERROR", "field %y value passed is the list %y with length %d - the input batch length expected is %d", key, v, v.size(), list_size);
                }
                else {
                    error2("MAPPER-FIELD-LIST-ERROR", "field %y value passed is the list %y in non-list mode", key, v);
                }
            }

            # move any XML CDATA into the field value
            # FIXME review cdata, 'v' can be list here! --PQ 22-Mar-2017
            if (v."^cdata^")
                v = v."^cdata^";

            # if the internal field was marked as needing processing by a subclass, then call the mapSubclass method
            if (m.subclass)
                v = v_is_list ? (map mapSubclass(m, $1), v) : mapSubclass(m, v);

            # execute any field filter if necessary
            if (m.code) {
                try {
                    if (do_list) {
                        v = map m.code(v_is_list ? v[$#] : v, getrec(rec, $#)),
                            xrange(0, list_size - 1);
                        # here we make a list from 'v' either way, since we simply
                        # cannot predict what 'code' could do with 'v' and 'rec'
                        v_is_list = True;
                    }
                    else {
                        v = m.code(v, rec);
                    }
                }
                catch (hash ex) {
                    ex.desc = sprintf("field %y closure: %s", key, ex.desc);
                    throw ex.err, ex.desc, ex.arg;
                }
            }

            if (v_is_list) {
                map delete v[$#], v, (m_empty_strings_to_nothing && $1 === "" || $1 === NULL);
            }
            else {
                if ((m_empty_strings_to_nothing && v === "") || v === NULL)
                    delete v;
            }

            if (m.type) {
                # note: v_is_list implies do_list
                if (v_is_list)
                    map mapFieldType(key, m, \v[$#], getrec(rec, $#)), v, $1.typeCode() != m.typeCode;
                else
                    mapFieldType(key, m, \v, rec);
            }

            if (exists m."default") {
                if (v_is_list) {
                    map v[$#] = m."default", v, !exists $1;
                }
                else if (!exists v)
                    v = m."default";
            }

            # check maximum length
            if (m.maxlen) {
                if (v_is_list) {
                    if (m.trunc)
                        map v[$1] = truncateField(key, $1, $#, v.size(), m.maxlen), v, $1.size() > m.maxlen;
                    else
                        map fieldLengthError(key, $1, $#, v.size(), m.maxlen, getrec(rec, $#)), v, $1.size() > m.maxlen;
                }
                else {
                    if (v.size() > m.maxlen) {
                        # truncate the string if necessary
                        if (m.trunc) {
                            v = truncateField(key, v, 0, 0, m.maxlen);
                        }
                        else
                            fieldLengthError(key, $1, 0, 0, m.maxlen, rec);
                    }
                }
            }

            if (m.mand) {
                if (v_is_list) {
                    map error2("MISSING-INPUT", "field %y element %d/%d is marked as mandatory but is missing in the input row: %y", getFieldName(key), $# + 1, v.size(), getrec(rec, $#)), v, !exists $1;
                }
                else if (!exists v)
                    error2("MISSING-INPUT", "field %y is marked as mandatory but is missing in the input row: %y", getFieldName(key), rec);
            }

            # add value to row list
            if (m.ostruct) {
                # recursive closure for generating structured data
                code ah = any sub (*hash ch, any vc, int off = 0) {
                    if (off == m.ostruct.size())
                        return vc;
                    string k = m.ostruct[off];
                    any oh = ch{k};
                    if (exists oh && oh.typeCode() != NT_HASH)
                        throw "INVALID-OUTPUT", sprintf("field %y cannot overwrite element %y with type %y", getFieldName(key), k, oh.type());
                    ch{k} = ah(oh, vc, off + 1);
                    return ch;
                };
                try {
                    h = ah(h, v);
                    return;
                }
                catch (hash ex) {
                    if (ex.err == "INVALID-OUTPUT")
                        error2(ex.err, ex.desc);
                    else
                        rethrow;
                }
            }

            h{key} = v;
        }

        #! called to truncate fields when processing hashes of lists
        private string truncateField(string k, string val, int ix, int sze, int maxlen) {
            if (info_log)
                info_log("field %y = %y%s input length %d truncating to %d bytes",
                        getFieldName(k), val, (sze > 0 ? sprintf(" element %d/%d", ix + 1, sze) : ""), val.size(), maxlen);
            return trunc_str(val, maxlen, encoding);
        }

        #! called when a field exceeds its maximum length when processing hashes of lists
        private fieldLengthError(string k, string val, int ix, int sze, int maxlen, hash rc) {
            error2("STRING-TOO-LONG", "field %y = %y%s, input length %d exceeds maximum byte length %d for input row: %y",
                    getFieldName(k), val, (sze > 0 ? sprintf(" element %d/%d", ix + 1, sze) : ""), val.size(), maxlen, rc);
        }

        #! calls the output logging @ref closure "closure" or @ref call_reference "call reference" (if any) to log the output record
        logOutput(hash h) {
            if (output_log)
                output_log(h);
        }

        #! returns the internal record count
        /** @see resetCount()
        */
        int getCount() {
            return count;
        }

        #! resets the internal record count
        /** @see getCount()
        */
        resetCount() {
            count = 0;
        }

        #! performs type handling
        private mapFieldType(string key, hash m, reference v, hash rec) {
            if (v === NULL) {
                delete v;
                return;
            }
            if (!exists v)
                return;

            # valid types are checked in the map initialization
            switch (m.type) {
                case "number": {
                    switch (v.typeCode()) {
                        case NT_NUMBER:
                        case NT_FLOAT:
                        case NT_INT:
                            return;
                        case NT_STRING: {
                            *string nf = m.number_format ? m.number_format : number_format;
                            if (nf) {
                                v = parse_number(v, nf);
                                return;
                            }
                            if (v !~ /^([-+])?[0-9]+(\.[0-9]+)?+$/)
                                error2("INVALID-NUMBER", "field %y = %y is marked as a numeric field, but the input data contains non-numeric text in input row: %y", getFieldName(key), v, rec);
                            else
                                v = number(v);
                            return;
                        }
                        default: {
                            error2("INVALID-NUMBER", "field %y = %y is marked as a numeric field, but the input data contains is type %y (value %y) in input row: %y", getFieldName(key), v.type(), v, rec);
                            return;
                        }
                    }
                }
                case "int":
                case "integer": {
                    switch (v.typeCode()) {
                        case NT_INT:
                            return;
                        case NT_STRING: {
                            # check for valid integer values
                            if (v !~ /^([-+])?[0-9]+$/)
                                error2("INVALID-INTEGER", "field %y = %y is marked as an integer field, but the input data contains non-integer text in input row: %y", getFieldName(key), v, rec);
                            v = int(v);
                            return;
                        }
                        default: {
                            int rc = int(v);
                            if (rc != v)
                                error2("INVALID-INTEGER", "field %y = %y is marked as an integer field, but the input data contains non-integer data in input row: %y", getFieldName(key), v, rec);
                            v = rc;
                            return;
                        }
                    }
                }
                case "date": {
                    # if there is no date_format below, then the default conversion is made
                    if (v.typeCode() != NT_DATE)
                        v = input_timezone.date(v, m.date_format ? m.date_format : date_format);
                    # convert to the output TimeZone if necessary
                    if (timezone)
                        v = timezone.date(v);
                    break;
                }
                case "string": {
                    if (v.typeCode() != NT_STRING)
                        v = string(v, encoding);
                    break;
                }
            }
        }

        #! throws a \c MAP-ERROR exception; prepends the map name to the description if known
        /** if this method is subclassed, it must also cause an exception to be thrown
        */
        private error(string fmt) {
            string err = vsprintf(fmt, argv);
            if (name)
                err = sprintf("mapper %y: %s", name, err);
            throw "MAP-ERROR", err;
        }

        #! throws the given exception; prepends the map name to the description if known
        private error2(string ex, string fmt) {
            string err = vsprintf(fmt, argv);
            if (name)
                err = sprintf("%y mapper: %s", name, err);
            throw ex, err;
        }

        #! to be overridden as necessary in subclasses
        private any mapSubclass(hash m, any v) {
            return v;
        }
    }

    #! abstract base class for hash iterator mappping classes based on a mapper object and an iterator input source
    public class AbstractMapperIterator inherits Qore::AbstractIterator {
        public {
        }

        private {
            #! input iterator; @ref Qore::AbstractIterator::getValue() "AbstractIterator::getValue()" must return a hash
            Qore::AbstractIterator i;
        }

        #! creates the iterator from the arguments passed
        /** @param iter input iterator; @ref Qore::AbstractIterator::getValue() "AbstractIterator::getValue()" must return a hash
        */
        constructor(Qore::AbstractIterator iter) {
            i = iter;
        }

        #! Moves the current position of the iterator to the next element; returns @ref Qore::False "False" if there are no more elements
        bool next() {
            return i.next();
        }

        #! returns @ref Qore::True "True" if the iterator is currently pointing at a valid element, @ref Qore::False "False" if not
        bool valid() {
            return i.valid();
        }

        #! returns @ref True if the iterator supports bulk mode; this method returns @ref False (the default)
        bool hasBulk() {
            return False;
        }

        #! performs bulk mapping; if the iterator does not support bulk mapping then it is simulated in this method
        /** @param size the number of rows to return

            @return a list of mapped hashes with a maximum number of rows corresponding to the \a size argument; in case there is less input data than requested, the list returned could have fewer rows than requested; in case there is no more data, the return value is an empty list
         */
        list mapBulk(int size) {
            list rv = ();
            while (next()) {
                rv += getValue();
                if (rv.size() == size)
                    break;
            }
            return rv;
        }
    }

    #! provides a hash iterator based on a mapper object and an iterator input source
    public class MapperIterator inherits Mapper::AbstractMapperIterator {
        public {
        }

        private {
            #! data mapper
            Mapper::Mapper mapc;
        }

        #! creates the iterator from the arguments passed
        /** @param i input iterator; @ref Qore::AbstractIterator::getValue() "AbstractIterator::getValue()" must return a hash
            @param mapv a hash providing field mappings; each hash key is the name of the output field; each value is either @ref Qore::True "True" (meaning no translations are done; the data is copied 1:1) or a hash describing the mapping; see @ref mapperkeys for detailed documnentation for this option
            @param opts an optional hash of options for the mapper; see @ref mapperoptions for a description of valid mapper options

            @throw MAP-ERROR the map hash has a logical error (ex: \c "trunc" key given without \c "maxlen", invalid map key)
         */
        constructor(Qore::AbstractIterator i, hash mapv, *hash opts) : Mapper::AbstractMapperIterator(i) {
            mapc = new Mapper(mapv, opts);
        }

        #! creates the iterator from the arguments passed
        /** @param i input iterator; @ref Qore::AbstractIterator::getValue() "AbstractIterator::getValue()" must return a hash
            @param mapv the mapper to transform the data
        */
        constructor(Qore::AbstractIterator i, Mapper::Mapper mapv) : Mapper::AbstractMapperIterator(i) {
            mapc = mapv;
        }

        #! returns the current row transformed with the mapper
        hash getValue() {
            return mapc.mapData(i.getValue());
        }

        #! returns the internal record count
        /** @see resetCount()
        */
        int getCount() {
            return mapc.getCount();
        }

        #! resets the internal record count
        /** @see getCount()
        */
        resetCount() {
            mapc.resetCount();
        }
    }
}

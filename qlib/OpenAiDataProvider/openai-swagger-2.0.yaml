swagger: '2.0'
info:
  contact:
    name: OpenAI Support
    url: 'https://help.openai.com/'
  description: >-
    The OpenAI REST API. Please see
    https://platform.openai.com/docs/api-reference for more details.
  license:
    name: MIT
    url: 'https://github.com/openai/openai-openapi/blob/master/LICENSE'
  termsOfService: 'https://openai.com/policies/terms-of-use'
  title: OpenAI API
  version: 2.0.0
host: api.openai.com
basePath: /v1
schemes:
  - https
paths:
  /assistants:
    get:
      produces:
        - application/json
      parameters:
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListAssistantsResponse'
      tags:
        - Assistants
      operationId: listAssistants
      summary: Returns a list of assistants.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl "https://api.openai.com/v1/assistants?order=desc&limit=20" \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistants = await openai.beta.assistants.list({
                  order: "desc",
                  limit: "20",
                });

                console.log(myAssistants.data);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistants = client.beta.assistants.list(
                  order="desc",
                  limit="20",
              )
              print(my_assistants.data)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "asst_abc123",
                  "object": "assistant",
                  "created_at": 1698982736,
                  "name": "Coding Tutor",
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc456",
                  "object": "assistant",
                  "created_at": 1698982718,
                  "name": "My Assistant",
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": "You are a helpful assistant designed to make me better at coding!",
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                },
                {
                  "id": "asst_abc789",
                  "object": "assistant",
                  "created_at": 1698982643,
                  "name": null,
                  "description": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "tools": [],
                  "tool_resources": {},
                  "metadata": {},
                  "top_p": 1.0,
                  "temperature": 1.0,
                  "response_format": "auto"
                }
              ],
              "first_id": "asst_abc123",
              "last_id": "asst_abc789",
              "has_more": false
            }
        group: assistants
        name: List assistants
        returns: 'A list of [assistant](/docs/api-reference/assistants/object) objects.'
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateAssistantRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/AssistantObject'
      tags:
        - Assistants
      operationId: createAssistant
      summary: Create an assistant with a model and instructions.
      x-oaiMeta:
        beta: true
        examples:
          - request:
              curl: |
                curl "https://api.openai.com/v1/assistants" \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                    "name": "Math Tutor",
                    "tools": [{"type": "code_interpreter"}],
                    "model": "gpt-4-turbo"
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const myAssistant = await openai.beta.assistants.create({
                    instructions:
                      "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                    name: "Math Tutor",
                    tools: [{ type: "code_interpreter" }],
                    model: "gpt-4-turbo",
                  });

                  console.log(myAssistant);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                my_assistant = client.beta.assistants.create(
                    instructions="You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                    name="Math Tutor",
                    tools=[{"type": "code_interpreter"}],
                    model="gpt-4-turbo",
                )
                print(my_assistant)
            response: |
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1698984975,
                "name": "Math Tutor",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
                "tools": [
                  {
                    "type": "code_interpreter"
                  }
                ],
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            title: Code Interpreter
          - request:
              curl: |
                curl https://api.openai.com/v1/assistants \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                    "tools": [{"type": "file_search"}],
                    "tool_resources": {"file_search": {"vector_store_ids": ["vs_123"]}},
                    "model": "gpt-4-turbo"
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const myAssistant = await openai.beta.assistants.create({
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    tool_resources: {
                      file_search: {
                        vector_store_ids: ["vs_123"]
                      }
                    },
                    model: "gpt-4-turbo"
                  });

                  console.log(myAssistant);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                my_assistant = client.beta.assistants.create(
                    instructions="You are an HR bot, and you have access to files to answer employee questions about company policies.",
                    name="HR Helper",
                    tools=[{"type": "file_search"}],
                    tool_resources={"file_search": {"vector_store_ids": ["vs_123"]}},
                    model="gpt-4-turbo"
                )
                print(my_assistant)
            response: |
              {
                "id": "asst_abc123",
                "object": "assistant",
                "created_at": 1699009403,
                "name": "HR Helper",
                "description": null,
                "model": "gpt-4-turbo",
                "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
                "tools": [
                  {
                    "type": "file_search"
                  }
                ],
                "tool_resources": {
                  "file_search": {
                    "vector_store_ids": ["vs_123"]
                  }
                },
                "metadata": {},
                "top_p": 1.0,
                "temperature": 1.0,
                "response_format": "auto"
              }
            title: Files
        group: assistants
        name: Create assistant
        returns: 'An [assistant](/docs/api-reference/assistants/object) object.'
  '/assistants/{assistant_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the assistant to delete.
          in: path
          name: assistant_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteAssistantResponse'
      tags:
        - Assistants
      operationId: deleteAssistant
      summary: Delete an assistant.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.assistants.del("asst_abc123");

                console.log(response);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.assistants.delete("asst_abc123")
              print(response)
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant.deleted",
              "deleted": true
            }
        group: assistants
        name: Delete assistant
        returns: Deletion status
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the assistant to retrieve.
          in: path
          name: assistant_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/AssistantObject'
      tags:
        - Assistants
      operationId: getAssistant
      summary: Retrieves an assistant.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myAssistant = await openai.beta.assistants.retrieve(
                  "asst_abc123"
                );

                console.log(myAssistant);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_assistant = client.beta.assistants.retrieve("asst_abc123")
              print(my_assistant)
          response: |
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        group: assistants
        name: Retrieve assistant
        returns: >-
          The [assistant](/docs/api-reference/assistants/object) object matching
          the specified ID.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: The ID of the assistant to modify.
          in: path
          name: assistant_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/ModifyAssistantRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/AssistantObject'
      tags:
        - Assistants
      operationId: modifyAssistant
      summary: Modifies an assistant.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/assistants/asst_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    "tools": [{"type": "file_search"}],
                    "model": "gpt-4-turbo"
                  }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myUpdatedAssistant = await openai.beta.assistants.update(
                  "asst_abc123",
                  {
                    instructions:
                      "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                    name: "HR Helper",
                    tools: [{ type: "file_search" }],
                    model: "gpt-4-turbo"
                  }
                );

                console.log(myUpdatedAssistant);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_assistant = client.beta.assistants.update(
                "asst_abc123",
                instructions="You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
                name="HR Helper",
                tools=[{"type": "file_search"}],
                model="gpt-4-turbo"
              )

              print(my_updated_assistant)
          response: |
            {
              "id": "asst_123",
              "object": "assistant",
              "created_at": 1699009709,
              "name": "HR Helper",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are an HR bot, and you have access to files to answer employee questions about company policies. Always response with info from either of the files.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": []
                }
              },
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
        group: assistants
        name: Modify assistant
        returns: >-
          The modified [assistant](/docs/api-reference/assistants/object)
          object.
  /audio/speech:
    post:
      consumes:
        - application/json
      produces:
        - application/octet-stream
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateSpeechRequest'
      responses:
        '200':
          description: OK
          headers:
            Transfer-Encoding:
              description: chunked
              type: string
          schema:
            format: binary
            type: string
      tags:
        - Audio
      operationId: createSpeech
      summary: Generates audio from the input text.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/speech \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "model": "tts-1",
                  "input": "The quick brown fox jumped over the lazy dog.",
                  "voice": "alloy"
                }' \
                --output speech.mp3
            node: |
              import fs from "fs";
              import path from "path";
              import OpenAI from "openai";

              const openai = new OpenAI();

              const speechFile = path.resolve("./speech.mp3");

              async function main() {
                const mp3 = await openai.audio.speech.create({
                  model: "tts-1",
                  voice: "alloy",
                  input: "Today is a wonderful day to build something people love!",
                });
                console.log(speechFile);
                const buffer = Buffer.from(await mp3.arrayBuffer());
                await fs.promises.writeFile(speechFile, buffer);
              }
              main();
            python: |
              from pathlib import Path
              import openai

              speech_file_path = Path(__file__).parent / "speech.mp3"
              response = openai.audio.speech.create(
                model="tts-1",
                voice="alloy",
                input="The quick brown fox jumped over the lazy dog."
              )
              response.stream_to_file(speech_file_path)
        group: audio
        name: Create speech
        returns: The audio file content.
  /audio/transcriptions:
    post:
      consumes:
        - multipart/form-data
      produces:
        - application/json
      parameters:
        - description: >
            The audio file object (not file name) to transcribe, in one of these
            formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          in: formData
          name: file
          required: true
          type: string
          x-oaiTypeLabel: file
        - description: >
            ID of the model to use. Only `whisper-1` (which is powered by our
            open source Whisper V2 model) is currently available.
          in: formData
          name: model
          required: true
          x-oaiTypeLabel: string
        - description: >
            The language of the input audio. Supplying the input language in
            [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
            format will improve accuracy and latency.
          in: formData
          name: language
          type: string
        - description: >
            An optional text to guide the model's style or continue a previous
            audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
            should match the audio language.
          in: formData
          name: prompt
          type: string
        - default: json
          description: >
            The format of the transcript output, in one of these options:
            `json`, `text`, `srt`, `verbose_json`, or `vtt`.
          enum:
            - json
            - text
            - srt
            - verbose_json
            - vtt
          in: formData
          name: response_format
          type: string
        - default: 0
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          in: formData
          name: temperature
          type: number
        - collectionFormat: csv
          default:
            - segment
          description: >
            The timestamp granularities to populate for this transcription.
            `response_format` must be set `verbose_json` to use timestamp
            granularities. Either or both of these options are supported:
            `word`, or `segment`. Note: There is no additional latency for
            segment timestamps, but generating word timestamps incurs additional
            latency.
          in: formData
          items:
            enum:
              - word
              - segment
            type: string
          name: 'timestamp_granularities[]'
          type: array
      responses:
        '200':
          description: OK
          schema: {}
      tags:
        - Audio
      operationId: createTranscription
      summary: Transcribes audio into the input language.
      x-oaiMeta:
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/audio/transcriptions \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: multipart/form-data" \
                  -F file="@/path/to/file/audio.mp3" \
                  -F model="whisper-1"
              node: |
                import fs from "fs";
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const transcription = await openai.audio.transcriptions.create({
                    file: fs.createReadStream("audio.mp3"),
                    model: "whisper-1",
                  });

                  console.log(transcription.text);
                }
                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                audio_file = open("speech.mp3", "rb")
                transcript = client.audio.transcriptions.create(
                  model="whisper-1",
                  file=audio_file
                )
            response: |
              {
                "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
              }
            title: Default
          - request:
              curl: |
                curl https://api.openai.com/v1/audio/transcriptions \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: multipart/form-data" \
                  -F file="@/path/to/file/audio.mp3" \
                  -F "timestamp_granularities[]=word" \
                  -F model="whisper-1" \
                  -F response_format="verbose_json"
              node: |
                import fs from "fs";
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const transcription = await openai.audio.transcriptions.create({
                    file: fs.createReadStream("audio.mp3"),
                    model: "whisper-1",
                    response_format: "verbose_json",
                    timestamp_granularities: ["word"]
                  });

                  console.log(transcription.text);
                }
                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                audio_file = open("speech.mp3", "rb")
                transcript = client.audio.transcriptions.create(
                  file=audio_file,
                  model="whisper-1",
                  response_format="verbose_json",
                  timestamp_granularities=["word"]
                )

                print(transcript.words)
            response: |
              {
                "task": "transcribe",
                "language": "english",
                "duration": 8.470000267028809,
                "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
                "words": [
                  {
                    "word": "The",
                    "start": 0.0,
                    "end": 0.23999999463558197
                  },
                  ...
                  {
                    "word": "volleyball",
                    "start": 7.400000095367432,
                    "end": 7.900000095367432
                  }
                ]
              }
            title: Word timestamps
          - request:
              curl: |
                curl https://api.openai.com/v1/audio/transcriptions \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: multipart/form-data" \
                  -F file="@/path/to/file/audio.mp3" \
                  -F "timestamp_granularities[]=segment" \
                  -F model="whisper-1" \
                  -F response_format="verbose_json"
              node: |
                import fs from "fs";
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const transcription = await openai.audio.transcriptions.create({
                    file: fs.createReadStream("audio.mp3"),
                    model: "whisper-1",
                    response_format: "verbose_json",
                    timestamp_granularities: ["segment"]
                  });

                  console.log(transcription.text);
                }
                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                audio_file = open("speech.mp3", "rb")
                transcript = client.audio.transcriptions.create(
                  file=audio_file,
                  model="whisper-1",
                  response_format="verbose_json",
                  timestamp_granularities=["segment"]
                )

                print(transcript.words)
            response: |
              {
                "task": "transcribe",
                "language": "english",
                "duration": 8.470000267028809,
                "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
                "segments": [
                  {
                    "id": 0,
                    "seek": 0,
                    "start": 0.0,
                    "end": 3.319999933242798,
                    "text": " The beach was a popular spot on a hot summer day.",
                    "tokens": [
                      50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
                    ],
                    "temperature": 0.0,
                    "avg_logprob": -0.2860786020755768,
                    "compression_ratio": 1.2363636493682861,
                    "no_speech_prob": 0.00985979475080967
                  },
                  ...
                ]
              }
            title: Segment timestamps
        group: audio
        name: Create transcription
        returns: >-
          The [transcription object](/docs/api-reference/audio/json-object) or a
          [verbose transcription
          object](/docs/api-reference/audio/verbose-json-object).
  /audio/translations:
    post:
      consumes:
        - multipart/form-data
      produces:
        - application/json
      parameters:
        - description: >
            The audio file object (not file name) translate, in one of these
            formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
          format: binary
          in: formData
          name: file
          required: true
          type: string
          x-oaiTypeLabel: file
        - description: >
            ID of the model to use. Only `whisper-1` (which is powered by our
            open source Whisper V2 model) is currently available.
          in: formData
          name: model
          required: true
          x-oaiTypeLabel: string
        - description: >
            An optional text to guide the model's style or continue a previous
            audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
            should be in English.
          in: formData
          name: prompt
          type: string
        - default: json
          description: >
            The format of the transcript output, in one of these options:
            `json`, `text`, `srt`, `verbose_json`, or `vtt`.
          in: formData
          name: response_format
          type: string
        - default: 0
          description: >
            The sampling temperature, between 0 and 1. Higher values like 0.8
            will make the output more random, while lower values like 0.2 will
            make it more focused and deterministic. If set to 0, the model will
            use [log probability](https://en.wikipedia.org/wiki/Log_probability)
            to automatically increase the temperature until certain thresholds
            are hit.
          in: formData
          name: temperature
          type: number
      responses:
        '200':
          description: OK
          schema: {}
      tags:
        - Audio
      operationId: createTranslation
      summary: Translates audio into English.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/audio/translations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: multipart/form-data" \
                -F file="@/path/to/file/german.m4a" \
                -F model="whisper-1"
            node: |
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                  const translation = await openai.audio.translations.create({
                      file: fs.createReadStream("speech.mp3"),
                      model: "whisper-1",
                  });

                  console.log(translation.text);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              audio_file = open("speech.mp3", "rb")
              transcript = client.audio.translations.create(
                model="whisper-1",
                file=audio_file
              )
          response: |
            {
              "text": "Hello, my name is Wolfgang and I come from Germany. Where are you heading today?"
            }
        group: audio
        name: Create translation
        returns: The translated text.
  /batches:
    get:
      produces:
        - application/json
      parameters:
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          required: false
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
      responses:
        '200':
          description: Batch listed successfully.
          schema:
            $ref: '#/definitions/ListBatchesResponse'
      tags:
        - Batch
      operationId: listBatches
      summary: List your organization's batches.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json"
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.batches.list();

                for await (const batch of list) {
                  console.log(batch);
                }
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.list()
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "batch_abc123",
                  "object": "batch",
                  "endpoint": "/v1/chat/completions",
                  "errors": null,
                  "input_file_id": "file-abc123",
                  "completion_window": "24h",
                  "status": "completed",
                  "output_file_id": "file-cvaTdG",
                  "error_file_id": "file-HOWS94",
                  "created_at": 1711471533,
                  "in_progress_at": 1711471538,
                  "expires_at": 1711557933,
                  "finalizing_at": 1711493133,
                  "completed_at": 1711493163,
                  "failed_at": null,
                  "expired_at": null,
                  "cancelling_at": null,
                  "cancelled_at": null,
                  "request_counts": {
                    "total": 100,
                    "completed": 95,
                    "failed": 5
                  },
                  "metadata": {
                    "customer_id": "user_123456789",
                    "batch_description": "Nightly job",
                  }
                },
                { ... },
              ],
              "first_id": "batch_abc123",
              "last_id": "batch_abc456",
              "has_more": true
            }
        group: batch
        name: List batch
        returns: 'A list of paginated [Batch](/docs/api-reference/batch/object) objects.'
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            properties:
              completion_window:
                description: >-
                  The time frame within which the batch should be processed.
                  Currently only `24h` is supported.
                enum:
                  - 24h
                type: string
              endpoint:
                description: >-
                  The endpoint to be used for all requests in the batch.
                  Currently `/v1/chat/completions`, `/v1/embeddings`, and
                  `/v1/completions` are supported. Note that `/v1/embeddings`
                  batches are also restricted to a maximum of 50,000 embedding
                  inputs across all requests in the batch.
                enum:
                  - /v1/chat/completions
                  - /v1/embeddings
                  - /v1/completions
                type: string
              input_file_id:
                description: >
                  The ID of an uploaded file that contains requests for the new
                  batch.


                  See [upload file](/docs/api-reference/files/create) for how to
                  upload a file.


                  Your input file must be formatted as a [JSONL
                  file](/docs/api-reference/batch/requestInput), and must be
                  uploaded with the purpose `batch`. The file can contain up to
                  50,000 requests, and can be up to 100 MB in size.
                type: string
              metadata:
                additionalProperties:
                  type: string
                description: Optional custom metadata for the batch.
                type: object
                x-nullable: true
            required:
              - input_file_id
              - endpoint
              - completion_window
            type: object
      responses:
        '200':
          description: Batch created successfully.
          schema:
            $ref: '#/definitions/Batch'
      tags:
        - Batch
      operationId: createBatch
      summary: Creates and executes a batch from an uploaded file of requests
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input_file_id": "file-abc123",
                  "endpoint": "/v1/chat/completions",
                  "completion_window": "24h"
                }'
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.create({
                  input_file_id: "file-abc123",
                  endpoint: "/v1/chat/completions",
                  completion_window: "24h"
                });

                console.log(batch);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.create(
                input_file_id="file-abc123",
                endpoint="/v1/chat/completions",
                completion_window="24h"
              )
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "validating",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": null,
              "expires_at": null,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 0,
                "completed": 0,
                "failed": 0
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
        group: batch
        name: Create batch
        returns: 'The created [Batch](/docs/api-reference/batch/object) object.'
  '/batches/{batch_id}':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the batch to retrieve.
          in: path
          name: batch_id
          required: true
          type: string
      responses:
        '200':
          description: Batch retrieved successfully.
          schema:
            $ref: '#/definitions/Batch'
      tags:
        - Batch
      operationId: retrieveBatch
      summary: Retrieves a batch.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.retrieve("batch_abc123");

                console.log(batch);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.retrieve("batch_abc123")
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "completed",
              "output_file_id": "file-cvaTdG",
              "error_file_id": "file-HOWS94",
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": 1711493133,
              "completed_at": 1711493163,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": null,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 95,
                "failed": 5
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
        group: batch
        name: Retrieve batch
        returns: >-
          The [Batch](/docs/api-reference/batch/object) object matching the
          specified ID.
  '/batches/{batch_id}/cancel':
    post:
      produces:
        - application/json
      parameters:
        - description: The ID of the batch to cancel.
          in: path
          name: batch_id
          required: true
          type: string
      responses:
        '200':
          description: Batch is cancelling. Returns the cancelling batch's details.
          schema:
            $ref: '#/definitions/Batch'
      tags:
        - Batch
      operationId: cancelBatch
      summary: Cancels an in-progress batch.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/batches/batch_abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -X POST
            node: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const batch = await openai.batches.cancel("batch_abc123");

                console.log(batch);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.batches.cancel("batch_abc123")
          response: |
            {
              "id": "batch_abc123",
              "object": "batch",
              "endpoint": "/v1/chat/completions",
              "errors": null,
              "input_file_id": "file-abc123",
              "completion_window": "24h",
              "status": "cancelling",
              "output_file_id": null,
              "error_file_id": null,
              "created_at": 1711471533,
              "in_progress_at": 1711471538,
              "expires_at": 1711557933,
              "finalizing_at": null,
              "completed_at": null,
              "failed_at": null,
              "expired_at": null,
              "cancelling_at": 1711475133,
              "cancelled_at": null,
              "request_counts": {
                "total": 100,
                "completed": 23,
                "failed": 1
              },
              "metadata": {
                "customer_id": "user_123456789",
                "batch_description": "Nightly eval job",
              }
            }
        group: batch
        name: Cancel batch
        returns: >-
          The [Batch](/docs/api-reference/batch/object) object matching the
          specified ID.
  /chat/completions:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateChatCompletionRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/CreateChatCompletionResponse'
      tags:
        - Chat
      operationId: createChatCompletion
      summary: Creates a model response for the given chat conversation.
      x-oaiMeta:
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/chat/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a helpful assistant."
                      },
                      {
                        "role": "user",
                        "content": "Hello!"
                      }
                    ]
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    messages: [{ role: "system", content: "You are a helpful assistant." }],
                    model: "VAR_model_id",
                  });

                  console.log(completion.choices[0]);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                completion = client.chat.completions.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ]
                )

                print(completion.choices[0].message)
            response: |
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo-0125",
                "system_fingerprint": "fp_44709d6fcb",
                "choices": [{
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "\n\nHello there, how may I assist you today?",
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 12,
                  "total_tokens": 21
                }
              }
            title: Default
          - request:
              curl: |
                curl https://api.openai.com/v1/chat/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "gpt-4-turbo",
                    "messages": [
                      {
                        "role": "user",
                        "content": [
                          {
                            "type": "text",
                            "text": "What'\''s in this image?"
                          },
                          {
                            "type": "image_url",
                            "image_url": {
                              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"
                            }
                          }
                        ]
                      }
                    ],
                    "max_tokens": 300
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const response = await openai.chat.completions.create({
                    model: "gpt-4-turbo",
                    messages: [
                      {
                        role: "user",
                        content: [
                          { type: "text", text: "What's in this image?" },
                          {
                            type: "image_url",
                            image_url:
                              "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                          },
                        ],
                      },
                    ],
                  });
                  console.log(response.choices[0]);
                }
                main();
              python: |
                from openai import OpenAI

                client = OpenAI()

                response = client.chat.completions.create(
                    model="gpt-4-turbo",
                    messages=[
                        {
                            "role": "user",
                            "content": [
                                {"type": "text", "text": "What's in this image?"},
                                {
                                    "type": "image_url",
                                    "image_url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg",
                                },
                            ],
                        }
                    ],
                    max_tokens=300,
                )

                print(response.choices[0])
            response: |
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1677652288,
                "model": "gpt-3.5-turbo-0125",
                "system_fingerprint": "fp_44709d6fcb",
                "choices": [{
                  "index": 0,
                  "message": {
                    "role": "assistant",
                    "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
                  },
                  "logprobs": null,
                  "finish_reason": "stop"
                }],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 12,
                  "total_tokens": 21
                }
              }
            title: Image input
          - request:
              curl: |
                curl https://api.openai.com/v1/chat/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "messages": [
                      {
                        "role": "system",
                        "content": "You are a helpful assistant."
                      },
                      {
                        "role": "user",
                        "content": "Hello!"
                      }
                    ],
                    "stream": true
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    model: "VAR_model_id",
                    messages: [
                      {"role": "system", "content": "You are a helpful assistant."},
                      {"role": "user", "content": "Hello!"}
                    ],
                    stream: true,
                  });

                  for await (const chunk of completion) {
                    console.log(chunk.choices[0].delta.content);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                completion = client.chat.completions.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": "Hello!"}
                  ],
                  stream=True
                )

                for chunk in completion:
                  print(chunk.choices[0].delta)
            response: >
              {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
              "system_fingerprint": "fp_44709d6fcb",
              "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


              {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
              "system_fingerprint": "fp_44709d6fcb",
              "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}


              ....


              {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
              "system_fingerprint": "fp_44709d6fcb",
              "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
            title: Streaming
          - request:
              curl: |
                curl https://api.openai.com/v1/chat/completions \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "gpt-4-turbo",
                  "messages": [
                    {
                      "role": "user",
                      "content": "What'\''s the weather like in Boston today?"
                    }
                  ],
                  "tools": [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA"
                            },
                            "unit": {
                              "type": "string",
                              "enum": ["celsius", "fahrenheit"]
                            }
                          },
                          "required": ["location"]
                        }
                      }
                    }
                  ],
                  "tool_choice": "auto"
                }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const messages = [{"role": "user", "content": "What's the weather like in Boston today?"}];
                  const tools = [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "description": "Get the current weather in a given location",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA",
                              },
                              "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                            },
                            "required": ["location"],
                          },
                        }
                      }
                  ];

                  const response = await openai.chat.completions.create({
                    model: "gpt-4-turbo",
                    messages: messages,
                    tools: tools,
                    tool_choice: "auto",
                  });

                  console.log(response);
                }

                main();
              python: >
                from openai import OpenAI

                client = OpenAI()


                tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
                ]

                messages = [{"role": "user", "content": "What's the weather like
                in Boston today?"}]

                completion = client.chat.completions.create(
                  model="VAR_model_id",
                  messages=messages,
                  tools=tools,
                  tool_choice="auto"
                )


                print(completion)
            response: |
              {
                "id": "chatcmpl-abc123",
                "object": "chat.completion",
                "created": 1699896916,
                "model": "gpt-3.5-turbo-0125",
                "choices": [
                  {
                    "index": 0,
                    "message": {
                      "role": "assistant",
                      "content": null,
                      "tool_calls": [
                        {
                          "id": "call_abc123",
                          "type": "function",
                          "function": {
                            "name": "get_current_weather",
                            "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                          }
                        }
                      ]
                    },
                    "logprobs": null,
                    "finish_reason": "tool_calls"
                  }
                ],
                "usage": {
                  "prompt_tokens": 82,
                  "completion_tokens": 17,
                  "total_tokens": 99
                }
              }
            title: Functions
          - request:
              curl: |
                curl https://api.openai.com/v1/chat/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "messages": [
                      {
                        "role": "user",
                        "content": "Hello!"
                      }
                    ],
                    "logprobs": true,
                    "top_logprobs": 2
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.chat.completions.create({
                    messages: [{ role: "user", content: "Hello!" }],
                    model: "VAR_model_id",
                    logprobs: true,
                    top_logprobs: 2,
                  });

                  console.log(completion.choices[0]);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                completion = client.chat.completions.create(
                  model="VAR_model_id",
                  messages=[
                    {"role": "user", "content": "Hello!"}
                  ],
                  logprobs=True,
                  top_logprobs=2
                )

                print(completion.choices[0].message)
                print(completion.choices[0].logprobs)
            response: |
              {
                "id": "chatcmpl-123",
                "object": "chat.completion",
                "created": 1702685778,
                "model": "gpt-3.5-turbo-0125",
                "choices": [
                  {
                    "index": 0,
                    "message": {
                      "role": "assistant",
                      "content": "Hello! How can I assist you today?"
                    },
                    "logprobs": {
                      "content": [
                        {
                          "token": "Hello",
                          "logprob": -0.31725305,
                          "bytes": [72, 101, 108, 108, 111],
                          "top_logprobs": [
                            {
                              "token": "Hello",
                              "logprob": -0.31725305,
                              "bytes": [72, 101, 108, 108, 111]
                            },
                            {
                              "token": "Hi",
                              "logprob": -1.3190403,
                              "bytes": [72, 105]
                            }
                          ]
                        },
                        {
                          "token": "!",
                          "logprob": -0.02380986,
                          "bytes": [
                            33
                          ],
                          "top_logprobs": [
                            {
                              "token": "!",
                              "logprob": -0.02380986,
                              "bytes": [33]
                            },
                            {
                              "token": " there",
                              "logprob": -3.787621,
                              "bytes": [32, 116, 104, 101, 114, 101]
                            }
                          ]
                        },
                        {
                          "token": " How",
                          "logprob": -0.000054669687,
                          "bytes": [32, 72, 111, 119],
                          "top_logprobs": [
                            {
                              "token": " How",
                              "logprob": -0.000054669687,
                              "bytes": [32, 72, 111, 119]
                            },
                            {
                              "token": "<|end|>",
                              "logprob": -10.953937,
                              "bytes": null
                            }
                          ]
                        },
                        {
                          "token": " can",
                          "logprob": -0.015801601,
                          "bytes": [32, 99, 97, 110],
                          "top_logprobs": [
                            {
                              "token": " can",
                              "logprob": -0.015801601,
                              "bytes": [32, 99, 97, 110]
                            },
                            {
                              "token": " may",
                              "logprob": -4.161023,
                              "bytes": [32, 109, 97, 121]
                            }
                          ]
                        },
                        {
                          "token": " I",
                          "logprob": -3.7697225e-6,
                          "bytes": [
                            32,
                            73
                          ],
                          "top_logprobs": [
                            {
                              "token": " I",
                              "logprob": -3.7697225e-6,
                              "bytes": [32, 73]
                            },
                            {
                              "token": " assist",
                              "logprob": -13.596657,
                              "bytes": [32, 97, 115, 115, 105, 115, 116]
                            }
                          ]
                        },
                        {
                          "token": " assist",
                          "logprob": -0.04571125,
                          "bytes": [32, 97, 115, 115, 105, 115, 116],
                          "top_logprobs": [
                            {
                              "token": " assist",
                              "logprob": -0.04571125,
                              "bytes": [32, 97, 115, 115, 105, 115, 116]
                            },
                            {
                              "token": " help",
                              "logprob": -3.1089056,
                              "bytes": [32, 104, 101, 108, 112]
                            }
                          ]
                        },
                        {
                          "token": " you",
                          "logprob": -5.4385737e-6,
                          "bytes": [32, 121, 111, 117],
                          "top_logprobs": [
                            {
                              "token": " you",
                              "logprob": -5.4385737e-6,
                              "bytes": [32, 121, 111, 117]
                            },
                            {
                              "token": " today",
                              "logprob": -12.807695,
                              "bytes": [32, 116, 111, 100, 97, 121]
                            }
                          ]
                        },
                        {
                          "token": " today",
                          "logprob": -0.0040071653,
                          "bytes": [32, 116, 111, 100, 97, 121],
                          "top_logprobs": [
                            {
                              "token": " today",
                              "logprob": -0.0040071653,
                              "bytes": [32, 116, 111, 100, 97, 121]
                            },
                            {
                              "token": "?",
                              "logprob": -5.5247097,
                              "bytes": [63]
                            }
                          ]
                        },
                        {
                          "token": "?",
                          "logprob": -0.0008108172,
                          "bytes": [63],
                          "top_logprobs": [
                            {
                              "token": "?",
                              "logprob": -0.0008108172,
                              "bytes": [63]
                            },
                            {
                              "token": "?\n",
                              "logprob": -7.184561,
                              "bytes": [63, 10]
                            }
                          ]
                        }
                      ]
                    },
                    "finish_reason": "stop"
                  }
                ],
                "usage": {
                  "prompt_tokens": 9,
                  "completion_tokens": 9,
                  "total_tokens": 18
                },
                "system_fingerprint": null
              }
            title: Logprobs
        group: chat
        name: Create chat completion
        path: create
        returns: >
          Returns a [chat completion](/docs/api-reference/chat/object) object,
          or a streamed sequence of [chat completion
          chunk](/docs/api-reference/chat/streaming) objects if the request is
          streamed.
  /completions:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateCompletionRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/CreateCompletionResponse'
      tags:
        - Completions
      operationId: createCompletion
      summary: Creates a completion for the provided prompt and parameters.
      x-oaiMeta:
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "prompt": "Say this is a test",
                    "max_tokens": 7,
                    "temperature": 0
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const completion = await openai.completions.create({
                    model: "VAR_model_id",
                    prompt: "Say this is a test.",
                    max_tokens: 7,
                    temperature: 0,
                  });

                  console.log(completion);
                }
                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                client.completions.create(
                  model="VAR_model_id",
                  prompt="Say this is a test",
                  max_tokens=7,
                  temperature=0
                )
            response: |
              {
                "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
                "object": "text_completion",
                "created": 1589478378,
                "model": "VAR_model_id",
                "system_fingerprint": "fp_44709d6fcb",
                "choices": [
                  {
                    "text": "\n\nThis is indeed a test",
                    "index": 0,
                    "logprobs": null,
                    "finish_reason": "length"
                  }
                ],
                "usage": {
                  "prompt_tokens": 5,
                  "completion_tokens": 7,
                  "total_tokens": 12
                }
              }
            title: No streaming
          - request:
              curl: |
                curl https://api.openai.com/v1/completions \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "model": "VAR_model_id",
                    "prompt": "Say this is a test",
                    "max_tokens": 7,
                    "temperature": 0,
                    "stream": true
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const stream = await openai.completions.create({
                    model: "VAR_model_id",
                    prompt: "Say this is a test.",
                    stream: true,
                  });

                  for await (const chunk of stream) {
                    console.log(chunk.choices[0].text)
                  }
                }
                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                for chunk in client.completions.create(
                  model="VAR_model_id",
                  prompt="Say this is a test",
                  max_tokens=7,
                  temperature=0,
                  stream=True
                ):
                  print(chunk.choices[0].text)
            response: |
              {
                "id": "cmpl-7iA7iJjj8V2zOkCGvWF2hAkDWBQZe",
                "object": "text_completion",
                "created": 1690759702,
                "choices": [
                  {
                    "text": "This",
                    "index": 0,
                    "logprobs": null,
                    "finish_reason": null
                  }
                ],
                "model": "gpt-3.5-turbo-instruct"
                "system_fingerprint": "fp_44709d6fcb",
              }
            title: Streaming
        group: completions
        legacy: true
        name: Create completion
        returns: >
          Returns a [completion](/docs/api-reference/completions/object) object,
          or a sequence of completion objects if the request is streamed.
  /embeddings:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateEmbeddingRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/CreateEmbeddingResponse'
      tags:
        - Embeddings
      operationId: createEmbedding
      summary: Creates an embedding vector representing the input text.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/embeddings \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -d '{
                  "input": "The food was delicious and the waiter...",
                  "model": "text-embedding-ada-002",
                  "encoding_format": "float"
                }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const embedding = await openai.embeddings.create({
                  model: "text-embedding-ada-002",
                  input: "The quick brown fox jumped over the lazy dog",
                  encoding_format: "float",
                });

                console.log(embedding);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.embeddings.create(
                model="text-embedding-ada-002",
                input="The food was delicious and the waiter...",
                encoding_format="float"
              )
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "embedding",
                  "embedding": [
                    0.0023064255,
                    -0.009327292,
                    .... (1536 floats total for ada-002)
                    -0.0028842222,
                  ],
                  "index": 0
                }
              ],
              "model": "text-embedding-ada-002",
              "usage": {
                "prompt_tokens": 8,
                "total_tokens": 8
              }
            }
        group: embeddings
        name: Create embeddings
        returns: 'A list of [embedding](/docs/api-reference/embeddings/object) objects.'
  /files:
    get:
      produces:
        - application/json
      parameters:
        - description: Only return files with the given purpose.
          in: query
          name: purpose
          required: false
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListFilesResponse'
      tags:
        - Files
      operationId: listFiles
      summary: Returns a list of files that belong to the user's organization.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.files.list();

                for await (const file of list) {
                  console.log(file);
                }
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.list()
          response: |
            {
              "data": [
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 175,
                  "created_at": 1613677385,
                  "filename": "salesOverview.pdf",
                  "purpose": "assistants",
                },
                {
                  "id": "file-abc123",
                  "object": "file",
                  "bytes": 140,
                  "created_at": 1613779121,
                  "filename": "puppy.jsonl",
                  "purpose": "fine-tune",
                }
              ],
              "object": "list"
            }
        group: files
        name: List files
        returns: 'A list of [File](/docs/api-reference/files/object) objects.'
    post:
      consumes:
        - multipart/form-data
      produces:
        - application/json
      parameters:
        - description: |
            The File object (not file name) to be uploaded.
          format: binary
          in: formData
          name: file
          required: true
          type: string
        - description: >
            The intended purpose of the uploaded file.


            Use "assistants" for [Assistants](/docs/api-reference/assistants)
            and [Message](/docs/api-reference/messages) files, "vision" for
            Assistants image file inputs, "batch" for [Batch
            API](/docs/guides/batch), and "fine-tune" for
            [Fine-tuning](/docs/api-reference/fine-tuning).
          enum:
            - assistants
            - batch
            - fine-tune
          in: formData
          name: purpose
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/OpenAIFile'
      tags:
        - Files
      operationId: createFile
      summary: >
        Upload a file that can be used across various endpoints. Individual
        files can be up to 512 MB, and the size of all files uploaded by one
        organization can be up to 100 GB.


        The Assistants API supports files up to 2 million tokens and of specific
        file types. See the [Assistants Tools guide](/docs/assistants/tools) for
        details.


        The Fine-tuning API only supports `.jsonl` files.


        The Batch API only supports `.jsonl` files up to 100 MB in size.


        Please [contact us](https://help.openai.com/) if you need to increase
        these storage limits.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F purpose="fine-tune" \
                -F file="@mydata.jsonl"
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.create({
                  file: fs.createReadStream("mydata.jsonl"),
                  purpose: "fine-tune",
                });

                console.log(file);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.create(
                file=open("mydata.jsonl", "rb"),
                purpose="fine-tune"
              )
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
        group: files
        name: Upload file
        returns: 'The uploaded [File](/docs/api-reference/files/object) object.'
  '/files/{file_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the file to use for this request.
          in: path
          name: file_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteFileResponse'
      tags:
        - Files
      operationId: deleteFile
      summary: Delete a file.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.del("file-abc123");

                console.log(file);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.delete("file-abc123")
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "deleted": true
            }
        group: files
        name: Delete file
        returns: Deletion status.
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the file to use for this request.
          in: path
          name: file_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/OpenAIFile'
      tags:
        - Files
      operationId: retrieveFile
      summary: Returns information about a specific file.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.retrieve("file-abc123");

                console.log(file);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.files.retrieve("file-abc123")
          response: |
            {
              "id": "file-abc123",
              "object": "file",
              "bytes": 120000,
              "created_at": 1677610602,
              "filename": "mydata.jsonl",
              "purpose": "fine-tune",
            }
        group: files
        name: Retrieve file
        returns: >-
          The [File](/docs/api-reference/files/object) object matching the
          specified ID.
  '/files/{file_id}/content':
    get:
      produces:
        - application/json
        - application/octet-stream
      parameters:
        - description: The ID of the file to use for this request.
          in: path
          name: file_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            type: string
      tags:
        - Files
      operationId: downloadFile
      summary: Returns the contents of the specified file.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/files/file-abc123/content \
                -H "Authorization: Bearer $OPENAI_API_KEY" > file.jsonl
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const file = await openai.files.content("file-abc123");

                console.log(file);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              content = client.files.content("file-abc123")
        group: files
        name: Retrieve file content
        returns: The file content.
  /fine_tuning/jobs:
    get:
      produces:
        - application/json
      parameters:
        - description: Identifier for the last job from the previous pagination request.
          in: query
          name: after
          required: false
          type: string
        - default: 20
          description: Number of fine-tuning jobs to retrieve.
          in: query
          name: limit
          required: false
          type: integer
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListPaginatedFineTuningJobsResponse'
      tags:
        - Fine-tuning
      operationId: listPaginatedFineTuningJobs
      summary: |
        List your organization's fine-tuning jobs
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/fine_tuning/jobs?limit=2 \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.jobs.list();

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list()
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-TjX0lMfOniCZX64t9PUQT5hn",
                  "created_at": 1689813489,
                  "level": "warn",
                  "message": "Fine tuning process stopping due to job cancellation",
                  "data": null,
                  "type": "message"
                },
                { ... },
                { ... }
              ], "has_more": true
            }
        group: fine-tuning
        name: List fine-tuning jobs
        returns: >-
          A list of paginated [fine-tuning
          job](/docs/api-reference/fine-tuning/object) objects.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateFineTuningJobRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/FineTuningJob'
      tags:
        - Fine-tuning
      operationId: createFineTuningJob
      summary: >
        Creates a fine-tuning job which begins the process of creating a new
        model from a given dataset.


        Response includes details of the enqueued job including job status and
        the name of the fine-tuned models once complete.


        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      x-oaiMeta:
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/fine_tuning/jobs \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "training_file": "file-BK7bzQj3FfZFXr7DbL6xJwfo",
                    "model": "gpt-3.5-turbo"
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const fineTune = await openai.fineTuning.jobs.create({
                    training_file: "file-abc123"
                  });

                  console.log(fineTune);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                client.fine_tuning.jobs.create(
                  training_file="file-abc123",
                  model="gpt-3.5-turbo"
                )
            response: |
              {
                "object": "fine_tuning.job",
                "id": "ftjob-abc123",
                "model": "gpt-3.5-turbo-0125",
                "created_at": 1614807352,
                "fine_tuned_model": null,
                "organization_id": "org-123",
                "result_files": [],
                "status": "queued",
                "validation_file": null,
                "training_file": "file-abc123",
              }
            title: Default
          - request:
              curl: |
                curl https://api.openai.com/v1/fine_tuning/jobs \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "training_file": "file-abc123",
                    "model": "gpt-3.5-turbo",
                    "hyperparameters": {
                      "n_epochs": 2
                    }
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const fineTune = await openai.fineTuning.jobs.create({
                    training_file: "file-abc123",
                    model: "gpt-3.5-turbo",
                    hyperparameters: { n_epochs: 2 }
                  });

                  console.log(fineTune);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                client.fine_tuning.jobs.create(
                  training_file="file-abc123",
                  model="gpt-3.5-turbo",
                  hyperparameters={
                    "n_epochs":2
                  }
                )
            response: |
              {
                "object": "fine_tuning.job",
                "id": "ftjob-abc123",
                "model": "gpt-3.5-turbo-0125",
                "created_at": 1614807352,
                "fine_tuned_model": null,
                "organization_id": "org-123",
                "result_files": [],
                "status": "queued",
                "validation_file": null,
                "training_file": "file-abc123",
                "hyperparameters": {"n_epochs": 2},
              }
            title: Epochs
          - request:
              curl: |
                curl https://api.openai.com/v1/fine_tuning/jobs \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "training_file": "file-abc123",
                    "validation_file": "file-abc123",
                    "model": "gpt-3.5-turbo"
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const fineTune = await openai.fineTuning.jobs.create({
                    training_file: "file-abc123",
                    validation_file: "file-abc123"
                  });

                  console.log(fineTune);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                client.fine_tuning.jobs.create(
                  training_file="file-abc123",
                  validation_file="file-def456",
                  model="gpt-3.5-turbo"
                )
            response: |
              {
                "object": "fine_tuning.job",
                "id": "ftjob-abc123",
                "model": "gpt-3.5-turbo-0125",
                "created_at": 1614807352,
                "fine_tuned_model": null,
                "organization_id": "org-123",
                "result_files": [],
                "status": "queued",
                "validation_file": "file-abc123",
                "training_file": "file-abc123",
              }
            title: Validation file
          - request:
              curl: |
                curl https://api.openai.com/v1/fine_tuning/jobs \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -d '{
                    "training_file": "file-abc123",
                    "validation_file": "file-abc123",
                    "model": "gpt-3.5-turbo",
                    "integrations": [
                      {
                        "type": "wandb",
                        "wandb": {
                          "project": "my-wandb-project",
                          "name": "ft-run-display-name"
                          "tags": [
                            "first-experiment", "v2"
                          ]
                        }
                      }
                    ]
                  }'
            response: |
              {
                "object": "fine_tuning.job",
                "id": "ftjob-abc123",
                "model": "gpt-3.5-turbo-0125",
                "created_at": 1614807352,
                "fine_tuned_model": null,
                "organization_id": "org-123",
                "result_files": [],
                "status": "queued",
                "validation_file": "file-abc123",
                "training_file": "file-abc123",
                "integrations": [
                  {
                    "type": "wandb",
                    "wandb": {
                      "project": "my-wandb-project",
                      "entity": None,
                      "run_id": "ftjob-abc123"
                    }
                  }
                ]
              }
            title: W&B Integration
        group: fine-tuning
        name: Create fine-tuning job
        returns: 'A [fine-tuning.job](/docs/api-reference/fine-tuning/object) object.'
  '/fine_tuning/jobs/{fine_tuning_job_id}':
    get:
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the fine-tuning job.
          in: path
          name: fine_tuning_job_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/FineTuningJob'
      tags:
        - Fine-tuning
      operationId: retrieveFineTuningJob
      summary: |
        Get info about a fine-tuning job.

        [Learn more about fine-tuning](/docs/guides/fine-tuning)
      x-oaiMeta:
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/fine_tuning/jobs/ft-AF1WoRqd3aJAHsqc9NY7iL8F
              \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.retrieve("ftjob-abc123");

                console.log(fineTune);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.retrieve("ftjob-abc123")
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "davinci-002",
              "created_at": 1692661014,
              "finished_at": 1692661190,
              "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
              "organization_id": "org-123",
              "result_files": [
                  "file-abc123"
              ],
              "status": "succeeded",
              "validation_file": null,
              "training_file": "file-abc123",
              "hyperparameters": {
                  "n_epochs": 4,
                  "batch_size": 1,
                  "learning_rate_multiplier": 1.0
              },
              "trained_tokens": 5768,
              "integrations": [],
              "seed": 0,
              "estimated_finish": 0
            }
        group: fine-tuning
        name: Retrieve fine-tuning job
        returns: >-
          The [fine-tuning](/docs/api-reference/fine-tuning/object) object with
          the given ID.
  '/fine_tuning/jobs/{fine_tuning_job_id}/cancel':
    post:
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the fine-tuning job to cancel.
          in: path
          name: fine_tuning_job_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/FineTuningJob'
      tags:
        - Fine-tuning
      operationId: cancelFineTuningJob
      summary: |
        Immediately cancel a fine-tune job.
      x-oaiMeta:
        examples:
          request:
            curl: >
              curl -X POST
              https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/cancel \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const fineTune = await openai.fineTuning.jobs.cancel("ftjob-abc123");

                console.log(fineTune);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.cancel("ftjob-abc123")
          response: |
            {
              "object": "fine_tuning.job",
              "id": "ftjob-abc123",
              "model": "gpt-3.5-turbo-0125",
              "created_at": 1689376978,
              "fine_tuned_model": null,
              "organization_id": "org-123",
              "result_files": [],
              "hyperparameters": {
                "n_epochs":  "auto"
              },
              "status": "cancelled",
              "validation_file": "file-abc123",
              "training_file": "file-abc123"
            }
        group: fine-tuning
        name: Cancel fine-tuning
        returns: >-
          The cancelled [fine-tuning](/docs/api-reference/fine-tuning/object)
          object.
  '/fine_tuning/jobs/{fine_tuning_job_id}/checkpoints':
    get:
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the fine-tuning job to get checkpoints for.
          in: path
          name: fine_tuning_job_id
          required: true
          type: string
        - description: >-
            Identifier for the last checkpoint ID from the previous pagination
            request.
          in: query
          name: after
          required: false
          type: string
        - default: 10
          description: Number of checkpoints to retrieve.
          in: query
          name: limit
          required: false
          type: integer
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListFineTuningJobCheckpointsResponse'
      tags:
        - Fine-tuning
      operationId: listFineTuningJobCheckpoints
      summary: |
        List checkpoints for a fine-tuning job.
      x-oaiMeta:
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/checkpoints
              \
                -H "Authorization: Bearer $OPENAI_API_KEY"
          response: |
            {
              "object": "list"
              "data": [
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
                  "created_at": 1519129973,
                  "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom-suffix:96olL566:ckpt-step-2000",
                  "metrics": {
                    "full_valid_loss": 0.134,
                    "full_valid_mean_token_accuracy": 0.874
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 2000,
                },
                {
                  "object": "fine_tuning.job.checkpoint",
                  "id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
                  "created_at": 1519129833,
                  "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom-suffix:7q8mpxmy:ckpt-step-1000",
                  "metrics": {
                    "full_valid_loss": 0.167,
                    "full_valid_mean_token_accuracy": 0.781
                  },
                  "fine_tuning_job_id": "ftjob-abc123",
                  "step_number": 1000,
                },
              ],
              "first_id": "ftckpt_zc4Q7MP6XxulcVzj4MZdwsAB",
              "last_id": "ftckpt_enQCFmOTGj3syEpYVhBRLTSy",
              "has_more": true
            }
        group: fine-tuning
        name: List fine-tuning checkpoints
        returns: >-
          A list of fine-tuning [checkpoint
          objects](/docs/api-reference/fine-tuning/checkpoint-object) for a
          fine-tuning job.
  '/fine_tuning/jobs/{fine_tuning_job_id}/events':
    get:
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the fine-tuning job to get events for.
          in: path
          name: fine_tuning_job_id
          required: true
          type: string
        - description: Identifier for the last event from the previous pagination request.
          in: query
          name: after
          required: false
          type: string
        - default: 20
          description: Number of events to retrieve.
          in: query
          name: limit
          required: false
          type: integer
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListFineTuningJobEventsResponse'
      tags:
        - Fine-tuning
      operationId: listFineTuningEvents
      summary: |
        Get status updates for a fine-tuning job.
      x-oaiMeta:
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/fine_tuning/jobs/ftjob-abc123/events \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.fineTuning.list_events(id="ftjob-abc123", limit=2);

                for await (const fineTune of list) {
                  console.log(fineTune);
                }
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.fine_tuning.jobs.list_events(
                fine_tuning_job_id="ftjob-abc123",
                limit=2
              )
          response: |
            {
              "object": "list",
              "data": [
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-ddTJfwuMVpfLXseO0Am0Gqjm",
                  "created_at": 1692407401,
                  "level": "info",
                  "message": "Fine tuning job successfully completed",
                  "data": null,
                  "type": "message"
                },
                {
                  "object": "fine_tuning.job.event",
                  "id": "ft-event-tyiGuB72evQncpH87xe505Sv",
                  "created_at": 1692407400,
                  "level": "info",
                  "message": "New fine-tuned model created: ft:gpt-3.5-turbo:openai::7p4lURel",
                  "data": null,
                  "type": "message"
                }
              ],
              "has_more": true
            }
        group: fine-tuning
        name: List fine-tuning events
        returns: A list of fine-tuning event objects.
  /images/edits:
    post:
      consumes:
        - multipart/form-data
      produces:
        - application/json
      parameters:
        - description: >-
            The image to edit. Must be a valid PNG file, less than 4MB, and
            square. If mask is not provided, image must have transparency, which
            will be used as the mask.
          format: binary
          in: formData
          name: image
          required: true
          type: string
        - description: >-
            A text description of the desired image(s). The maximum length is
            1000 characters.
          in: formData
          name: prompt
          required: true
          type: string
        - description: >-
            An additional image whose fully transparent areas (e.g. where alpha
            is zero) indicate where `image` should be edited. Must be a valid
            PNG file, less than 4MB, and have the same dimensions as `image`.
          format: binary
          in: formData
          name: mask
          type: string
        - default: dall-e-2
          description: >-
            The model to use for image generation. Only `dall-e-2` is supported
            at this time.
          in: formData
          name: model
          x-nullable: true
          x-oaiTypeLabel: string
        - default: 1
          description: The number of images to generate. Must be between 1 and 10.
          in: formData
          maximum: 10
          minimum: 1
          name: 'n'
          type: integer
          x-nullable: true
        - default: 1024x1024
          description: >-
            The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          in: formData
          name: size
          type: string
          x-nullable: true
        - default: url
          description: >-
            The format in which the generated images are returned. Must be one
            of `url` or `b64_json`. URLs are only valid for 60 minutes after the
            image has been generated.
          enum:
            - url
            - b64_json
          in: formData
          name: response_format
          type: string
          x-nullable: true
        - description: >
            A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect abuse. [Learn
            more](/docs/guides/safety-best-practices/end-user-ids).
          in: formData
          name: user
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ImagesResponse'
      tags:
        - Images
      operationId: createImageEdit
      summary: >-
        Creates an edited or extended image given an original image and a
        prompt.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/edits \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F mask="@mask.png" \
                -F prompt="A cute baby sea otter wearing a beret" \
                -F n=2 \
                -F size="1024x1024"
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.edit({
                  image: fs.createReadStream("otter.png"),
                  mask: fs.createReadStream("mask.png"),
                  prompt: "A cute baby sea otter wearing a beret",
                });

                console.log(image.data);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.edit(
                image=open("otter.png", "rb"),
                mask=open("mask.png", "rb"),
                prompt="A cute baby sea otter wearing a beret",
                n=2,
                size="1024x1024"
              )
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
        group: images
        name: Create image edit
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
  /images/generations:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateImageRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ImagesResponse'
      tags:
        - Images
      operationId: createImage
      summary: Creates an image given a prompt.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/generations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "model": "dall-e-3",
                  "prompt": "A cute baby sea otter",
                  "n": 1,
                  "size": "1024x1024"
                }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.generate({ model: "dall-e-3", prompt: "A cute baby sea otter" });

                console.log(image.data);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.images.generate(
                model="dall-e-3",
                prompt="A cute baby sea otter",
                n=1,
                size="1024x1024"
              )
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
        group: images
        name: Create image
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
  /images/variations:
    post:
      consumes:
        - multipart/form-data
      produces:
        - application/json
      parameters:
        - description: >-
            The image to use as the basis for the variation(s). Must be a valid
            PNG file, less than 4MB, and square.
          format: binary
          in: formData
          name: image
          required: true
          type: string
        - default: dall-e-2
          description: >-
            The model to use for image generation. Only `dall-e-2` is supported
            at this time.
          in: formData
          name: model
          x-nullable: true
          x-oaiTypeLabel: string
        - default: 1
          description: >-
            The number of images to generate. Must be between 1 and 10. For
            `dall-e-3`, only `n=1` is supported.
          in: formData
          maximum: 10
          minimum: 1
          name: 'n'
          type: integer
          x-nullable: true
        - default: url
          description: >-
            The format in which the generated images are returned. Must be one
            of `url` or `b64_json`. URLs are only valid for 60 minutes after the
            image has been generated.
          enum:
            - url
            - b64_json
          in: formData
          name: response_format
          type: string
          x-nullable: true
        - default: 1024x1024
          description: >-
            The size of the generated images. Must be one of `256x256`,
            `512x512`, or `1024x1024`.
          enum:
            - 256x256
            - 512x512
            - 1024x1024
          in: formData
          name: size
          type: string
          x-nullable: true
        - description: >
            A unique identifier representing your end-user, which can help
            OpenAI to monitor and detect abuse. [Learn
            more](/docs/guides/safety-best-practices/end-user-ids).
          in: formData
          name: user
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ImagesResponse'
      tags:
        - Images
      operationId: createImageVariation
      summary: Creates a variation of a given image.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/images/variations \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -F image="@otter.png" \
                -F n=2 \
                -F size="1024x1024"
            node.js: |-
              import fs from "fs";
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const image = await openai.images.createVariation({
                  image: fs.createReadStream("otter.png"),
                });

                console.log(image.data);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.images.create_variation(
                image=open("image_edit_original.png", "rb"),
                n=2,
                size="1024x1024"
              )
          response: |
            {
              "created": 1589478378,
              "data": [
                {
                  "url": "https://..."
                },
                {
                  "url": "https://..."
                }
              ]
            }
        group: images
        name: Create image variation
        returns: 'Returns a list of [image](/docs/api-reference/images/object) objects.'
  /models:
    get:
      produces:
        - application/json
      parameters: []
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListModelsResponse'
      tags:
        - Models
      operationId: listModels
      summary: >-
        Lists the currently available models, and provides basic information
        about each one such as the owner and availability.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const list = await openai.models.list();

                for await (const model of list) {
                  console.log(model);
                }
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.list()
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "model-id-0",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner"
                },
                {
                  "id": "model-id-1",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "organization-owner",
                },
                {
                  "id": "model-id-2",
                  "object": "model",
                  "created": 1686935002,
                  "owned_by": "openai"
                },
              ],
              "object": "list"
            }
        group: models
        name: List models
        returns: 'A list of [model](/docs/api-reference/models/object) objects.'
  '/models/{model}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The model to delete
          in: path
          name: model
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteModelResponse'
      tags:
        - Models
      operationId: deleteModel
      summary: >-
        Delete a fine-tuned model. You must have the Owner role in your
        organization to delete a model.
      x-oaiMeta:
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/models/ft:gpt-3.5-turbo:acemeco:suffix:abc123
              \
                -X DELETE \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.del("ft:gpt-3.5-turbo:acemeco:suffix:abc123");

                console.log(model);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.delete("ft:gpt-3.5-turbo:acemeco:suffix:abc123")
          response: |
            {
              "id": "ft:gpt-3.5-turbo:acemeco:suffix:abc123",
              "object": "model",
              "deleted": true
            }
        group: models
        name: Delete a fine-tuned model
        returns: Deletion status.
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the model to use for this request
          in: path
          name: model
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/Model'
      tags:
        - Models
      operationId: retrieveModel
      summary: >-
        Retrieves a model instance, providing basic information about the model
        such as the owner and permissioning.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/models/VAR_model_id \
                -H "Authorization: Bearer $OPENAI_API_KEY"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const model = await openai.models.retrieve("VAR_model_id");

                console.log(model);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              client.models.retrieve("VAR_model_id")
          response: |
            {
              "id": "VAR_model_id",
              "object": "model",
              "created": 1686935002,
              "owned_by": "openai"
            }
        group: models
        name: Retrieve model
        returns: >-
          The [model](/docs/api-reference/models/object) object matching the
          specified ID.
  /moderations:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateModerationRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/CreateModerationResponse'
      tags:
        - Moderations
      operationId: createModeration
      summary: Classifies if text is potentially harmful.
      x-oaiMeta:
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/moderations \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -d '{
                  "input": "I want to kill them."
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const moderation = await openai.moderations.create({ input: "I want to kill them." });

                console.log(moderation);
              }
              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              moderation = client.moderations.create(input="I want to kill
              them.")

              print(moderation)
          response: |
            {
              "id": "modr-XXXXX",
              "model": "text-moderation-005",
              "results": [
                {
                  "flagged": true,
                  "categories": {
                    "sexual": false,
                    "hate": false,
                    "harassment": false,
                    "self-harm": false,
                    "sexual/minors": false,
                    "hate/threatening": false,
                    "violence/graphic": false,
                    "self-harm/intent": false,
                    "self-harm/instructions": false,
                    "harassment/threatening": true,
                    "violence": true,
                  },
                  "category_scores": {
                    "sexual": 1.2282071e-06,
                    "hate": 0.010696256,
                    "harassment": 0.29842457,
                    "self-harm": 1.5236925e-08,
                    "sexual/minors": 5.7246268e-08,
                    "hate/threatening": 0.0060676364,
                    "violence/graphic": 4.435014e-06,
                    "self-harm/intent": 8.098441e-10,
                    "self-harm/instructions": 2.8498655e-11,
                    "harassment/threatening": 0.63055265,
                    "violence": 0.99011886,
                  }
                }
              ]
            }
        group: moderations
        name: Create moderation
        returns: 'A [moderation](/docs/api-reference/moderations/object) object.'
  /threads:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          schema:
            $ref: '#/definitions/CreateThreadRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ThreadObject'
      tags:
        - Assistants
      operationId: createThread
      summary: Create a thread.
      x-oaiMeta:
        beta: true
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/threads \
                  -H "Content-Type: application/json" \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d ''
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const emptyThread = await openai.beta.threads.create();

                  console.log(emptyThread);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                empty_thread = client.beta.threads.create()
                print(empty_thread)
            response: |
              {
                "id": "thread_abc123",
                "object": "thread",
                "created_at": 1699012949,
                "metadata": {},
                "tool_resources": {}
              }
            title: Empty
          - request:
              curl: |
                curl https://api.openai.com/v1/threads \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "messages": [{
                      "role": "user",
                      "content": "Hello, what is AI?"
                    }, {
                      "role": "user",
                      "content": "How does AI work? Explain it in simple terms."
                    }]
                  }'
              node.js: |-
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const messageThread = await openai.beta.threads.create({
                    messages: [
                      {
                        role: "user",
                        content: "Hello, what is AI?"
                      },
                      {
                        role: "user",
                        content: "How does AI work? Explain it in simple terms.",
                      },
                    ],
                  });

                  console.log(messageThread);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                message_thread = client.beta.threads.create(
                  messages=[
                    {
                      "role": "user",
                      "content": "Hello, what is AI?"
                    },
                    {
                      "role": "user",
                      "content": "How does AI work? Explain it in simple terms."
                    },
                  ]
                )

                print(message_thread)
            response: |
              {
                "id": "thread_abc123",
                "object": "thread",
                "created_at": 1699014083,
                "metadata": {},
                "tool_resources": {}
              }
            title: Messages
        group: threads
        name: Create thread
        returns: 'A [thread](/docs/api-reference/threads) object.'
  /threads/runs:
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateThreadAndRunRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: createThreadAndRun
      summary: Create a thread and run it in one request.
      x-oaiMeta:
        beta: true
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                      "assistant_id": "asst_abc123",
                      "thread": {
                        "messages": [
                          {"role": "user", "content": "Explain deep learning to a 5 year old."}
                        ]
                      }
                    }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const run = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_abc123",
                    thread: {
                      messages: [
                        { role: "user", content: "Explain deep learning to a 5 year old." },
                      ],
                    },
                  });

                  console.log(run);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                run = client.beta.threads.create_and_run(
                  assistant_id="asst_abc123",
                  thread={
                    "messages": [
                      {"role": "user", "content": "Explain deep learning to a 5 year old."}
                    ]
                  }
                )

                print(run)
            response: |
              {
                "id": "run_abc123",
                "object": "thread.run",
                "created_at": 1699076792,
                "assistant_id": "asst_abc123",
                "thread_id": "thread_abc123",
                "status": "queued",
                "started_at": null,
                "expires_at": 1699077392,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": null,
                "required_action": null,
                "last_error": null,
                "model": "gpt-4-turbo",
                "instructions": "You are a helpful assistant.",
                "tools": [],
                "tool_resources": {},
                "metadata": {},
                "temperature": 1.0,
                "top_p": 1.0,
                "max_completion_tokens": null,
                "max_prompt_tokens": null,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "incomplete_details": null,
                "usage": null,
                "response_format": "auto",
                "tool_choice": "auto"
              }
            title: Default
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "Hello"}
                      ]
                    },
                    "stream": true
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const stream = await openai.beta.threads.createAndRun({
                      assistant_id: "asst_123",
                      thread: {
                        messages: [
                          { role: "user", content: "Hello" },
                        ],
                      },
                      stream: true
                  });

                  for await (const event of stream) {
                    console.log(event);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                stream = client.beta.threads.create_and_run(
                  assistant_id="asst_123",
                  thread={
                    "messages": [
                      {"role": "user", "content": "Hello"}
                    ]
                  },
                  stream=True
                )

                for event in stream:
                  print(event)
            response: >
              event: thread.created

              data:
              {"id":"thread_123","object":"thread","created_at":1710348075,"metadata":{}}


              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"tool_resources":{},"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
              "metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],
              "metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}], "metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              {"id":"run_123","object":"thread.run","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1713226836,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1713226837,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto"}


              event: done

              data: [DONE]
            title: Streaming
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123",
                    "thread": {
                      "messages": [
                        {"role": "user", "content": "What is the weather like in San Francisco?"}
                      ]
                    },
                    "tools": [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "description": "Get the current weather in a given location",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                "type": "string",
                                "enum": ["celsius", "fahrenheit"]
                              }
                            },
                            "required": ["location"]
                          }
                        }
                      }
                    ],
                    "stream": true
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                async function main() {
                  const stream = await openai.beta.threads.createAndRun({
                    assistant_id: "asst_123",
                    thread: {
                      messages: [
                        { role: "user", content: "What is the weather like in San Francisco?" },
                      ],
                    },
                    tools: tools,
                    stream: true
                  });

                  for await (const event of stream) {
                    console.log(event);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
                ]

                stream = client.beta.threads.create_and_run(
                  thread={
                      "messages": [
                        {"role": "user", "content": "What is the weather like in San Francisco?"}
                      ]
                  },
                  assistant_id="asst_abc123",
                  tools=tools,
                  stream=True
                )

                for event in stream:
                  print(event)
            response: >
              event: thread.created

              data:
              {"id":"thread_123","object":"thread","created_at":1710351818,"metadata":{}}


              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710351819,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710352418,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[]},"usage":null}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"","output":null}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"{\""}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"location"}}]}}}


              ...


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"ahrenheit"}}]}}}


              event: thread.run.step.delta

              data:
              {"id":"step_001","object":"thread.run.step.delta","delta":{"step_details":{"type":"tool_calls","tool_calls":[{"index":0,"type":"function","function":{"arguments":"\"}"}}]}}}


              event: thread.run.requires_action

              data:
              {"id":"run_123","object":"thread.run","created_at":1710351818,"assistant_id":"asst_123","thread_id":"thread_123","status":"requires_action","started_at":1710351818,"expires_at":1710352418,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":{"type":"submit_tool_outputs","submit_tool_outputs":{"tool_calls":[{"id":"call_XXNp8YGaFrjrSjgqxtC8JJ1B","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
              Francisco,
              CA\",\"unit\":\"fahrenheit\"}"}}]}},"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":345,"completion_tokens":11,"total_tokens":356},"response_format":"auto","tool_choice":"auto"}}


              event: done

              data: [DONE]
            title: Streaming with Functions
        group: threads
        name: Create thread and run
        returns: 'A [run](/docs/api-reference/runs/object) object.'
  '/threads/{thread_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to delete.
          in: path
          name: thread_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteThreadResponse'
      tags:
        - Assistants
      operationId: deleteThread
      summary: Delete a thread.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const response = await openai.beta.threads.del("thread_abc123");

                console.log(response);
              }
              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              response = client.beta.threads.delete("thread_abc123")
              print(response)
          response: |
            {
              "id": "thread_abc123",
              "object": "thread.deleted",
              "deleted": true
            }
        group: threads
        name: Delete thread
        returns: Deletion status
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to retrieve.
          in: path
          name: thread_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ThreadObject'
      tags:
        - Assistants
      operationId: getThread
      summary: Retrieves a thread.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const myThread = await openai.beta.threads.retrieve(
                  "thread_abc123"
                );

                console.log(myThread);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_thread = client.beta.threads.retrieve("thread_abc123")
              print(my_thread)
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {},
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": []
                }
              }
            }
        group: threads
        name: Retrieve thread
        returns: >-
          The [thread](/docs/api-reference/threads/object) object matching the
          specified ID.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to modify. Only the `metadata` can be modified.
          in: path
          name: thread_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/ModifyThreadRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ThreadObject'
      tags:
        - Assistants
      operationId: modifyThread
      summary: Modifies a thread.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123 \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const updatedThread = await openai.beta.threads.update(
                  "thread_abc123",
                  {
                    metadata: { modified: "true", user: "abc123" },
                  }
                );

                console.log(updatedThread);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              my_updated_thread = client.beta.threads.update(
                "thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123"
                }
              )
              print(my_updated_thread)
          response: |
            {
              "id": "thread_abc123",
              "object": "thread",
              "created_at": 1699014083,
              "metadata": {
                "modified": "true",
                "user": "abc123"
              },
              "tool_resources": {}
            }
        group: threads
        name: Modify thread
        returns: >-
          The modified [thread](/docs/api-reference/threads/object) object
          matching the specified ID.
  '/threads/{thread_id}/messages':
    get:
      produces:
        - application/json
      parameters:
        - description: >-
            The ID of the [thread](/docs/api-reference/threads) the messages
            belong to.
          in: path
          name: thread_id
          required: true
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
        - description: |
            Filter messages by the run ID that generated them.
          in: query
          name: run_id
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListMessagesResponse'
      tags:
        - Assistants
      operationId: listMessages
      summary: Returns a list of messages for a given thread.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.list(
                  "thread_abc123"
                );

                console.log(threadMessages.data);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              thread_messages =
              client.beta.threads.messages.list("thread_abc123")

              print(thread_messages.data)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "msg_abc123",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "How does AI work? Explain it in simple terms.",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                },
                {
                  "id": "msg_abc456",
                  "object": "thread.message",
                  "created_at": 1699016383,
                  "assistant_id": null,
                  "thread_id": "thread_abc123",
                  "run_id": null,
                  "role": "user",
                  "content": [
                    {
                      "type": "text",
                      "text": {
                        "value": "Hello, what is AI?",
                        "annotations": []
                      }
                    }
                  ],
                  "attachments": [],
                  "metadata": {}
                }
              ],
              "first_id": "msg_abc123",
              "last_id": "msg_abc456",
              "has_more": false
            }
        group: threads
        name: List messages
        returns: 'A list of [message](/docs/api-reference/messages) objects.'
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: >-
            The ID of the [thread](/docs/api-reference/threads) to create a
            message for.
          in: path
          name: thread_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateMessageRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/MessageObject'
      tags:
        - Assistants
      operationId: createMessage
      summary: Create a message.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/messages \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "role": "user",
                    "content": "How does AI work? Explain it in simple terms."
                  }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const threadMessages = await openai.beta.threads.messages.create(
                  "thread_abc123",
                  { role: "user", content: "How does AI work? Explain it in simple terms." }
                );

                console.log(threadMessages);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              thread_message = client.beta.threads.messages.create(
                "thread_abc123",
                role="user",
                content="How does AI work? Explain it in simple terms.",
              )
              print(thread_message)
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1713226573,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
        group: threads
        name: Create message
        returns: 'A [message](/docs/api-reference/messages/object) object.'
  '/threads/{thread_id}/messages/{message_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to which this message belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the message to delete.
          in: path
          name: message_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteMessageResponse'
      tags:
        - Assistants
      operationId: deleteMessage
      summary: Deletes a message.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl -X DELETE
              https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123
              \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const deletedMessage = await openai.beta.threads.messages.del(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(deletedMessage);
              }
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_message = client.beta.threads.messages.delete(
                message_id="msg_abc12",
                thread_id="thread_abc123",
              )
              print(deleted_message)
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message.deleted",
              "deleted": true
            }
        group: threads
        name: Delete message
        returns: Deletion status
    get:
      produces:
        - application/json
      parameters:
        - description: >-
            The ID of the [thread](/docs/api-reference/threads) to which this
            message belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the message to retrieve.
          in: path
          name: message_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/MessageObject'
      tags:
        - Assistants
      operationId: getMessage
      summary: Retrieve a message.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123
              \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.retrieve(
                  "thread_abc123",
                  "msg_abc123"
                );

                console.log(message);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.retrieve(
                message_id="msg_abc123",
                thread_id="thread_abc123",
              )
              print(message)
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "attachments": [],
              "metadata": {}
            }
        group: threads
        name: Retrieve message
        returns: >-
          The [message](/docs/api-reference/threads/messages/object) object
          matching the specified ID.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to which this message belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the message to modify.
          in: path
          name: message_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/ModifyMessageRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/MessageObject'
      tags:
        - Assistants
      operationId: modifyMessage
      summary: Modifies a message.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/messages/msg_abc123
              \
                -H "Content-Type: application/json" \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                    "metadata": {
                      "modified": "true",
                      "user": "abc123"
                    }
                  }'
            node.js: |-
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const message = await openai.beta.threads.messages.update(
                  "thread_abc123",
                  "msg_abc123",
                  {
                    metadata: {
                      modified: "true",
                      user: "abc123",
                    },
                  }
                }'
            python: |
              from openai import OpenAI
              client = OpenAI()

              message = client.beta.threads.messages.update(
                message_id="msg_abc12",
                thread_id="thread_abc123",
                metadata={
                  "modified": "true",
                  "user": "abc123",
                },
              )
              print(message)
          response: |
            {
              "id": "msg_abc123",
              "object": "thread.message",
              "created_at": 1699017614,
              "assistant_id": null,
              "thread_id": "thread_abc123",
              "run_id": null,
              "role": "user",
              "content": [
                {
                  "type": "text",
                  "text": {
                    "value": "How does AI work? Explain it in simple terms.",
                    "annotations": []
                  }
                }
              ],
              "file_ids": [],
              "metadata": {
                "modified": "true",
                "user": "abc123"
              }
            }
        group: threads
        name: Modify message
        returns: >-
          The modified [message](/docs/api-reference/threads/messages/object)
          object.
  '/threads/{thread_id}/runs':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread the run belongs to.
          in: path
          name: thread_id
          required: true
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListRunsResponse'
      tags:
        - Assistants
      operationId: listRuns
      summary: Returns a list of runs belonging to a thread.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/threads/thread_abc123/runs \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const runs = await openai.beta.threads.runs.list(
                  "thread_abc123"
                );

                console.log(runs);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              runs = client.beta.threads.runs.list(
                "thread_abc123"
              )

              print(runs)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "run_abc123",
                  "object": "thread.run",
                  "created_at": 1699075072,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699075072,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699075073,
                  "last_error": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto"
                },
                {
                  "id": "run_abc456",
                  "object": "thread.run",
                  "created_at": 1699063290,
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "status": "completed",
                  "started_at": 1699063290,
                  "expires_at": null,
                  "cancelled_at": null,
                  "failed_at": null,
                  "completed_at": 1699063291,
                  "last_error": null,
                  "model": "gpt-4-turbo",
                  "instructions": null,
                  "incomplete_details": null,
                  "tools": [
                    {
                      "type": "code_interpreter"
                    }
                  ],
                  "tool_resources": {
                    "code_interpreter": {
                      "file_ids": [
                        "file-abc123",
                        "file-abc456"
                      ]
                    }
                  },
                  "metadata": {},
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  },
                  "temperature": 1.0,
                  "top_p": 1.0,
                  "max_prompt_tokens": 1000,
                  "max_completion_tokens": 1000,
                  "truncation_strategy": {
                    "type": "auto",
                    "last_messages": null
                  },
                  "response_format": "auto",
                  "tool_choice": "auto"
                }
              ],
              "first_id": "run_abc123",
              "last_id": "run_abc456",
              "has_more": false
            }
        group: threads
        name: List runs
        returns: 'A list of [run](/docs/api-reference/runs/object) objects.'
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to run.
          in: path
          name: thread_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateRunRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: createRun
      summary: Create a run.
      x-oaiMeta:
        beta: true
        examples:
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_abc123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123"
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const run = await openai.beta.threads.runs.create(
                    "thread_abc123",
                    { assistant_id: "asst_abc123" }
                  );

                  console.log(run);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                run = client.beta.threads.runs.create(
                  thread_id="thread_abc123",
                  assistant_id="asst_abc123"
                )

                print(run)
            response: |
              {
                "id": "run_abc123",
                "object": "thread.run",
                "created_at": 1699063290,
                "assistant_id": "asst_abc123",
                "thread_id": "thread_abc123",
                "status": "queued",
                "started_at": 1699063290,
                "expires_at": null,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": 1699063291,
                "last_error": null,
                "model": "gpt-4-turbo",
                "instructions": null,
                "incomplete_details": null,
                "tools": [
                  {
                    "type": "code_interpreter"
                  }
                ],
                "metadata": {},
                "usage": null,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_prompt_tokens": 1000,
                "max_completion_tokens": 1000,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "response_format": "auto",
                "tool_choice": "auto"
              }
            title: Default
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_123",
                    "stream": true
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const stream = await openai.beta.threads.runs.create(
                    "thread_123",
                    { assistant_id: "asst_123", stream: true }
                  );

                  for await (const event of stream) {
                    console.log(event);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                stream = client.beta.threads.runs.create(
                  thread_id="thread_123",
                  assistant_id="asst_123",
                  stream=True
                )

                for event in stream:
                  print(event)
            response: >
              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710330641,"expires_at":1710331240,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710330641,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710330642,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710330641,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710330642,"expires_at":1710331240,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710330640,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710330641,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710330642,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto"}}


              event: done

              data: [DONE]
            title: Streaming
          - request:
              curl: |
                curl https://api.openai.com/v1/threads/thread_abc123/runs \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "assistant_id": "asst_abc123",
                    "tools": [
                      {
                        "type": "function",
                        "function": {
                          "name": "get_current_weather",
                          "description": "Get the current weather in a given location",
                          "parameters": {
                            "type": "object",
                            "properties": {
                              "location": {
                                "type": "string",
                                "description": "The city and state, e.g. San Francisco, CA"
                              },
                              "unit": {
                                "type": "string",
                                "enum": ["celsius", "fahrenheit"]
                              }
                            },
                            "required": ["location"]
                          }
                        }
                      }
                    ],
                    "stream": true
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                const tools = [
                    {
                      "type": "function",
                      "function": {
                        "name": "get_current_weather",
                        "description": "Get the current weather in a given location",
                        "parameters": {
                          "type": "object",
                          "properties": {
                            "location": {
                              "type": "string",
                              "description": "The city and state, e.g. San Francisco, CA",
                            },
                            "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                          },
                          "required": ["location"],
                        },
                      }
                    }
                ];

                async function main() {
                  const stream = await openai.beta.threads.runs.create(
                    "thread_abc123",
                    {
                      assistant_id: "asst_abc123",
                      tools: tools,
                      stream: true
                    }
                  );

                  for await (const event of stream) {
                    console.log(event);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                tools = [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA",
                          },
                          "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                        },
                        "required": ["location"],
                      },
                    }
                  }
                ]

                stream = client.beta.threads.runs.create(
                  thread_id="thread_abc123",
                  assistant_id="asst_abc123",
                  tools=tools,
                  stream=True
                )

                for event in stream:
                  print(event)
            response: >
              event: thread.run.created

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":null,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710348075,"expires_at":1710348675,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.step.created

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"Hello","annotations":[]}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              today"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_001","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"?"}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_001","object":"thread.message","created_at":1710348076,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710348077,"role":"assistant","content":[{"type":"text","text":{"value":"Hello!
              How can I assist you today?","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710348076,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710348077,"expires_at":1710348675,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_001"}},"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710348075,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710348075,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710348077,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto"}}


              event: done

              data: [DONE]
            title: Streaming with Functions
        group: threads
        name: Create run
        returns: 'A [run](/docs/api-reference/runs/object) object.'
  '/threads/{thread_id}/runs/{run_id}':
    get:
      produces:
        - application/json
      parameters:
        - description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run to retrieve.
          in: path
          name: run_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: getRun
      summary: Retrieves a run.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.retrieve(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.retrieve(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "metadata": {},
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto"
            }
        group: threads
        name: Retrieve run
        returns: >-
          The [run](/docs/api-reference/runs/object) object matching the
          specified ID.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run to modify.
          in: path
          name: run_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/ModifyRunRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: modifyRun
      summary: Modifies a run.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -d '{
                  "metadata": {
                    "user_id": "user_abc123"
                  }
                }'
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.update(
                  "thread_abc123",
                  "run_abc123",
                  {
                    metadata: {
                      user_id: "user_abc123",
                    },
                  }
                );

                console.log(run);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.update(
                thread_id="thread_abc123",
                run_id="run_abc123",
                metadata={"user_id": "user_abc123"},
              )

              print(run)
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699075072,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "completed",
              "started_at": 1699075072,
              "expires_at": null,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": 1699075073,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "incomplete_details": null,
              "tools": [
                {
                  "type": "code_interpreter"
                }
              ],
              "tool_resources": {
                "code_interpreter": {
                  "file_ids": [
                    "file-abc123",
                    "file-abc456"
                  ]
                }
              },
              "metadata": {
                "user_id": "user_abc123"
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              },
              "temperature": 1.0,
              "top_p": 1.0,
              "max_prompt_tokens": 1000,
              "max_completion_tokens": 1000,
              "truncation_strategy": {
                "type": "auto",
                "last_messages": null
              },
              "response_format": "auto",
              "tool_choice": "auto"
            }
        group: threads
        name: Modify run
        returns: >-
          The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  '/threads/{thread_id}/runs/{run_id}/cancel':
    post:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to which this run belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run to cancel.
          in: path
          name: run_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: cancelRun
      summary: Cancels a run that is `in_progress`.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/cancel
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            node.js: |
              import OpenAI from "openai";

              const openai = new OpenAI();

              async function main() {
                const run = await openai.beta.threads.runs.cancel(
                  "thread_abc123",
                  "run_abc123"
                );

                console.log(run);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              run = client.beta.threads.runs.cancel(
                thread_id="thread_abc123",
                run_id="run_abc123"
              )

              print(run)
          response: |
            {
              "id": "run_abc123",
              "object": "thread.run",
              "created_at": 1699076126,
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "status": "cancelling",
              "started_at": 1699076126,
              "expires_at": 1699076726,
              "cancelled_at": null,
              "failed_at": null,
              "completed_at": null,
              "last_error": null,
              "model": "gpt-4-turbo",
              "instructions": "You summarize books.",
              "tools": [
                {
                  "type": "file_search"
                }
              ],
              "tool_resources": {
                "file_search": {
                  "vector_store_ids": ["vs_123"]
                }
              },
              "metadata": {},
              "usage": null,
              "temperature": 1.0,
              "top_p": 1.0,
              "response_format": "auto"
            }
        group: threads
        name: Cancel a run
        returns: >-
          The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  '/threads/{thread_id}/runs/{run_id}/steps':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread the run and run steps belong to.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run the run steps belong to.
          in: path
          name: run_id
          required: true
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListRunStepsResponse'
      tags:
        - Assistants
      operationId: listRunSteps
      summary: Returns a list of run steps belonging to a run.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.list(
                  "thread_abc123",
                  "run_abc123"
                );
                console.log(runStep);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_steps = client.beta.threads.runs.steps.list(
                  thread_id="thread_abc123",
                  run_id="run_abc123"
              )

              print(run_steps)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "step_abc123",
                  "object": "thread.run.step",
                  "created_at": 1699063291,
                  "run_id": "run_abc123",
                  "assistant_id": "asst_abc123",
                  "thread_id": "thread_abc123",
                  "type": "message_creation",
                  "status": "completed",
                  "cancelled_at": null,
                  "completed_at": 1699063291,
                  "expired_at": null,
                  "failed_at": null,
                  "last_error": null,
                  "step_details": {
                    "type": "message_creation",
                    "message_creation": {
                      "message_id": "msg_abc123"
                    }
                  },
                  "usage": {
                    "prompt_tokens": 123,
                    "completion_tokens": 456,
                    "total_tokens": 579
                  }
                }
              ],
              "first_id": "step_abc123",
              "last_id": "step_abc456",
              "has_more": false
            }
        group: threads
        name: List run steps
        returns: 'A list of [run step](/docs/api-reference/runs/step-object) objects.'
  '/threads/{thread_id}/runs/{run_id}/steps/{step_id}':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the thread to which the run and run step belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run to which the run step belongs.
          in: path
          name: run_id
          required: true
          type: string
        - description: The ID of the run step to retrieve.
          in: path
          name: step_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunStepObject'
      tags:
        - Assistants
      operationId: getRunStep
      summary: Retrieves a run step.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/threads/thread_abc123/runs/run_abc123/steps/step_abc123
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const runStep = await openai.beta.threads.runs.steps.retrieve(
                  "thread_abc123",
                  "run_abc123",
                  "step_abc123"
                );
                console.log(runStep);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              run_step = client.beta.threads.runs.steps.retrieve(
                  thread_id="thread_abc123",
                  run_id="run_abc123",
                  step_id="step_abc123"
              )

              print(run_step)
          response: |
            {
              "id": "step_abc123",
              "object": "thread.run.step",
              "created_at": 1699063291,
              "run_id": "run_abc123",
              "assistant_id": "asst_abc123",
              "thread_id": "thread_abc123",
              "type": "message_creation",
              "status": "completed",
              "cancelled_at": null,
              "completed_at": 1699063291,
              "expired_at": null,
              "failed_at": null,
              "last_error": null,
              "step_details": {
                "type": "message_creation",
                "message_creation": {
                  "message_id": "msg_abc123"
                }
              },
              "usage": {
                "prompt_tokens": 123,
                "completion_tokens": 456,
                "total_tokens": 579
              }
            }
        group: threads
        name: Retrieve run step
        returns: >-
          The [run step](/docs/api-reference/runs/step-object) object matching
          the specified ID.
  '/threads/{thread_id}/runs/{run_id}/submit_tool_outputs':
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: >-
            The ID of the [thread](/docs/api-reference/threads) to which this
            run belongs.
          in: path
          name: thread_id
          required: true
          type: string
        - description: The ID of the run that requires the tool output submission.
          in: path
          name: run_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/SubmitToolOutputsRunRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/RunObject'
      tags:
        - Assistants
      operationId: submitToolOuputsToRun
      summary: >
        When a run has the `status: "requires_action"` and
        `required_action.type` is `submit_tool_outputs`, this endpoint can be
        used to submit the outputs from the tool calls once they're all
        completed. All outputs must be submitted in a single request.
      x-oaiMeta:
        beta: true
        examples:
          - request:
              curl: >
                curl
                https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs
                \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "tool_outputs": [
                      {
                        "tool_call_id": "call_001",
                        "output": "70 degrees and sunny."
                      }
                    ]
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const run = await openai.beta.threads.runs.submitToolOutputs(
                    "thread_123",
                    "run_123",
                    {
                      tool_outputs: [
                        {
                          tool_call_id: "call_001",
                          output: "70 degrees and sunny.",
                        },
                      ],
                    }
                  );

                  console.log(run);
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                run = client.beta.threads.runs.submit_tool_outputs(
                  thread_id="thread_123",
                  run_id="run_123",
                  tool_outputs=[
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ]
                )

                print(run)
            response: |
              {
                "id": "run_123",
                "object": "thread.run",
                "created_at": 1699075592,
                "assistant_id": "asst_123",
                "thread_id": "thread_123",
                "status": "queued",
                "started_at": 1699075592,
                "expires_at": 1699076192,
                "cancelled_at": null,
                "failed_at": null,
                "completed_at": null,
                "last_error": null,
                "model": "gpt-4-turbo",
                "instructions": null,
                "tools": [
                  {
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "description": "Get the current weather in a given location",
                      "parameters": {
                        "type": "object",
                        "properties": {
                          "location": {
                            "type": "string",
                            "description": "The city and state, e.g. San Francisco, CA"
                          },
                          "unit": {
                            "type": "string",
                            "enum": ["celsius", "fahrenheit"]
                          }
                        },
                        "required": ["location"]
                      }
                    }
                  }
                ],
                "metadata": {},
                "usage": null,
                "temperature": 1.0,
                "top_p": 1.0,
                "max_prompt_tokens": 1000,
                "max_completion_tokens": 1000,
                "truncation_strategy": {
                  "type": "auto",
                  "last_messages": null
                },
                "response_format": "auto",
                "tool_choice": "auto"
              }
            title: Default
          - request:
              curl: >
                curl
                https://api.openai.com/v1/threads/thread_123/runs/run_123/submit_tool_outputs
                \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "tool_outputs": [
                      {
                        "tool_call_id": "call_001",
                        "output": "70 degrees and sunny."
                      }
                    ],
                    "stream": true
                  }'
              node.js: |
                import OpenAI from "openai";

                const openai = new OpenAI();

                async function main() {
                  const stream = await openai.beta.threads.runs.submitToolOutputs(
                    "thread_123",
                    "run_123",
                    {
                      tool_outputs: [
                        {
                          tool_call_id: "call_001",
                          output: "70 degrees and sunny.",
                        },
                      ],
                    }
                  );

                  for await (const event of stream) {
                    console.log(event);
                  }
                }

                main();
              python: |
                from openai import OpenAI
                client = OpenAI()

                stream = client.beta.threads.runs.submit_tool_outputs(
                  thread_id="thread_123",
                  run_id="run_123",
                  tool_outputs=[
                    {
                      "tool_call_id": "call_001",
                      "output": "70 degrees and sunny."
                    }
                  ],
                  stream=True
                )

                for event in stream:
                  print(event)
            response: >
              event: thread.run.step.completed

              data:
              {"id":"step_001","object":"thread.run.step","created_at":1710352449,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"tool_calls","status":"completed","cancelled_at":null,"completed_at":1710352475,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"tool_calls","tool_calls":[{"id":"call_iWr0kQ2EaYMaxNdl0v3KYkx7","type":"function","function":{"name":"get_current_weather","arguments":"{\"location\":\"San
              Francisco, CA\",\"unit\":\"fahrenheit\"}","output":"70 degrees and
              sunny."}}]},"usage":{"prompt_tokens":291,"completion_tokens":24,"total_tokens":315}}


              event: thread.run.queued

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"queued","started_at":1710352448,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.in_progress

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"in_progress","started_at":1710352475,"expires_at":1710353047,"cancelled_at":null,"failed_at":null,"completed_at":null,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":null,"response_format":"auto","tool_choice":"auto"}}


              event: thread.run.step.created

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


              event: thread.run.step.in_progress

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"in_progress","cancelled_at":null,"completed_at":null,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":null}


              event: thread.message.created

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.in_progress

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"in_progress","incomplete_details":null,"incomplete_at":null,"completed_at":null,"role":"assistant","content":[],"metadata":{}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"The","annotations":[]}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              current"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              weather"}}]}}


              ...


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"
              sunny"}}]}}


              event: thread.message.delta

              data:
              {"id":"msg_002","object":"thread.message.delta","delta":{"content":[{"index":0,"type":"text","text":{"value":"."}}]}}


              event: thread.message.completed

              data:
              {"id":"msg_002","object":"thread.message","created_at":1710352476,"assistant_id":"asst_123","thread_id":"thread_123","run_id":"run_123","status":"completed","incomplete_details":null,"incomplete_at":null,"completed_at":1710352477,"role":"assistant","content":[{"type":"text","text":{"value":"The
              current weather in San Francisco, CA is 70 degrees Fahrenheit and
              sunny.","annotations":[]}}],"metadata":{}}


              event: thread.run.step.completed

              data:
              {"id":"step_002","object":"thread.run.step","created_at":1710352476,"run_id":"run_123","assistant_id":"asst_123","thread_id":"thread_123","type":"message_creation","status":"completed","cancelled_at":null,"completed_at":1710352477,"expires_at":1710353047,"failed_at":null,"last_error":null,"step_details":{"type":"message_creation","message_creation":{"message_id":"msg_002"}},"usage":{"prompt_tokens":329,"completion_tokens":18,"total_tokens":347}}


              event: thread.run.completed

              data:
              {"id":"run_123","object":"thread.run","created_at":1710352447,"assistant_id":"asst_123","thread_id":"thread_123","status":"completed","started_at":1710352475,"expires_at":null,"cancelled_at":null,"failed_at":null,"completed_at":1710352477,"required_action":null,"last_error":null,"model":"gpt-4-turbo","instructions":null,"tools":[{"type":"function","function":{"name":"get_current_weather","description":"Get
              the current weather in a given
              location","parameters":{"type":"object","properties":{"location":{"type":"string","description":"The
              city and state, e.g. San Francisco,
              CA"},"unit":{"type":"string","enum":["celsius","fahrenheit"]}},"required":["location"]}}}],"metadata":{},"temperature":1.0,"top_p":1.0,"max_completion_tokens":null,"max_prompt_tokens":null,"truncation_strategy":{"type":"auto","last_messages":null},"incomplete_details":null,"usage":{"prompt_tokens":20,"completion_tokens":11,"total_tokens":31},"response_format":"auto","tool_choice":"auto"}}


              event: done

              data: [DONE]
            title: Streaming
        group: threads
        name: Submit tool outputs to run
        returns: >-
          The modified [run](/docs/api-reference/runs/object) object matching
          the specified ID.
  /vector_stores:
    get:
      produces:
        - application/json
      parameters:
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListVectorStoresResponse'
      tags:
        - Vector Stores
      operationId: listVectorStores
      summary: Returns a list of vector stores.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStores = await openai.beta.vectorStores.list();
                console.log(vectorStores);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_stores = client.beta.vector_stores.list()
              print(vector_stores)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "vs_abc123",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                },
                {
                  "id": "vs_abc456",
                  "object": "vector_store",
                  "created_at": 1699061776,
                  "name": "Support FAQ v2",
                  "bytes": 139920,
                  "file_counts": {
                    "in_progress": 0,
                    "completed": 3,
                    "failed": 0,
                    "cancelled": 0,
                    "total": 3
                  }
                }
              ],
              "first_id": "vs_abc123",
              "last_id": "vs_abc456",
              "has_more": false
            }
        group: vector_stores
        name: List vector stores
        returns: >-
          A list of [vector store](/docs/api-reference/vector-stores/object)
          objects.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateVectorStoreRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreObject'
      tags:
        - Vector Stores
      operationId: createVectorStore
      summary: Create a vector store.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.create({
                  name: "Support FAQ"
                });
                console.log(vectorStore);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.create(
                name="Support FAQ"
              )
              print(vector_store)
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
        group: vector_stores
        name: Create vector store
        returns: 'A [vector store](/docs/api-reference/vector-stores/object) object.'
  '/vector_stores/{vector_store_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store to delete.
          in: path
          name: vector_store_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteVectorStoreResponse'
      tags:
        - Vector Stores
      operationId: deleteVectorStore
      summary: Delete a vector store.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStore = await openai.beta.vectorStores.del(
                  "vs_abc123"
                );
                console.log(deletedVectorStore);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              deleted_vector_store = client.beta.vector_stores.delete(
                vector_store_id="vs_abc123"
              )
              print(deleted_vector_store)
          response: |
            {
              id: "vs_abc123",
              object: "vector_store.deleted",
              deleted: true
            }
        group: vector_stores
        name: Delete vector store
        returns: Deletion status
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store to retrieve.
          in: path
          name: vector_store_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreObject'
      tags:
        - Vector Stores
      operationId: getVectorStore
      summary: Retrieves a vector store.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.retrieve(
                  "vs_abc123"
                );
                console.log(vectorStore);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.retrieve(
                vector_store_id="vs_abc123"
              )
              print(vector_store)
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776
            }
        group: vector_stores
        name: Retrieve vector store
        returns: >-
          The [vector store](/docs/api-reference/vector-stores/object) object
          matching the specified ID.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store to modify.
          in: path
          name: vector_store_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/UpdateVectorStoreRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreObject'
      tags:
        - Vector Stores
      operationId: modifyVectorStore
      summary: Modifies a vector store.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123 \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
                -d '{
                  "name": "Support FAQ"
                }'
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStore = await openai.beta.vectorStores.update(
                  "vs_abc123",
                  {
                    name: "Support FAQ"
                  }
                );
                console.log(vectorStore);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store = client.beta.vector_stores.update(
                vector_store_id="vs_abc123",
                name="Support FAQ"
              )
              print(vector_store)
          response: |
            {
              "id": "vs_abc123",
              "object": "vector_store",
              "created_at": 1699061776,
              "name": "Support FAQ",
              "bytes": 139920,
              "file_counts": {
                "in_progress": 0,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 3
              }
            }
        group: vector_stores
        name: Modify vector store
        returns: >-
          The modified [vector store](/docs/api-reference/vector-stores/object)
          object.
  '/vector_stores/{vector_store_id}/file_batches':
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the vector store for which to create a File Batch.
          in: path
          name: vector_store_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateVectorStoreFileBatchRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreFileBatchObject'
      tags:
        - Vector Stores
      operationId: createVectorStoreFileBatch
      summary: Create a vector store file batch.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/file_batches \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_ids": ["file-abc123", "file-abc456"]
                  }'
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.create(
                  "vs_abc123",
                  {
                    file_ids: ["file-abc123", "file-abc456"]
                  }
                );
                console.log(myVectorStoreFileBatch);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              vector_store_file_batch =
              client.beta.vector_stores.file_batches.create(
                vector_store_id="vs_abc123",
                file_ids=["file-abc123", "file-abc456"]
              )

              print(vector_store_file_batch)
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
        group: vector_stores
        name: Create vector store file batch
        returns: >-
          A [vector store file
          batch](/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the file batch belongs to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - description: The ID of the file batch being retrieved.
          in: path
          name: batch_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreFileBatchObject'
      tags:
        - Vector Stores
      operationId: getVectorStoreFileBatch
      summary: Retrieves a vector store file batch.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFileBatch = await openai.beta.vectorStores.fileBatches.retrieve(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFileBatch);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              vector_store_file_batch =
              client.beta.vector_stores.file_batches.retrieve(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )

              print(vector_store_file_batch)
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "in_progress",
              "file_counts": {
                "in_progress": 1,
                "completed": 1,
                "failed": 0,
                "cancelled": 0,
                "total": 0,
              }
            }
        group: vector_stores
        name: Retrieve vector store file batch
        returns: >-
          The [vector store file
          batch](/docs/api-reference/vector-stores-file-batches/batch-object)
          object.
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/cancel':
    post:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the file batch belongs to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - description: The ID of the file batch to cancel.
          in: path
          name: batch_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreFileBatchObject'
      tags:
        - Vector Stores
      operationId: cancelVectorStoreFileBatch
      summary: >-
        Cancel a vector store file batch. This attempts to cancel the processing
        of files in this batch as soon as possible.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/cancel
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X POST
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFileBatch = await openai.vector_stores.fileBatches.cancel(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(deletedVectorStoreFileBatch);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              deleted_vector_store_file_batch =
              client.beta.vector_stores.file_batches.cancel(
                  vector_store_id="vs_abc123",
                  file_batch_id="vsfb_abc123"
              )

              print(deleted_vector_store_file_batch)
          response: |
            {
              "id": "vsfb_abc123",
              "object": "vector_store.file_batch",
              "created_at": 1699061776,
              "vector_store_id": "vs_abc123",
              "status": "cancelling",
              "file_counts": {
                "in_progress": 12,
                "completed": 3,
                "failed": 0,
                "cancelled": 0,
                "total": 15,
              }
            }
        group: vector_stores
        name: Cancel vector store file batch
        returns: The modified vector store file batch object.
  '/vector_stores/{vector_store_id}/file_batches/{batch_id}/files':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the files belong to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - description: The ID of the file batch that the files belong to.
          in: path
          name: batch_id
          required: true
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
        - description: >-
            Filter by file status. One of `in_progress`, `completed`, `failed`,
            `cancelled`.
          enum:
            - in_progress
            - completed
            - failed
            - cancelled
          in: query
          name: filter
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListVectorStoreFilesResponse'
      tags:
        - Vector Stores
      operationId: listFilesInVectorStoreBatch
      summary: Returns a list of vector store files in a batch.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/files_batches/vsfb_abc123/files
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.fileBatches.listFiles(
                  "vs_abc123",
                  "vsfb_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              vector_store_files =
              client.beta.vector_stores.file_batches.list_files(
                vector_store_id="vs_abc123",
                batch_id="vsfb_abc123"
              )

              print(vector_store_files)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
        group: vector_stores
        name: List vector store files in a batch
        returns: >-
          A list of [vector store
          file](/docs/api-reference/vector-stores-files/file-object) objects.
  '/vector_stores/{vector_store_id}/files':
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the files belong to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - default: 20
          description: >
            A limit on the number of objects to be returned. Limit can range
            between 1 and 100, and the default is 20.
          in: query
          name: limit
          required: false
          type: integer
        - default: desc
          description: >
            Sort order by the `created_at` timestamp of the objects. `asc` for
            ascending order and `desc` for descending order.
          enum:
            - asc
            - desc
          in: query
          name: order
          type: string
        - description: >
            A cursor for use in pagination. `after` is an object ID that defines
            your place in the list. For instance, if you make a list request and
            receive 100 objects, ending with obj_foo, your subsequent call can
            include after=obj_foo in order to fetch the next page of the list.
          in: query
          name: after
          type: string
        - description: >
            A cursor for use in pagination. `before` is an object ID that
            defines your place in the list. For instance, if you make a list
            request and receive 100 objects, ending with obj_foo, your
            subsequent call can include before=obj_foo in order to fetch the
            previous page of the list.
          in: query
          name: before
          type: string
        - description: >-
            Filter by file status. One of `in_progress`, `completed`, `failed`,
            `cancelled`.
          enum:
            - in_progress
            - completed
            - failed
            - cancelled
          in: query
          name: filter
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/ListVectorStoreFilesResponse'
      tags:
        - Vector Stores
      operationId: listVectorStoreFiles
      summary: Returns a list of vector store files.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFiles = await openai.beta.vectorStores.files.list(
                  "vs_abc123"
                );
                console.log(vectorStoreFiles);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_files = client.beta.vector_stores.files.list(
                vector_store_id="vs_abc123"
              )
              print(vector_store_files)
          response: |
            {
              "object": "list",
              "data": [
                {
                  "id": "file-abc123",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                },
                {
                  "id": "file-abc456",
                  "object": "vector_store.file",
                  "created_at": 1699061776,
                  "vector_store_id": "vs_abc123"
                }
              ],
              "first_id": "file-abc123",
              "last_id": "file-abc456",
              "has_more": false
            }
        group: vector_stores
        name: List vector store files
        returns: >-
          A list of [vector store
          file](/docs/api-reference/vector-stores-files/file-object) objects.
    post:
      consumes:
        - application/json
      produces:
        - application/json
      parameters:
        - description: |
            The ID of the vector store for which to create a File.
          in: path
          name: vector_store_id
          required: true
          type: string
        - in: body
          name: body
          required: true
          schema:
            $ref: '#/definitions/CreateVectorStoreFileRequest'
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreFileObject'
      tags:
        - Vector Stores
      operationId: createVectorStoreFile
      summary: >-
        Create a vector store file by attaching a
        [File](/docs/api-reference/files) to a [vector
        store](/docs/api-reference/vector-stores/object).
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: |
              curl https://api.openai.com/v1/vector_stores/vs_abc123/files \
                  -H "Authorization: Bearer $OPENAI_API_KEY" \
                  -H "Content-Type: application/json" \
                  -H "OpenAI-Beta: assistants=v2" \
                  -d '{
                    "file_id": "file-abc123"
                  }'
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const myVectorStoreFile = await openai.beta.vectorStores.files.create(
                  "vs_abc123",
                  {
                    file_id: "file-abc123"
                  }
                );
                console.log(myVectorStoreFile);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.create(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "usage_bytes": 1234,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
        group: vector_stores
        name: Create vector store file
        returns: >-
          A [vector store
          file](/docs/api-reference/vector-stores-files/file-object) object.
  '/vector_stores/{vector_store_id}/files/{file_id}':
    delete:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the file belongs to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - description: The ID of the file to delete.
          in: path
          name: file_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/DeleteVectorStoreFileResponse'
      tags:
        - Vector Stores
      operationId: deleteVectorStoreFile
      summary: >-
        Delete a vector store file. This will remove the file from the vector
        store but the file itself will not be deleted. To delete the file, use
        the [delete file](/docs/api-reference/files/delete) endpoint.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2" \
                -X DELETE
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const deletedVectorStoreFile = await openai.beta.vectorStores.files.del(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(deletedVectorStoreFile);
              }

              main();
            python: >
              from openai import OpenAI

              client = OpenAI()


              deleted_vector_store_file =
              client.beta.vector_stores.files.delete(
                  vector_store_id="vs_abc123",
                  file_id="file-abc123"
              )

              print(deleted_vector_store_file)
          response: |
            {
              id: "file-abc123",
              object: "vector_store.file.deleted",
              deleted: true
            }
        group: vector_stores
        name: Delete vector store file
        returns: Deletion status
    get:
      produces:
        - application/json
      parameters:
        - description: The ID of the vector store that the file belongs to.
          in: path
          name: vector_store_id
          required: true
          type: string
        - description: The ID of the file being retrieved.
          in: path
          name: file_id
          required: true
          type: string
      responses:
        '200':
          description: OK
          schema:
            $ref: '#/definitions/VectorStoreFileObject'
      tags:
        - Vector Stores
      operationId: getVectorStoreFile
      summary: Retrieves a vector store file.
      x-oaiMeta:
        beta: true
        examples:
          request:
            curl: >
              curl
              https://api.openai.com/v1/vector_stores/vs_abc123/files/file-abc123
              \
                -H "Authorization: Bearer $OPENAI_API_KEY" \
                -H "Content-Type: application/json" \
                -H "OpenAI-Beta: assistants=v2"
            node.js: |
              import OpenAI from "openai";
              const openai = new OpenAI();

              async function main() {
                const vectorStoreFile = await openai.beta.vectorStores.files.retrieve(
                  "vs_abc123",
                  "file-abc123"
                );
                console.log(vectorStoreFile);
              }

              main();
            python: |
              from openai import OpenAI
              client = OpenAI()

              vector_store_file = client.beta.vector_stores.files.retrieve(
                vector_store_id="vs_abc123",
                file_id="file-abc123"
              )
              print(vector_store_file)
          response: |
            {
              "id": "file-abc123",
              "object": "vector_store.file",
              "created_at": 1699061776,
              "vector_store_id": "vs_abcd",
              "status": "completed",
              "last_error": null
            }
        group: vector_stores
        name: Retrieve vector store file
        returns: >-
          The [vector store
          file](/docs/api-reference/vector-stores-files/file-object) object.
definitions:
  AssistantObject:
    description: Represents an `assistant` that can call the model and use tools.
    properties:
      created_at:
        description: The Unix timestamp (in seconds) for when the assistant was created.
        type: integer
      description:
        description: >
          The description of the assistant. The maximum length is 512
          characters.
        maxLength: 512
        type: string
        x-nullable: true
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      instructions:
        description: >
          The system instructions that the assistant uses. The maximum length is
          256,000 characters.
        maxLength: 256000
        type: string
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >
          ID of the model to use. You can use the [List
          models](/docs/api-reference/models/list) API to see all of your
          available models, or see our [Model overview](/docs/models/overview)
          for descriptions of them.
        type: string
      name:
        description: |
          The name of the assistant. The maximum length is 256 characters.
        maxLength: 256
        type: string
        x-nullable: true
      object:
        description: 'The object type, which is always `assistant`.'
        enum:
          - assistant
        type: string
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      tool_resources:
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter`` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The ID of the [vector
                  store](/docs/api-reference/vector-stores/object) attached to
                  this assistant. There can be a maximum of 1 vector store
                  attached to the assistant.
                items:
                  type: string
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
      tools:
        default: []
        description: >
          A list of tool enabled on the assistant. There can be a maximum of 128
          tools per assistant. Tools can be of types `code_interpreter`,
          `file_search`, or `function`.
        items:
          x-oaiExpandable: true
        maxItems: 128
        type: array
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
    required:
      - id
      - object
      - created_at
      - name
      - description
      - model
      - instructions
      - tools
      - metadata
    title: Assistant
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "asst_abc123",
          "object": "assistant",
          "created_at": 1698984975,
          "name": "Math Tutor",
          "description": null,
          "model": "gpt-4-turbo",
          "instructions": "You are a personal math tutor. When asked a question, write and run Python code to answer the question.",
          "tools": [
            {
              "type": "code_interpreter"
            }
          ],
          "metadata": {},
          "top_p": 1.0,
          "temperature": 1.0,
          "response_format": "auto"
        }
      name: The assistant object
  AssistantStreamEvent:
    description: >
      Represents an event emitted when streaming a Run.


      Each event in a server-sent events stream has an `event` and `data`
      property:


      ```

      event: thread.created

      data: {"id": "thread_123", "object": "thread", ...}

      ```


      We emit events whenever a new object is created, transitions to a new
      state, or is being

      streamed in parts (deltas). For example, we emit `thread.run.created` when
      a new run

      is created, `thread.run.completed` when a run completes, and so on. When
      an Assistant chooses

      to create a message during a run, we emit a `thread.message.created
      event`, a

      `thread.message.in_progress` event, many `thread.message.delta` events,
      and finally a

      `thread.message.completed` event.


      We may add additional events over time, so we recommend handling unknown
      events gracefully

      in your code. See the [Assistants API
      quickstart](/docs/assistants/overview) to learn how to

      integrate the Assistants API with streaming.
    x-oaiMeta:
      beta: true
      name: Assistant stream events
  AssistantToolsCode:
    properties:
      type:
        description: 'The type of tool being defined: `code_interpreter`'
        enum:
          - code_interpreter
        type: string
    required:
      - type
    title: Code interpreter tool
    type: object
  AssistantToolsFileSearch:
    properties:
      type:
        description: 'The type of tool being defined: `file_search`'
        enum:
          - file_search
        type: string
    required:
      - type
    title: FileSearch tool
    type: object
  AssistantToolsFunction:
    properties:
      function:
        $ref: '#/definitions/FunctionObject'
      type:
        description: 'The type of tool being defined: `function`'
        enum:
          - function
        type: string
    required:
      - type
      - function
    title: Function tool
    type: object
  AssistantsApiResponseFormat:
    description: >
      An object describing the expected output of the model. If `json_object`
      only `function` type `tools` are allowed to be passed to the Run. If
      `text` the model can return text or any value needed.
    properties:
      type:
        default: text
        description: Must be one of `text` or `json_object`.
        enum:
          - text
          - json_object
        example: json_object
        type: string
    type: object
  AssistantsApiResponseFormatOption:
    description: >
      Specifies the format that the model must output. Compatible with
      [GPT-4o](/docs/models/gpt-4o), [GPT-4
      Turbo](/docs/models/gpt-4-turbo-and-gpt-4), and all GPT-3.5 Turbo models
      since `gpt-3.5-turbo-1106`.


      Setting to `{ "type": "json_object" }` enables JSON mode, which guarantees
      the message the model generates is valid JSON.


      **Important:** when using JSON mode, you **must** also instruct the model
      to produce JSON yourself via a system or user message. Without this, the
      model may generate an unending stream of whitespace until the generation
      reaches the token limit, resulting in a long-running and seemingly "stuck"
      request. Also note that the message content may be partially cut off if
      `finish_reason="length"`, which indicates the generation exceeded
      `max_tokens` or the conversation exceeded the max context length.
    x-oaiExpandable: true
  AssistantsApiToolChoiceOption:
    description: >
      Controls which (if any) tool is called by the model.

      `none` means the model will not call any tools and instead generates a
      message.

      `auto` is the default value and means the model can pick between
      generating a message or calling one or more tools.

      `required` means the model must call one or more tools before responding
      to the user.

      Specifying a particular tool like `{"type": "file_search"}` or `{"type":
      "function", "function": {"name": "my_function"}}` forces the model to call
      that tool.
    x-oaiExpandable: true
  AssistantsNamedToolChoice:
    description: >-
      Specifies a tool the model should use. Use to force the model to call a
      specific tool.
    properties:
      function:
        properties:
          name:
            description: The name of the function to call.
            type: string
        required:
          - name
        type: object
      type:
        description: >-
          The type of the tool. If type is `function`, the function name must be
          set
        enum:
          - function
          - code_interpreter
          - file_search
        type: string
    required:
      - type
    type: object
  Batch:
    properties:
      cancelled_at:
        description: The Unix timestamp (in seconds) for when the batch was cancelled.
        type: integer
      cancelling_at:
        description: The Unix timestamp (in seconds) for when the batch started cancelling.
        type: integer
      completed_at:
        description: The Unix timestamp (in seconds) for when the batch was completed.
        type: integer
      completion_window:
        description: The time frame within which the batch should be processed.
        type: string
      created_at:
        description: The Unix timestamp (in seconds) for when the batch was created.
        type: integer
      endpoint:
        description: The OpenAI API endpoint used by the batch.
        type: string
      error_file_id:
        description: The ID of the file containing the outputs of requests with errors.
        type: string
      errors:
        properties:
          data:
            items:
              properties:
                code:
                  description: An error code identifying the error type.
                  type: string
                line:
                  description: >-
                    The line number of the input file where the error occurred,
                    if applicable.
                  type: integer
                  x-nullable: true
                message:
                  description: >-
                    A human-readable message providing more details about the
                    error.
                  type: string
                param:
                  description: >-
                    The name of the parameter that caused the error, if
                    applicable.
                  type: string
                  x-nullable: true
              type: object
            type: array
          object:
            description: 'The object type, which is always `list`.'
            type: string
        type: object
      expired_at:
        description: The Unix timestamp (in seconds) for when the batch expired.
        type: integer
      expires_at:
        description: The Unix timestamp (in seconds) for when the batch will expire.
        type: integer
      failed_at:
        description: The Unix timestamp (in seconds) for when the batch failed.
        type: integer
      finalizing_at:
        description: The Unix timestamp (in seconds) for when the batch started finalizing.
        type: integer
      id:
        type: string
      in_progress_at:
        description: The Unix timestamp (in seconds) for when the batch started processing.
        type: integer
      input_file_id:
        description: The ID of the input file for the batch.
        type: string
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      object:
        description: 'The object type, which is always `batch`.'
        enum:
          - batch
        type: string
      output_file_id:
        description: >-
          The ID of the file containing the outputs of successfully executed
          requests.
        type: string
      request_counts:
        description: The request counts for different statuses within the batch.
        properties:
          completed:
            description: Number of requests that have been completed successfully.
            type: integer
          failed:
            description: Number of requests that have failed.
            type: integer
          total:
            description: Total number of requests in the batch.
            type: integer
        required:
          - total
          - completed
          - failed
        type: object
      status:
        description: The current status of the batch.
        enum:
          - validating
          - failed
          - in_progress
          - finalizing
          - completed
          - expired
          - cancelling
          - cancelled
        type: string
    required:
      - id
      - object
      - endpoint
      - input_file_id
      - completion_window
      - status
      - created_at
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "batch_abc123",
          "object": "batch",
          "endpoint": "/v1/completions",
          "errors": null,
          "input_file_id": "file-abc123",
          "completion_window": "24h",
          "status": "completed",
          "output_file_id": "file-cvaTdG",
          "error_file_id": "file-HOWS94",
          "created_at": 1711471533,
          "in_progress_at": 1711471538,
          "expires_at": 1711557933,
          "finalizing_at": 1711493133,
          "completed_at": 1711493163,
          "failed_at": null,
          "expired_at": null,
          "cancelling_at": null,
          "cancelled_at": null,
          "request_counts": {
            "total": 100,
            "completed": 95,
            "failed": 5
          },
          "metadata": {
            "customer_id": "user_123456789",
            "batch_description": "Nightly eval job",
          }
        }
      name: The batch object
  BatchRequestInput:
    description: The per-line object of the batch input file
    properties:
      custom_id:
        description: >-
          A developer-provided per-request id that will be used to match outputs
          to inputs. Must be unique for each request in a batch.
        type: string
      method:
        description: >-
          The HTTP method to be used for the request. Currently only `POST` is
          supported.
        enum:
          - POST
        type: string
      url:
        description: >-
          The OpenAI API relative URL to be used for the request. Currently
          `/v1/chat/completions`, `/v1/embeddings`, and `/v1/completions` are
          supported.
        type: string
    type: object
    x-oaiMeta:
      example: >
        {"custom_id": "request-1", "method": "POST", "url":
        "/v1/chat/completions", "body": {"model": "gpt-3.5-turbo", "messages":
        [{"role": "system", "content": "You are a helpful assistant."}, {"role":
        "user", "content": "What is 2+2?"}]}}
      name: The request input object
  BatchRequestOutput:
    description: The per-line object of the batch output and error files
    properties:
      custom_id:
        description: >-
          A developer-provided per-request id that will be used to match outputs
          to inputs.
        type: string
      error:
        description: >-
          For requests that failed with a non-HTTP error, this will contain more
          information on the cause of the failure.
        properties:
          code:
            description: A machine-readable error code.
            type: string
          message:
            description: A human-readable error message.
            type: string
        type: object
        x-nullable: true
      id:
        type: string
      response:
        properties:
          body:
            description: The JSON body of the response
            type: object
            x-oaiTypeLabel: map
          request_id:
            description: >-
              An unique identifier for the OpenAI API request. Please include
              this request ID when contacting support.
            type: string
          status_code:
            description: The HTTP status code of the response
            type: integer
        type: object
        x-nullable: true
    type: object
    x-oaiMeta:
      example: >
        {"id": "batch_req_wnaDys", "custom_id": "request-2", "response":
        {"status_code": 200, "request_id": "req_c187b3", "body": {"id":
        "chatcmpl-9758Iw", "object": "chat.completion", "created": 1711475054,
        "model": "gpt-3.5-turbo", "choices": [{"index": 0, "message": {"role":
        "assistant", "content": "2 + 2 equals 4."}, "finish_reason": "stop"}],
        "usage": {"prompt_tokens": 24, "completion_tokens": 15, "total_tokens":
        39}, "system_fingerprint": null}}, "error": null}
      name: The request output object
  ChatCompletionFunctionCallOption:
    description: >
      Specifying a particular function via `{"name": "my_function"}` forces the
      model to call that function.
    properties:
      name:
        description: The name of the function to call.
        type: string
    required:
      - name
    type: object
  ChatCompletionFunctions:
    properties:
      parameters:
        $ref: '#/definitions/FunctionParameters'
      description:
        description: >-
          A description of what the function does, used by the model to choose
          when and how to call the function.
        type: string
      name:
        description: >-
          The name of the function to be called. Must be a-z, A-Z, 0-9, or
          contain underscores and dashes, with a maximum length of 64.
        type: string
    required:
      - name
    type: object
    x-deprecated: true
    x-nullable: true
  ChatCompletionMessageToolCall:
    properties:
      function:
        description: The function that the model called.
        properties:
          arguments:
            description: >-
              The arguments to call the function with, as generated by the model
              in JSON format. Note that the model does not always generate valid
              JSON, and may hallucinate parameters not defined by your function
              schema. Validate the arguments in your code before calling your
              function.
            type: string
          name:
            description: The name of the function to call.
            type: string
        required:
          - name
          - arguments
        type: object
      id:
        description: The ID of the tool call.
        type: string
      type:
        description: 'The type of the tool. Currently, only `function` is supported.'
        enum:
          - function
        type: string
    required:
      - id
      - type
      - function
    type: object
  ChatCompletionMessageToolCallChunk:
    properties:
      function:
        properties:
          arguments:
            description: >-
              The arguments to call the function with, as generated by the model
              in JSON format. Note that the model does not always generate valid
              JSON, and may hallucinate parameters not defined by your function
              schema. Validate the arguments in your code before calling your
              function.
            type: string
          name:
            description: The name of the function to call.
            type: string
        type: object
      id:
        description: The ID of the tool call.
        type: string
      index:
        type: integer
      type:
        description: 'The type of the tool. Currently, only `function` is supported.'
        enum:
          - function
        type: string
    required:
      - index
    type: object
  ChatCompletionMessageToolCalls:
    description: 'The tool calls generated by the model, such as function calls.'
    items:
      $ref: '#/definitions/ChatCompletionMessageToolCall'
    type: array
  ChatCompletionNamedToolChoice:
    description: >-
      Specifies a tool the model should use. Use to force the model to call a
      specific function.
    properties:
      function:
        properties:
          name:
            description: The name of the function to call.
            type: string
        required:
          - name
        type: object
      type:
        description: 'The type of the tool. Currently, only `function` is supported.'
        enum:
          - function
        type: string
    required:
      - type
      - function
    type: object
  ChatCompletionRequestAssistantMessage:
    properties:
      content:
        description: >
          The contents of the assistant message. Required unless `tool_calls` or
          `function_call` is specified.
        type: string
        x-nullable: true
      function_call:
        description: >-
          Deprecated and replaced by `tool_calls`. The name and arguments of a
          function that should be called, as generated by the model.
        properties:
          arguments:
            description: >-
              The arguments to call the function with, as generated by the model
              in JSON format. Note that the model does not always generate valid
              JSON, and may hallucinate parameters not defined by your function
              schema. Validate the arguments in your code before calling your
              function.
            type: string
          name:
            description: The name of the function to call.
            type: string
        required:
          - arguments
          - name
        type: object
        x-deprecated: true
        x-nullable: true
      name:
        description: >-
          An optional name for the participant. Provides the model information
          to differentiate between participants of the same role.
        type: string
      role:
        description: 'The role of the messages author, in this case `assistant`.'
        enum:
          - assistant
        type: string
      tool_calls:
        $ref: '#/definitions/ChatCompletionMessageToolCalls'
    required:
      - role
    title: Assistant message
    type: object
  ChatCompletionRequestFunctionMessage:
    properties:
      content:
        description: The contents of the function message.
        type: string
        x-nullable: true
      name:
        description: The name of the function to call.
        type: string
      role:
        description: 'The role of the messages author, in this case `function`.'
        enum:
          - function
        type: string
    required:
      - role
      - content
      - name
    title: Function message
    type: object
    x-deprecated: true
    x-nullable: true
  ChatCompletionRequestMessage:
    x-oaiExpandable: true
  ChatCompletionRequestMessageContentPart:
    x-oaiExpandable: true
  ChatCompletionRequestMessageContentPartImage:
    properties:
      image_url:
        properties:
          detail:
            default: auto
            description: >-
              Specifies the detail level of the image. Learn more in the [Vision
              guide](/docs/guides/vision/low-or-high-fidelity-image-understanding).
            enum:
              - auto
              - low
              - high
            type: string
          url:
            description: Either a URL of the image or the base64 encoded image data.
            format: uri
            type: string
        required:
          - url
        type: object
      type:
        description: The type of the content part.
        enum:
          - image_url
        type: string
    required:
      - type
      - image_url
    title: Image content part
    type: object
  ChatCompletionRequestMessageContentPartText:
    properties:
      text:
        description: The text content.
        type: string
      type:
        description: The type of the content part.
        enum:
          - text
        type: string
    required:
      - type
      - text
    title: Text content part
    type: object
  ChatCompletionRequestSystemMessage:
    properties:
      content:
        description: The contents of the system message.
        type: string
      name:
        description: >-
          An optional name for the participant. Provides the model information
          to differentiate between participants of the same role.
        type: string
      role:
        description: 'The role of the messages author, in this case `system`.'
        enum:
          - system
        type: string
    required:
      - content
      - role
    title: System message
    type: object
  ChatCompletionRequestToolMessage:
    properties:
      content:
        description: The contents of the tool message.
        type: string
      role:
        description: 'The role of the messages author, in this case `tool`.'
        enum:
          - tool
        type: string
      tool_call_id:
        description: Tool call that this message is responding to.
        type: string
    required:
      - role
      - content
      - tool_call_id
    title: Tool message
    type: object
  ChatCompletionRequestUserMessage:
    properties:
      content:
        description: |
          The contents of the user message.
        x-oaiExpandable: true
      name:
        description: >-
          An optional name for the participant. Provides the model information
          to differentiate between participants of the same role.
        type: string
      role:
        description: 'The role of the messages author, in this case `user`.'
        enum:
          - user
        type: string
    required:
      - content
      - role
    title: User message
    type: object
  ChatCompletionResponseMessage:
    description: A chat completion message generated by the model.
    properties:
      content:
        description: The contents of the message.
        type: string
        x-nullable: true
      function_call:
        description: >-
          Deprecated and replaced by `tool_calls`. The name and arguments of a
          function that should be called, as generated by the model.
        properties:
          arguments:
            description: >-
              The arguments to call the function with, as generated by the model
              in JSON format. Note that the model does not always generate valid
              JSON, and may hallucinate parameters not defined by your function
              schema. Validate the arguments in your code before calling your
              function.
            type: string
          name:
            description: The name of the function to call.
            type: string
        required:
          - name
          - arguments
        type: object
        x-deprecated: true
        x-nullable: true
      role:
        description: The role of the author of this message.
        enum:
          - assistant
        type: string
      tool_calls:
        $ref: '#/definitions/ChatCompletionMessageToolCalls'
    required:
      - role
      - content
    type: object
  ChatCompletionRole:
    description: The role of the author of a message
    enum:
      - system
      - user
      - assistant
      - tool
      - function
    type: string
  ChatCompletionStreamOptions:
    default: null
    description: |
      Options for streaming response. Only set this when you set `stream: true`.
    properties:
      include_usage:
        description: >
          If set, an additional chunk will be streamed before the `data: [DONE]`
          message. The `usage` field on this chunk shows the token usage
          statistics for the entire request, and the `choices` field will always
          be an empty array. All other chunks will also include a `usage` field,
          but with a null value.
        type: boolean
    type: object
    x-nullable: true
  ChatCompletionStreamResponseDelta:
    description: A chat completion delta generated by streamed model responses.
    properties:
      content:
        description: The contents of the chunk message.
        type: string
        x-nullable: true
      function_call:
        description: >-
          Deprecated and replaced by `tool_calls`. The name and arguments of a
          function that should be called, as generated by the model.
        properties:
          arguments:
            description: >-
              The arguments to call the function with, as generated by the model
              in JSON format. Note that the model does not always generate valid
              JSON, and may hallucinate parameters not defined by your function
              schema. Validate the arguments in your code before calling your
              function.
            type: string
          name:
            description: The name of the function to call.
            type: string
        type: object
        x-deprecated: true
        x-nullable: true
      role:
        description: The role of the author of this message.
        enum:
          - system
          - user
          - assistant
          - tool
        type: string
      tool_calls:
        items:
          $ref: '#/definitions/ChatCompletionMessageToolCallChunk'
        type: array
    type: object
  ChatCompletionTokenLogprob:
    properties:
      bytes:
        description: >-
          A list of integers representing the UTF-8 bytes representation of the
          token. Useful in instances where characters are represented by
          multiple tokens and their byte representations must be combined to
          generate the correct text representation. Can be `null` if there is no
          bytes representation for the token.
        items:
          type: integer
        type: array
        x-nullable: true
      logprob:
        description: >-
          The log probability of this token, if it is within the top 20 most
          likely tokens. Otherwise, the value `-9999.0` is used to signify that
          the token is very unlikely.
        type: number
      token:
        description: The token.
        type: string
      top_logprobs:
        description: >-
          List of the most likely tokens and their log probability, at this
          token position. In rare cases, there may be fewer than the number of
          requested `top_logprobs` returned.
        items:
          properties:
            bytes:
              description: >-
                A list of integers representing the UTF-8 bytes representation
                of the token. Useful in instances where characters are
                represented by multiple tokens and their byte representations
                must be combined to generate the correct text representation.
                Can be `null` if there is no bytes representation for the token.
              items:
                type: integer
              type: array
              x-nullable: true
            logprob:
              description: >-
                The log probability of this token, if it is within the top 20
                most likely tokens. Otherwise, the value `-9999.0` is used to
                signify that the token is very unlikely.
              type: number
            token:
              description: The token.
              type: string
          required:
            - token
            - logprob
            - bytes
          type: object
        type: array
    required:
      - token
      - logprob
      - bytes
      - top_logprobs
    type: object
  ChatCompletionTool:
    properties:
      function:
        $ref: '#/definitions/FunctionObject'
      type:
        description: 'The type of the tool. Currently, only `function` is supported.'
        enum:
          - function
        type: string
    required:
      - type
      - function
    type: object
  ChatCompletionToolChoiceOption:
    description: >
      Controls which (if any) tool is called by the model.

      `none` means the model will not call any tool and instead generates a
      message.

      `auto` means the model can pick between generating a message or calling
      one or more tools.

      `required` means the model must call one or more tools.

      Specifying a particular tool via `{"type": "function", "function":
      {"name": "my_function"}}` forces the model to call that tool.


      `none` is the default when no tools are present. `auto` is the default if
      tools are present.
    x-oaiExpandable: true
  CompletionUsage:
    description: Usage statistics for the completion request.
    properties:
      completion_tokens:
        description: Number of tokens in the generated completion.
        type: integer
      prompt_tokens:
        description: Number of tokens in the prompt.
        type: integer
      total_tokens:
        description: Total number of tokens used in the request (prompt + completion).
        type: integer
    required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
    type: object
  CreateAssistantRequest:
    additionalProperties: false
    properties:
      description:
        description: >
          The description of the assistant. The maximum length is 512
          characters.
        maxLength: 512
        type: string
        x-nullable: true
      instructions:
        description: >
          The system instructions that the assistant uses. The maximum length is
          256,000 characters.
        maxLength: 256000
        type: string
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >
          ID of the model to use. You can use the [List
          models](/docs/api-reference/models/list) API to see all of your
          available models, or see our [Model overview](/docs/models/overview)
          for descriptions of them.
        example: gpt-4-turbo
        x-oaiTypeLabel: string
      name:
        description: |
          The name of the assistant. The maximum length is 256 characters.
        maxLength: 256
        type: string
        x-nullable: true
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      tool_resources:
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The [vector store](/docs/api-reference/vector-stores/object)
                  attached to this assistant. There can be a maximum of 1 vector
                  store attached to the assistant.
                items:
                  type: string
                maxItems: 1
                type: array
              vector_stores:
                description: >
                  A helper to create a [vector
                  store](/docs/api-reference/vector-stores/object) with file_ids
                  and attach it to this assistant. There can be a maximum of 1
                  vector store attached to the assistant.
                items:
                  properties:
                    file_ids:
                      description: >
                        A list of [file](/docs/api-reference/files) IDs to add
                        to the vector store. There can be a maximum of 10000
                        files in a vector store.
                      items:
                        type: string
                      maxItems: 10000
                      type: array
                    metadata:
                      description: >
                        Set of 16 key-value pairs that can be attached to a
                        vector store. This can be useful for storing additional
                        information about the vector store in a structured
                        format. Keys can be a maximum of 64 characters long and
                        values can be a maxium of 512 characters long.
                      type: object
                      x-oaiTypeLabel: map
                  type: object
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
      tools:
        default: []
        description: >
          A list of tool enabled on the assistant. There can be a maximum of 128
          tools per assistant. Tools can be of types `code_interpreter`,
          `file_search`, or `function`.
        items:
          x-oaiExpandable: true
        maxItems: 128
        type: array
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
    required:
      - model
    type: object
  CreateChatCompletionFunctionResponse:
    description: >-
      Represents a chat completion response returned by model, based on the
      provided input.
    properties:
      choices:
        description: >-
          A list of chat completion choices. Can be more than one if `n` is
          greater than 1.
        items:
          properties:
            finish_reason:
              description: >
                The reason the model stopped generating tokens. This will be
                `stop` if the model hit a natural stop point or a provided stop
                sequence, `length` if the maximum number of tokens specified in
                the request was reached, `content_filter` if content was omitted
                due to a flag from our content filters, or `function_call` if
                the model called a function.
              enum:
                - stop
                - length
                - function_call
                - content_filter
              type: string
            index:
              description: The index of the choice in the list of choices.
              type: integer
            message:
              $ref: '#/definitions/ChatCompletionResponseMessage'
          required:
            - finish_reason
            - index
            - message
            - logprobs
          type: object
        type: array
      created:
        description: >-
          The Unix timestamp (in seconds) of when the chat completion was
          created.
        type: integer
      id:
        description: A unique identifier for the chat completion.
        type: string
      model:
        description: The model used for the chat completion.
        type: string
      object:
        description: 'The object type, which is always `chat.completion`.'
        enum:
          - chat.completion
        type: string
      system_fingerprint:
        description: >
          This fingerprint represents the backend configuration that the model
          runs with.


          Can be used in conjunction with the `seed` request parameter to
          understand when backend changes have been made that might impact
          determinism.
        type: string
      usage:
        $ref: '#/definitions/CompletionUsage'
    required:
      - choices
      - created
      - id
      - model
      - object
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "chatcmpl-abc123",
          "object": "chat.completion",
          "created": 1699896916,
          "model": "gpt-3.5-turbo-0125",
          "choices": [
            {
              "index": 0,
              "message": {
                "role": "assistant",
                "content": null,
                "tool_calls": [
                  {
                    "id": "call_abc123",
                    "type": "function",
                    "function": {
                      "name": "get_current_weather",
                      "arguments": "{\n\"location\": \"Boston, MA\"\n}"
                    }
                  }
                ]
              },
              "logprobs": null,
              "finish_reason": "tool_calls"
            }
          ],
          "usage": {
            "prompt_tokens": 82,
            "completion_tokens": 17,
            "total_tokens": 99
          }
        }
      group: chat
      name: The chat completion object
  CreateChatCompletionImageResponse:
    description: >-
      Represents a streamed chunk of a chat completion response returned by
      model, based on the provided input.
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "chatcmpl-123",
          "object": "chat.completion",
          "created": 1677652288,
          "model": "gpt-3.5-turbo-0125",
          "system_fingerprint": "fp_44709d6fcb",
          "choices": [{
            "index": 0,
            "message": {
              "role": "assistant",
              "content": "\n\nThis image shows a wooden boardwalk extending through a lush green marshland.",
            },
            "logprobs": null,
            "finish_reason": "stop"
          }],
          "usage": {
            "prompt_tokens": 9,
            "completion_tokens": 12,
            "total_tokens": 21
          }
        }
      group: chat
      name: The chat completion chunk object
  CreateChatCompletionRequest:
    properties:
      frequency_penalty:
        default: 0
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on their existing frequency in the text so far, decreasing the model's
          likelihood to repeat the same line verbatim.


          [See more information about frequency and presence
          penalties.](/docs/guides/text-generation/parameter-details)
        maximum: 2
        minimum: -2
        type: number
        x-nullable: true
      function_call:
        description: >
          Deprecated in favor of `tool_choice`.


          Controls which (if any) function is called by the model.

          `none` means the model will not call a function and instead generates
          a message.

          `auto` means the model can pick between generating a message or
          calling a function.

          Specifying a particular function via `{"name": "my_function"}` forces
          the model to call that function.


          `none` is the default when no functions are present. `auto` is the
          default if functions are present.
        x-deprecated: true
        x-nullable: true
        x-oaiExpandable: true
      functions:
        description: |
          Deprecated in favor of `tools`.

          A list of functions the model may generate JSON inputs for.
        items:
          $ref: '#/definitions/ChatCompletionFunctions'
        maxItems: 128
        minItems: 1
        type: array
        x-deprecated: true
        x-nullable: true
      logit_bias:
        additionalProperties:
          type: integer
        default: null
        description: >
          Modify the likelihood of specified tokens appearing in the completion.


          Accepts a JSON object that maps tokens (specified by their token ID in
          the tokenizer) to an associated bias value from -100 to 100.
          Mathematically, the bias is added to the logits generated by the model
          prior to sampling. The exact effect will vary per model, but values
          between -1 and 1 should decrease or increase likelihood of selection;
          values like -100 or 100 should result in a ban or exclusive selection
          of the relevant token.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      logprobs:
        default: false
        description: >-
          Whether to return log probabilities of the output tokens or not. If
          true, returns the log probabilities of each output token returned in
          the `content` of `message`.
        type: boolean
        x-nullable: true
      max_tokens:
        description: >
          The maximum number of [tokens](/tokenizer) that can be generated in
          the chat completion.


          The total length of input tokens and generated tokens is limited by
          the model's context length. [Example Python
          code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
          for counting tokens.
        type: integer
        x-nullable: true
      messages:
        description: >-
          A list of messages comprising the conversation so far. [Example Python
          code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
        items:
          $ref: '#/definitions/ChatCompletionRequestMessage'
        minItems: 1
        type: array
      model:
        description: >-
          ID of the model to use. See the [model endpoint
          compatibility](/docs/models/model-endpoint-compatibility) table for
          details on which models work with the Chat API.
        example: gpt-4-turbo
        x-oaiTypeLabel: string
      'n':
        default: 1
        description: >-
          How many chat completion choices to generate for each input message.
          Note that you will be charged based on the number of generated tokens
          across all of the choices. Keep `n` as `1` to minimize costs.
        example: 1
        maximum: 128
        minimum: 1
        type: integer
        x-nullable: true
      presence_penalty:
        default: 0
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the text so far, increasing the model's
          likelihood to talk about new topics.


          [See more information about frequency and presence
          penalties.](/docs/guides/text-generation/parameter-details)
        maximum: 2
        minimum: -2
        type: number
        x-nullable: true
      response_format:
        description: >
          An object specifying the format that the model must output. Compatible
          with [GPT-4 Turbo](/docs/models/gpt-4-and-gpt-4-turbo) and all GPT-3.5
          Turbo models newer than `gpt-3.5-turbo-1106`.


          Setting to `{ "type": "json_object" }` enables JSON mode, which
          guarantees the message the model generates is valid JSON.


          **Important:** when using JSON mode, you **must** also instruct the
          model to produce JSON yourself via a system or user message. Without
          this, the model may generate an unending stream of whitespace until
          the generation reaches the token limit, resulting in a long-running
          and seemingly "stuck" request. Also note that the message content may
          be partially cut off if `finish_reason="length"`, which indicates the
          generation exceeded `max_tokens` or the conversation exceeded the max
          context length.
        properties:
          type:
            default: text
            description: Must be one of `text` or `json_object`.
            enum:
              - text
              - json_object
            example: json_object
            type: string
        type: object
      seed:
        description: >
          This feature is in Beta.

          If specified, our system will make a best effort to sample
          deterministically, such that repeated requests with the same `seed`
          and parameters should return the same result.

          Determinism is not guaranteed, and you should refer to the
          `system_fingerprint` response parameter to monitor changes in the
          backend.
        maximum: 9223372036854775807
        minimum: -9223372036854775807
        type: integer
        x-nullable: true
        x-oaiMeta:
          beta: true
      stop:
        default: null
        description: |
          Up to 4 sequences where the API will stop generating further tokens.
      stream:
        default: false
        description: >
          If set, partial message deltas will be sent, like in ChatGPT. Tokens
          will be sent as data-only [server-sent
          events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
          as they become available, with the stream terminated by a `data:
          [DONE]` message. [Example Python
          code](https://cookbook.openai.com/examples/how_to_stream_completions).
        type: boolean
        x-nullable: true
      stream_options:
        $ref: '#/definitions/ChatCompletionStreamOptions'
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.


          We generally recommend altering this or `top_p` but not both.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      tool_choice:
        $ref: '#/definitions/ChatCompletionToolChoiceOption'
      tools:
        description: >
          A list of tools the model may call. Currently, only functions are
          supported as a tool. Use this to provide a list of functions the model
          may generate JSON inputs for. A max of 128 functions are supported.
        items:
          $ref: '#/definitions/ChatCompletionTool'
        type: array
      top_logprobs:
        description: >-
          An integer between 0 and 20 specifying the number of most likely
          tokens to return at each token position, each with an associated log
          probability. `logprobs` must be set to `true` if this parameter is
          used.
        maximum: 20
        minimum: 0
        type: integer
        x-nullable: true
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or `temperature` but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - model
      - messages
    type: object
  CreateChatCompletionResponse:
    description: >-
      Represents a chat completion response returned by model, based on the
      provided input.
    properties:
      choices:
        description: >-
          A list of chat completion choices. Can be more than one if `n` is
          greater than 1.
        items:
          properties:
            finish_reason:
              description: >
                The reason the model stopped generating tokens. This will be
                `stop` if the model hit a natural stop point or a provided stop
                sequence,

                `length` if the maximum number of tokens specified in the
                request was reached,

                `content_filter` if content was omitted due to a flag from our
                content filters,

                `tool_calls` if the model called a tool, or `function_call`
                (deprecated) if the model called a function.
              enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
              type: string
            index:
              description: The index of the choice in the list of choices.
              type: integer
            logprobs:
              description: Log probability information for the choice.
              properties:
                content:
                  description: >-
                    A list of message content tokens with log probability
                    information.
                  items:
                    $ref: '#/definitions/ChatCompletionTokenLogprob'
                  type: array
                  x-nullable: true
              required:
                - content
              type: object
              x-nullable: true
            message:
              $ref: '#/definitions/ChatCompletionResponseMessage'
          required:
            - finish_reason
            - index
            - message
            - logprobs
          type: object
        type: array
      created:
        description: >-
          The Unix timestamp (in seconds) of when the chat completion was
          created.
        type: integer
      id:
        description: A unique identifier for the chat completion.
        type: string
      model:
        description: The model used for the chat completion.
        type: string
      object:
        description: 'The object type, which is always `chat.completion`.'
        enum:
          - chat.completion
        type: string
      system_fingerprint:
        description: >
          This fingerprint represents the backend configuration that the model
          runs with.


          Can be used in conjunction with the `seed` request parameter to
          understand when backend changes have been made that might impact
          determinism.
        type: string
      usage:
        $ref: '#/definitions/CompletionUsage'
    required:
      - choices
      - created
      - id
      - model
      - object
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "chatcmpl-123",
          "object": "chat.completion",
          "created": 1677652288,
          "model": "gpt-3.5-turbo-0125",
          "system_fingerprint": "fp_44709d6fcb",
          "choices": [{
            "index": 0,
            "message": {
              "role": "assistant",
              "content": "\n\nHello there, how may I assist you today?",
            },
            "logprobs": null,
            "finish_reason": "stop"
          }],
          "usage": {
            "prompt_tokens": 9,
            "completion_tokens": 12,
            "total_tokens": 21
          }
        }
      group: chat
      name: The chat completion object
  CreateChatCompletionStreamResponse:
    description: >-
      Represents a streamed chunk of a chat completion response returned by
      model, based on the provided input.
    properties:
      choices:
        description: >
          A list of chat completion choices. Can contain more than one elements
          if `n` is greater than 1. Can also be empty for the

          last chunk if you set `stream_options: {"include_usage": true}`.
        items:
          properties:
            delta:
              $ref: '#/definitions/ChatCompletionStreamResponseDelta'
            finish_reason:
              description: >
                The reason the model stopped generating tokens. This will be
                `stop` if the model hit a natural stop point or a provided stop
                sequence,

                `length` if the maximum number of tokens specified in the
                request was reached,

                `content_filter` if content was omitted due to a flag from our
                content filters,

                `tool_calls` if the model called a tool, or `function_call`
                (deprecated) if the model called a function.
              enum:
                - stop
                - length
                - tool_calls
                - content_filter
                - function_call
              type: string
              x-nullable: true
            index:
              description: The index of the choice in the list of choices.
              type: integer
            logprobs:
              description: Log probability information for the choice.
              properties:
                content:
                  description: >-
                    A list of message content tokens with log probability
                    information.
                  items:
                    $ref: '#/definitions/ChatCompletionTokenLogprob'
                  type: array
                  x-nullable: true
              required:
                - content
              type: object
              x-nullable: true
          required:
            - delta
            - finish_reason
            - index
          type: object
        type: array
      created:
        description: >-
          The Unix timestamp (in seconds) of when the chat completion was
          created. Each chunk has the same timestamp.
        type: integer
      id:
        description: >-
          A unique identifier for the chat completion. Each chunk has the same
          ID.
        type: string
      model:
        description: The model to generate the completion.
        type: string
      object:
        description: 'The object type, which is always `chat.completion.chunk`.'
        enum:
          - chat.completion.chunk
        type: string
      system_fingerprint:
        description: >
          This fingerprint represents the backend configuration that the model
          runs with.

          Can be used in conjunction with the `seed` request parameter to
          understand when backend changes have been made that might impact
          determinism.
        type: string
      usage:
        description: >
          An optional field that will only be present when you set
          `stream_options: {"include_usage": true}` in your request.

          When present, it contains a null value except for the last chunk which
          contains the token usage statistics for the entire request.
        properties:
          completion_tokens:
            description: Number of tokens in the generated completion.
            type: integer
          prompt_tokens:
            description: Number of tokens in the prompt.
            type: integer
          total_tokens:
            description: Total number of tokens used in the request (prompt + completion).
            type: integer
        required:
          - prompt_tokens
          - completion_tokens
          - total_tokens
        type: object
    required:
      - choices
      - created
      - id
      - model
      - object
    type: object
    x-oaiMeta:
      example: >
        {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
        "system_fingerprint": "fp_44709d6fcb",
        "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}


        {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
        "system_fingerprint": "fp_44709d6fcb",
        "choices":[{"index":0,"delta":{"content":"Hello"},"logprobs":null,"finish_reason":null}]}


        ....


        {"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-3.5-turbo-0125",
        "system_fingerprint": "fp_44709d6fcb",
        "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
      group: chat
      name: The chat completion chunk object
  CreateCompletionRequest:
    properties:
      best_of:
        default: 1
        description: >
          Generates `best_of` completions server-side and returns the "best"
          (the one with the highest log probability per token). Results cannot
          be streamed.


          When used with `n`, `best_of` controls the number of candidate
          completions and `n` specifies how many to return – `best_of` must be
          greater than `n`.


          **Note:** Because this parameter generates many completions, it can
          quickly consume your token quota. Use carefully and ensure that you
          have reasonable settings for `max_tokens` and `stop`.
        maximum: 20
        minimum: 0
        type: integer
        x-nullable: true
      echo:
        default: false
        description: |
          Echo back the prompt in addition to the completion
        type: boolean
        x-nullable: true
      frequency_penalty:
        default: 0
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on their existing frequency in the text so far, decreasing the model's
          likelihood to repeat the same line verbatim.


          [See more information about frequency and presence
          penalties.](/docs/guides/text-generation/parameter-details)
        maximum: 2
        minimum: -2
        type: number
        x-nullable: true
      logit_bias:
        additionalProperties:
          type: integer
        default: null
        description: >
          Modify the likelihood of specified tokens appearing in the completion.


          Accepts a JSON object that maps tokens (specified by their token ID in
          the GPT tokenizer) to an associated bias value from -100 to 100. You
          can use this [tokenizer tool](/tokenizer?view=bpe) to convert text to
          token IDs. Mathematically, the bias is added to the logits generated
          by the model prior to sampling. The exact effect will vary per model,
          but values between -1 and 1 should decrease or increase likelihood of
          selection; values like -100 or 100 should result in a ban or exclusive
          selection of the relevant token.


          As an example, you can pass `{"50256": -100}` to prevent the
          <|endoftext|> token from being generated.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      logprobs:
        default: null
        description: >
          Include the log probabilities on the `logprobs` most likely output
          tokens, as well the chosen tokens. For example, if `logprobs` is 5,
          the API will return a list of the 5 most likely tokens. The API will
          always return the `logprob` of the sampled token, so there may be up
          to `logprobs+1` elements in the response.


          The maximum value for `logprobs` is 5.
        maximum: 5
        minimum: 0
        type: integer
        x-nullable: true
      max_tokens:
        default: 16
        description: >
          The maximum number of [tokens](/tokenizer) that can be generated in
          the completion.


          The token count of your prompt plus `max_tokens` cannot exceed the
          model's context length. [Example Python
          code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
          for counting tokens.
        example: 16
        minimum: 0
        type: integer
        x-nullable: true
      model:
        description: >
          ID of the model to use. You can use the [List
          models](/docs/api-reference/models/list) API to see all of your
          available models, or see our [Model overview](/docs/models/overview)
          for descriptions of them.
        x-oaiTypeLabel: string
      'n':
        default: 1
        description: >
          How many completions to generate for each prompt.


          **Note:** Because this parameter generates many completions, it can
          quickly consume your token quota. Use carefully and ensure that you
          have reasonable settings for `max_tokens` and `stop`.
        example: 1
        maximum: 128
        minimum: 1
        type: integer
        x-nullable: true
      presence_penalty:
        default: 0
        description: >
          Number between -2.0 and 2.0. Positive values penalize new tokens based
          on whether they appear in the text so far, increasing the model's
          likelihood to talk about new topics.


          [See more information about frequency and presence
          penalties.](/docs/guides/text-generation/parameter-details)
        maximum: 2
        minimum: -2
        type: number
        x-nullable: true
      prompt:
        default: <|endoftext|>
        description: >
          The prompt(s) to generate completions for, encoded as a string, array
          of strings, array of tokens, or array of token arrays.


          Note that <|endoftext|> is the document separator that the model sees
          during training, so if a prompt is not specified the model will
          generate as if from the beginning of a new document.
        x-nullable: true
      seed:
        description: >
          If specified, our system will make a best effort to sample
          deterministically, such that repeated requests with the same `seed`
          and parameters should return the same result.


          Determinism is not guaranteed, and you should refer to the
          `system_fingerprint` response parameter to monitor changes in the
          backend.
        maximum: 9223372036854775807
        minimum: -9223372036854775807
        type: integer
        x-nullable: true
      stop:
        default: null
        description: >
          Up to 4 sequences where the API will stop generating further tokens.
          The returned text will not contain the stop sequence.
        x-nullable: true
      stream:
        default: false
        description: >
          Whether to stream back partial progress. If set, tokens will be sent
          as data-only [server-sent
          events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
          as they become available, with the stream terminated by a `data:
          [DONE]` message. [Example Python
          code](https://cookbook.openai.com/examples/how_to_stream_completions).
        type: boolean
        x-nullable: true
      stream_options:
        $ref: '#/definitions/ChatCompletionStreamOptions'
      suffix:
        default: null
        description: |
          The suffix that comes after a completion of inserted text.

          This parameter is only supported for `gpt-3.5-turbo-instruct`.
        example: test.
        type: string
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.


          We generally recommend altering this or `top_p` but not both.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or `temperature` but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - model
      - prompt
    type: object
  CreateCompletionResponse:
    description: >
      Represents a completion response from the API. Note: both the streamed and
      non-streamed response objects share the same shape (unlike the chat
      endpoint).
    properties:
      choices:
        description: >-
          The list of completion choices the model generated for the input
          prompt.
        items:
          properties:
            finish_reason:
              description: >
                The reason the model stopped generating tokens. This will be
                `stop` if the model hit a natural stop point or a provided stop
                sequence,

                `length` if the maximum number of tokens specified in the
                request was reached,

                or `content_filter` if content was omitted due to a flag from
                our content filters.
              enum:
                - stop
                - length
                - content_filter
              type: string
            index:
              type: integer
            logprobs:
              properties:
                text_offset:
                  items:
                    type: integer
                  type: array
                token_logprobs:
                  items:
                    type: number
                  type: array
                tokens:
                  items:
                    type: string
                  type: array
                top_logprobs:
                  items:
                    additionalProperties:
                      type: number
                    type: object
                  type: array
              type: object
              x-nullable: true
            text:
              type: string
          required:
            - finish_reason
            - index
            - logprobs
            - text
          type: object
        type: array
      created:
        description: The Unix timestamp (in seconds) of when the completion was created.
        type: integer
      id:
        description: A unique identifier for the completion.
        type: string
      model:
        description: The model used for completion.
        type: string
      object:
        description: 'The object type, which is always "text_completion"'
        enum:
          - text_completion
        type: string
      system_fingerprint:
        description: >
          This fingerprint represents the backend configuration that the model
          runs with.


          Can be used in conjunction with the `seed` request parameter to
          understand when backend changes have been made that might impact
          determinism.
        type: string
      usage:
        $ref: '#/definitions/CompletionUsage'
    required:
      - id
      - object
      - created
      - model
      - choices
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "cmpl-uqkvlQyYK7bGYrRHQ0eXlWi7",
          "object": "text_completion",
          "created": 1589478378,
          "model": "gpt-4-turbo",
          "choices": [
            {
              "text": "\n\nThis is indeed a test",
              "index": 0,
              "logprobs": null,
              "finish_reason": "length"
            }
          ],
          "usage": {
            "prompt_tokens": 5,
            "completion_tokens": 7,
            "total_tokens": 12
          }
        }
      legacy: true
      name: The completion object
  CreateEmbeddingRequest:
    additionalProperties: false
    properties:
      dimensions:
        description: >
          The number of dimensions the resulting output embeddings should have.
          Only supported in `text-embedding-3` and later models.
        minimum: 1
        type: integer
      encoding_format:
        default: float
        description: >-
          The format to return the embeddings in. Can be either `float` or
          [`base64`](https://pypi.org/project/pybase64/).
        enum:
          - float
          - base64
        example: float
        type: string
      input:
        description: >
          Input text to embed, encoded as a string or array of tokens. To embed
          multiple inputs in a single request, pass an array of strings or array
          of token arrays. The input must not exceed the max input tokens for
          the model (8192 tokens for `text-embedding-ada-002`), cannot be an
          empty string, and any array must be 2048 dimensions or less. [Example
          Python
          code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
          for counting tokens.
        example: The quick brown fox jumped over the lazy dog
        x-oaiExpandable: true
      model:
        description: >
          ID of the model to use. You can use the [List
          models](/docs/api-reference/models/list) API to see all of your
          available models, or see our [Model overview](/docs/models/overview)
          for descriptions of them.
        example: text-embedding-3-small
        x-oaiTypeLabel: string
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - model
      - input
    type: object
  CreateEmbeddingResponse:
    properties:
      data:
        description: The list of embeddings generated by the model.
        items:
          $ref: '#/definitions/Embedding'
        type: array
      model:
        description: The name of the model used to generate the embedding.
        type: string
      object:
        description: 'The object type, which is always "list".'
        enum:
          - list
        type: string
      usage:
        description: The usage information for the request.
        properties:
          prompt_tokens:
            description: The number of tokens used by the prompt.
            type: integer
          total_tokens:
            description: The total number of tokens used by the request.
            type: integer
        required:
          - prompt_tokens
          - total_tokens
        type: object
    required:
      - object
      - model
      - data
      - usage
    type: object
  CreateFileRequest:
    additionalProperties: false
    properties:
      file:
        description: |
          The File object (not file name) to be uploaded.
        format: binary
        type: string
      purpose:
        description: >
          The intended purpose of the uploaded file.


          Use "assistants" for [Assistants](/docs/api-reference/assistants) and
          [Message](/docs/api-reference/messages) files, "vision" for Assistants
          image file inputs, "batch" for [Batch API](/docs/guides/batch), and
          "fine-tune" for [Fine-tuning](/docs/api-reference/fine-tuning).
        enum:
          - assistants
          - batch
          - fine-tune
        type: string
    required:
      - file
      - purpose
    type: object
  CreateFineTuningJobRequest:
    properties:
      hyperparameters:
        description: The hyperparameters used for the fine-tuning job.
        properties:
          batch_size:
            default: auto
            description: >
              Number of examples in each batch. A larger batch size means that
              model parameters

              are updated less frequently, but with lower variance.
          learning_rate_multiplier:
            default: auto
            description: >
              Scaling factor for the learning rate. A smaller learning rate may
              be useful to avoid

              overfitting.
          n_epochs:
            default: auto
            description: >
              The number of epochs to train the model for. An epoch refers to
              one full cycle

              through the training dataset.
        type: object
      integrations:
        description: A list of integrations to enable for your fine-tuning job.
        items:
          properties:
            type:
              description: >
                The type of integration to enable. Currently, only "wandb"
                (Weights and Biases) is supported.
            wandb:
              description: >
                The settings for your integration with Weights and Biases. This
                payload specifies the project that

                metrics will be sent to. Optionally, you can set an explicit
                display name for your run, add tags

                to your run, and set a default entity (team, username, etc) to
                be associated with your run.
              properties:
                tags:
                  description: >
                    A list of tags to be attached to the newly created run.
                    These tags are passed through directly to WandB. Some

                    default tags are generated by OpenAI: "openai/finetune",
                    "openai/{base-model}", "openai/{ftjob-abcdef}".
                  items:
                    example: custom-tag
                    type: string
                  type: array
                entity:
                  description: >
                    The entity to use for the run. This allows you to set the
                    team or username of the WandB user that you would

                    like associated with the run. If not set, the default entity
                    for the registered WandB API key is used.
                  type: string
                  x-nullable: true
                name:
                  description: >
                    A display name to set for the run. If not set, we will use
                    the Job ID as the name.
                  type: string
                  x-nullable: true
                project:
                  description: >
                    The name of the project that the new run will be created
                    under.
                  example: my-wandb-project
                  type: string
              required:
                - project
              type: object
          required:
            - type
            - wandb
          type: object
        type: array
        x-nullable: true
      model:
        description: >
          The name of the model to fine-tune. You can select one of the

          [supported
          models](/docs/guides/fine-tuning/what-models-can-be-fine-tuned).
        example: gpt-3.5-turbo
        x-oaiTypeLabel: string
      seed:
        description: >
          The seed controls the reproducibility of the job. Passing in the same
          seed and job parameters should produce the same results, but may
          differ in rare cases.

          If a seed is not specified, one will be generated for you.
        example: 42
        maximum: 2147483647
        minimum: 0
        type: integer
        x-nullable: true
      suffix:
        default: null
        description: >
          A string of up to 18 characters that will be added to your fine-tuned
          model name.


          For example, a `suffix` of "custom-model-name" would produce a model
          name like `ft:gpt-3.5-turbo:openai:custom-model-name:7p4lURel`.
        maxLength: 40
        minLength: 1
        type: string
        x-nullable: true
      training_file:
        description: >
          The ID of an uploaded file that contains training data.


          See [upload file](/docs/api-reference/files/create) for how to upload
          a file.


          Your dataset must be formatted as a JSONL file. Additionally, you must
          upload your file with the purpose `fine-tune`.


          See the [fine-tuning guide](/docs/guides/fine-tuning) for more
          details.
        example: file-abc123
        type: string
      validation_file:
        description: >
          The ID of an uploaded file that contains validation data.


          If you provide this file, the data is used to generate validation

          metrics periodically during fine-tuning. These metrics can be viewed
          in

          the fine-tuning results file.

          The same data should not be present in both train and validation
          files.


          Your dataset must be formatted as a JSONL file. You must upload your
          file with the purpose `fine-tune`.


          See the [fine-tuning guide](/docs/guides/fine-tuning) for more
          details.
        example: file-abc123
        type: string
        x-nullable: true
    required:
      - model
      - training_file
    type: object
  CreateImageEditRequest:
    properties:
      image:
        description: >-
          The image to edit. Must be a valid PNG file, less than 4MB, and
          square. If mask is not provided, image must have transparency, which
          will be used as the mask.
        format: binary
        type: string
      mask:
        description: >-
          An additional image whose fully transparent areas (e.g. where alpha is
          zero) indicate where `image` should be edited. Must be a valid PNG
          file, less than 4MB, and have the same dimensions as `image`.
        format: binary
        type: string
      model:
        default: dall-e-2
        description: >-
          The model to use for image generation. Only `dall-e-2` is supported at
          this time.
        example: dall-e-2
        x-nullable: true
        x-oaiTypeLabel: string
      'n':
        default: 1
        description: The number of images to generate. Must be between 1 and 10.
        example: 1
        maximum: 10
        minimum: 1
        type: integer
        x-nullable: true
      prompt:
        description: >-
          A text description of the desired image(s). The maximum length is 1000
          characters.
        example: A cute baby sea otter wearing a beret
        type: string
      response_format:
        default: url
        description: >-
          The format in which the generated images are returned. Must be one of
          `url` or `b64_json`. URLs are only valid for 60 minutes after the
          image has been generated.
        enum:
          - url
          - b64_json
        example: url
        type: string
        x-nullable: true
      size:
        default: 1024x1024
        description: >-
          The size of the generated images. Must be one of `256x256`, `512x512`,
          or `1024x1024`.
        enum:
          - 256x256
          - 512x512
          - 1024x1024
        example: 1024x1024
        type: string
        x-nullable: true
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - prompt
      - image
    type: object
  CreateImageRequest:
    properties:
      model:
        default: dall-e-2
        description: The model to use for image generation.
        example: dall-e-3
        x-nullable: true
        x-oaiTypeLabel: string
      'n':
        default: 1
        description: >-
          The number of images to generate. Must be between 1 and 10. For
          `dall-e-3`, only `n=1` is supported.
        example: 1
        maximum: 10
        minimum: 1
        type: integer
        x-nullable: true
      prompt:
        description: >-
          A text description of the desired image(s). The maximum length is 1000
          characters for `dall-e-2` and 4000 characters for `dall-e-3`.
        example: A cute baby sea otter
        type: string
      quality:
        default: standard
        description: >-
          The quality of the image that will be generated. `hd` creates images
          with finer details and greater consistency across the image. This
          param is only supported for `dall-e-3`.
        enum:
          - standard
          - hd
        example: standard
        type: string
      response_format:
        default: url
        description: >-
          The format in which the generated images are returned. Must be one of
          `url` or `b64_json`. URLs are only valid for 60 minutes after the
          image has been generated.
        enum:
          - url
          - b64_json
        example: url
        type: string
        x-nullable: true
      size:
        default: 1024x1024
        description: >-
          The size of the generated images. Must be one of `256x256`, `512x512`,
          or `1024x1024` for `dall-e-2`. Must be one of `1024x1024`,
          `1792x1024`, or `1024x1792` for `dall-e-3` models.
        enum:
          - 256x256
          - 512x512
          - 1024x1024
          - 1792x1024
          - 1024x1792
        example: 1024x1024
        type: string
        x-nullable: true
      style:
        default: vivid
        description: >-
          The style of the generated images. Must be one of `vivid` or
          `natural`. Vivid causes the model to lean towards generating
          hyper-real and dramatic images. Natural causes the model to produce
          more natural, less hyper-real looking images. This param is only
          supported for `dall-e-3`.
        enum:
          - vivid
          - natural
        example: vivid
        type: string
        x-nullable: true
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - prompt
    type: object
  CreateImageVariationRequest:
    properties:
      image:
        description: >-
          The image to use as the basis for the variation(s). Must be a valid
          PNG file, less than 4MB, and square.
        format: binary
        type: string
      model:
        default: dall-e-2
        description: >-
          The model to use for image generation. Only `dall-e-2` is supported at
          this time.
        example: dall-e-2
        x-nullable: true
        x-oaiTypeLabel: string
      'n':
        default: 1
        description: >-
          The number of images to generate. Must be between 1 and 10. For
          `dall-e-3`, only `n=1` is supported.
        example: 1
        maximum: 10
        minimum: 1
        type: integer
        x-nullable: true
      response_format:
        default: url
        description: >-
          The format in which the generated images are returned. Must be one of
          `url` or `b64_json`. URLs are only valid for 60 minutes after the
          image has been generated.
        enum:
          - url
          - b64_json
        example: url
        type: string
        x-nullable: true
      size:
        default: 1024x1024
        description: >-
          The size of the generated images. Must be one of `256x256`, `512x512`,
          or `1024x1024`.
        enum:
          - 256x256
          - 512x512
          - 1024x1024
        example: 1024x1024
        type: string
        x-nullable: true
      user:
        description: >
          A unique identifier representing your end-user, which can help OpenAI
          to monitor and detect abuse. [Learn
          more](/docs/guides/safety-best-practices/end-user-ids).
        example: user-1234
        type: string
    required:
      - image
    type: object
  CreateMessageRequest:
    additionalProperties: false
    properties:
      attachments:
        description: >-
          A list of files attached to the message, and the tools they should be
          added to.
        items:
          properties:
            file_id:
              description: The ID of the file to attach to the message.
              type: string
            tools:
              description: The tools to add this file to.
              items:
                x-oaiExpandable: true
              type: array
          type: object
        required:
          - file_id
          - tools
        type: array
        x-nullable: true
      content:
        x-oaiExpandable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      role:
        description: >
          The role of the entity that is creating the message. Allowed values
          include:

          - `user`: Indicates the message is sent by an actual user and should
          be used in most cases to represent user-generated messages.

          - `assistant`: Indicates the message is generated by the assistant.
          Use this value to insert messages from the assistant into the
          conversation.
        enum:
          - user
          - assistant
        type: string
    required:
      - role
      - content
    type: object
  CreateModerationRequest:
    properties:
      input:
        description: The input text to classify
      model:
        default: text-moderation-latest
        description: >
          Two content moderations models are available: `text-moderation-stable`
          and `text-moderation-latest`.


          The default is `text-moderation-latest` which will be automatically
          upgraded over time. This ensures you are always using our most
          accurate model. If you use `text-moderation-stable`, we will provide
          advanced notice before updating the model. Accuracy of
          `text-moderation-stable` may be slightly lower than for
          `text-moderation-latest`.
        example: text-moderation-stable
        nullable: false
        x-oaiTypeLabel: string
    required:
      - input
    type: object
  CreateModerationResponse:
    description: Represents if a given text input is potentially harmful.
    properties:
      id:
        description: The unique identifier for the moderation request.
        type: string
      model:
        description: The model used to generate the moderation results.
        type: string
      results:
        description: A list of moderation objects.
        items:
          properties:
            categories:
              description: 'A list of the categories, and whether they are flagged or not.'
              properties:
                harassment:
                  description: >-
                    Content that expresses, incites, or promotes harassing
                    language towards any target.
                  type: boolean
                harassment/threatening:
                  description: >-
                    Harassment content that also includes violence or serious
                    harm towards any target.
                  type: boolean
                hate:
                  description: >-
                    Content that expresses, incites, or promotes hate based on
                    race, gender, ethnicity, religion, nationality, sexual
                    orientation, disability status, or caste. Hateful content
                    aimed at non-protected groups (e.g., chess players) is
                    harassment.
                  type: boolean
                hate/threatening:
                  description: >-
                    Hateful content that also includes violence or serious harm
                    towards the targeted group based on race, gender, ethnicity,
                    religion, nationality, sexual orientation, disability
                    status, or caste.
                  type: boolean
                self-harm:
                  description: >-
                    Content that promotes, encourages, or depicts acts of
                    self-harm, such as suicide, cutting, and eating disorders.
                  type: boolean
                self-harm/instructions:
                  description: >-
                    Content that encourages performing acts of self-harm, such
                    as suicide, cutting, and eating disorders, or that gives
                    instructions or advice on how to commit such acts.
                  type: boolean
                self-harm/intent:
                  description: >-
                    Content where the speaker expresses that they are engaging
                    or intend to engage in acts of self-harm, such as suicide,
                    cutting, and eating disorders.
                  type: boolean
                sexual:
                  description: >-
                    Content meant to arouse sexual excitement, such as the
                    description of sexual activity, or that promotes sexual
                    services (excluding sex education and wellness).
                  type: boolean
                sexual/minors:
                  description: >-
                    Sexual content that includes an individual who is under 18
                    years old.
                  type: boolean
                violence:
                  description: 'Content that depicts death, violence, or physical injury.'
                  type: boolean
                violence/graphic:
                  description: >-
                    Content that depicts death, violence, or physical injury in
                    graphic detail.
                  type: boolean
              required:
                - hate
                - hate/threatening
                - harassment
                - harassment/threatening
                - self-harm
                - self-harm/intent
                - self-harm/instructions
                - sexual
                - sexual/minors
                - violence
                - violence/graphic
              type: object
            category_scores:
              description: >-
                A list of the categories along with their scores as predicted by
                model.
              properties:
                harassment:
                  description: The score for the category 'harassment'.
                  type: number
                harassment/threatening:
                  description: The score for the category 'harassment/threatening'.
                  type: number
                hate:
                  description: The score for the category 'hate'.
                  type: number
                hate/threatening:
                  description: The score for the category 'hate/threatening'.
                  type: number
                self-harm:
                  description: The score for the category 'self-harm'.
                  type: number
                self-harm/instructions:
                  description: The score for the category 'self-harm/instructions'.
                  type: number
                self-harm/intent:
                  description: The score for the category 'self-harm/intent'.
                  type: number
                sexual:
                  description: The score for the category 'sexual'.
                  type: number
                sexual/minors:
                  description: The score for the category 'sexual/minors'.
                  type: number
                violence:
                  description: The score for the category 'violence'.
                  type: number
                violence/graphic:
                  description: The score for the category 'violence/graphic'.
                  type: number
              required:
                - hate
                - hate/threatening
                - harassment
                - harassment/threatening
                - self-harm
                - self-harm/intent
                - self-harm/instructions
                - sexual
                - sexual/minors
                - violence
                - violence/graphic
              type: object
            flagged:
              description: Whether any of the below categories are flagged.
              type: boolean
          required:
            - flagged
            - categories
            - category_scores
          type: object
        type: array
    required:
      - id
      - model
      - results
    type: object
    x-oaiMeta:
      example: |
        {
          "id": "modr-XXXXX",
          "model": "text-moderation-005",
          "results": [
            {
              "flagged": true,
              "categories": {
                "sexual": false,
                "hate": false,
                "harassment": false,
                "self-harm": false,
                "sexual/minors": false,
                "hate/threatening": false,
                "violence/graphic": false,
                "self-harm/intent": false,
                "self-harm/instructions": false,
                "harassment/threatening": true,
                "violence": true,
              },
              "category_scores": {
                "sexual": 1.2282071e-06,
                "hate": 0.010696256,
                "harassment": 0.29842457,
                "self-harm": 1.5236925e-08,
                "sexual/minors": 5.7246268e-08,
                "hate/threatening": 0.0060676364,
                "violence/graphic": 4.435014e-06,
                "self-harm/intent": 8.098441e-10,
                "self-harm/instructions": 2.8498655e-11,
                "harassment/threatening": 0.63055265,
                "violence": 0.99011886,
              }
            }
          ]
        }
      name: The moderation object
  CreateRunRequest:
    additionalProperties: false
    properties:
      additional_instructions:
        description: >-
          Appends additional instructions at the end of the instructions for the
          run. This is useful for modifying the behavior on a per-run basis
          without overriding other instructions.
        type: string
        x-nullable: true
      additional_messages:
        description: Adds additional messages to the thread before creating the run.
        items:
          $ref: '#/definitions/CreateMessageRequest'
        type: array
        x-nullable: true
      assistant_id:
        description: >-
          The ID of the [assistant](/docs/api-reference/assistants) to use to
          execute this run.
        type: string
      instructions:
        description: >-
          Overrides the
          [instructions](/docs/api-reference/assistants/createAssistant) of the
          assistant. This is useful for modifying the behavior on a per-run
          basis.
        type: string
        x-nullable: true
      max_completion_tokens:
        description: >
          The maximum number of completion tokens that may be used over the
          course of the run. The run will make a best effort to use only the
          number of completion tokens specified, across multiple turns of the
          run. If the run exceeds the number of completion tokens specified, the
          run will end with status `incomplete`. See `incomplete_details` for
          more info.
        minimum: 256
        type: integer
        x-nullable: true
      max_prompt_tokens:
        description: >
          The maximum number of prompt tokens that may be used over the course
          of the run. The run will make a best effort to use only the number of
          prompt tokens specified, across multiple turns of the run. If the run
          exceeds the number of prompt tokens specified, the run will end with
          status `incomplete`. See `incomplete_details` for more info.
        minimum: 256
        type: integer
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >-
          The ID of the [Model](/docs/api-reference/models) to be used to
          execute this run. If a value is provided here, it will override the
          model associated with the assistant. If not, the model associated with
          the assistant will be used.
        example: gpt-4-turbo
        x-nullable: true
        x-oaiTypeLabel: string
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      stream:
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        type: boolean
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      tool_choice:
        $ref: '#/definitions/AssistantsApiToolChoiceOption'
        x-nullable: true
      tools:
        description: >-
          Override the tools the assistant can use for this run. This is useful
          for modifying the behavior on a per-run basis.
        items:
          x-oaiExpandable: true
        maxItems: 20
        type: array
        x-nullable: true
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
      truncation_strategy:
        $ref: '#/definitions/TruncationObject'
        x-nullable: true
    required:
      - thread_id
      - assistant_id
    type: object
  CreateSpeechRequest:
    additionalProperties: false
    properties:
      input:
        description: The text to generate audio for. The maximum length is 4096 characters.
        maxLength: 4096
        type: string
      model:
        description: >
          One of the available [TTS models](/docs/models/tts): `tts-1` or
          `tts-1-hd`
        x-oaiTypeLabel: string
      response_format:
        default: mp3
        description: >-
          The format to audio in. Supported formats are `mp3`, `opus`, `aac`,
          `flac`, `wav`, and `pcm`.
        enum:
          - mp3
          - opus
          - aac
          - flac
          - wav
          - pcm
        type: string
      speed:
        default: 1
        description: >-
          The speed of the generated audio. Select a value from `0.25` to `4.0`.
          `1.0` is the default.
        maximum: 4
        minimum: 0.25
        type: number
      voice:
        description: >-
          The voice to use when generating the audio. Supported voices are
          `alloy`, `echo`, `fable`, `onyx`, `nova`, and `shimmer`. Previews of
          the voices are available in the [Text to speech
          guide](/docs/guides/text-to-speech/voice-options).
        enum:
          - alloy
          - echo
          - fable
          - onyx
          - nova
          - shimmer
        type: string
    required:
      - model
      - input
      - voice
    type: object
  CreateThreadAndRunRequest:
    additionalProperties: false
    properties:
      assistant_id:
        description: >-
          The ID of the [assistant](/docs/api-reference/assistants) to use to
          execute this run.
        type: string
      instructions:
        description: >-
          Override the default system message of the assistant. This is useful
          for modifying the behavior on a per-run basis.
        type: string
        x-nullable: true
      max_completion_tokens:
        description: >
          The maximum number of completion tokens that may be used over the
          course of the run. The run will make a best effort to use only the
          number of completion tokens specified, across multiple turns of the
          run. If the run exceeds the number of completion tokens specified, the
          run will end with status `incomplete`. See `incomplete_details` for
          more info.
        minimum: 256
        type: integer
        x-nullable: true
      max_prompt_tokens:
        description: >
          The maximum number of prompt tokens that may be used over the course
          of the run. The run will make a best effort to use only the number of
          prompt tokens specified, across multiple turns of the run. If the run
          exceeds the number of prompt tokens specified, the run will end with
          status `incomplete`. See `incomplete_details` for more info.
        minimum: 256
        type: integer
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >-
          The ID of the [Model](/docs/api-reference/models) to be used to
          execute this run. If a value is provided here, it will override the
          model associated with the assistant. If not, the model associated with
          the assistant will be used.
        example: gpt-4-turbo
        x-nullable: true
        x-oaiTypeLabel: string
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      stream:
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        type: boolean
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      thread:
        $ref: '#/definitions/CreateThreadRequest'
        description: 'If no thread is provided, an empty thread will be created.'
      tool_choice:
        $ref: '#/definitions/AssistantsApiToolChoiceOption'
        x-nullable: true
      tool_resources:
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The ID of the [vector
                  store](/docs/api-reference/vector-stores/object) attached to
                  this assistant. There can be a maximum of 1 vector store
                  attached to the assistant.
                items:
                  type: string
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
      tools:
        description: >-
          Override the tools the assistant can use for this run. This is useful
          for modifying the behavior on a per-run basis.
        items: {}
        maxItems: 20
        type: array
        x-nullable: true
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
      truncation_strategy:
        $ref: '#/definitions/TruncationObject'
        x-nullable: true
    required:
      - thread_id
      - assistant_id
    type: object
  CreateThreadRequest:
    additionalProperties: false
    properties:
      messages:
        description: >-
          A list of [messages](/docs/api-reference/messages) to start the thread
          with.
        items:
          $ref: '#/definitions/CreateMessageRequest'
        type: array
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      tool_resources:
        description: >
          A set of resources that are made available to the assistant's tools in
          this thread. The resources are specific to the type of tool. For
          example, the `code_interpreter` tool requires a list of file IDs,
          while the `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The [vector store](/docs/api-reference/vector-stores/object)
                  attached to this thread. There can be a maximum of 1 vector
                  store attached to the thread.
                items:
                  type: string
                maxItems: 1
                type: array
              vector_stores:
                description: >
                  A helper to create a [vector
                  store](/docs/api-reference/vector-stores/object) with file_ids
                  and attach it to this thread. There can be a maximum of 1
                  vector store attached to the thread.
                items:
                  properties:
                    file_ids:
                      description: >
                        A list of [file](/docs/api-reference/files) IDs to add
                        to the vector store. There can be a maximum of 10000
                        files in a vector store.
                      items:
                        type: string
                      maxItems: 10000
                      type: array
                    metadata:
                      description: >
                        Set of 16 key-value pairs that can be attached to a
                        vector store. This can be useful for storing additional
                        information about the vector store in a structured
                        format. Keys can be a maximum of 64 characters long and
                        values can be a maxium of 512 characters long.
                      type: object
                      x-oaiTypeLabel: map
                  type: object
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
    type: object
  CreateTranscriptionRequest:
    additionalProperties: false
    properties:
      file:
        description: >
          The audio file object (not file name) to transcribe, in one of these
          formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
        format: binary
        type: string
        x-oaiTypeLabel: file
      language:
        description: >
          The language of the input audio. Supplying the input language in
          [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)
          format will improve accuracy and latency.
        type: string
      model:
        description: >
          ID of the model to use. Only `whisper-1` (which is powered by our open
          source Whisper V2 model) is currently available.
        example: whisper-1
        x-oaiTypeLabel: string
      prompt:
        description: >
          An optional text to guide the model's style or continue a previous
          audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
          should match the audio language.
        type: string
      response_format:
        default: json
        description: >
          The format of the transcript output, in one of these options: `json`,
          `text`, `srt`, `verbose_json`, or `vtt`.
        enum:
          - json
          - text
          - srt
          - verbose_json
          - vtt
        type: string
      temperature:
        default: 0
        description: >
          The sampling temperature, between 0 and 1. Higher values like 0.8 will
          make the output more random, while lower values like 0.2 will make it
          more focused and deterministic. If set to 0, the model will use [log
          probability](https://en.wikipedia.org/wiki/Log_probability) to
          automatically increase the temperature until certain thresholds are
          hit.
        type: number
      'timestamp_granularities[]':
        default:
          - segment
        description: >
          The timestamp granularities to populate for this transcription.
          `response_format` must be set `verbose_json` to use timestamp
          granularities. Either or both of these options are supported: `word`,
          or `segment`. Note: There is no additional latency for segment
          timestamps, but generating word timestamps incurs additional latency.
        items:
          enum:
            - word
            - segment
          type: string
        type: array
    required:
      - file
      - model
    type: object
  CreateTranscriptionResponseJson:
    description: >-
      Represents a transcription response returned by model, based on the
      provided input.
    properties:
      text:
        description: The transcribed text.
        type: string
    required:
      - text
    type: object
    x-oaiMeta:
      example: |
        {
          "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
        }
      group: audio
      name: The transcription object
  CreateTranscriptionResponseVerboseJson:
    description: >-
      Represents a verbose json transcription response returned by model, based
      on the provided input.
    properties:
      duration:
        description: The duration of the input audio.
        type: string
      language:
        description: The language of the input audio.
        type: string
      segments:
        description: Segments of the transcribed text and their corresponding details.
        items:
          $ref: '#/definitions/TranscriptionSegment'
        type: array
      text:
        description: The transcribed text.
        type: string
      words:
        description: Extracted words and their corresponding timestamps.
        items:
          $ref: '#/definitions/TranscriptionWord'
        type: array
    required:
      - language
      - duration
      - text
    type: object
    x-oaiMeta:
      example: |
        {
          "task": "transcribe",
          "language": "english",
          "duration": 8.470000267028809,
          "text": "The beach was a popular spot on a hot summer day. People were swimming in the ocean, building sandcastles, and playing beach volleyball.",
          "segments": [
            {
              "id": 0,
              "seek": 0,
              "start": 0.0,
              "end": 3.319999933242798,
              "text": " The beach was a popular spot on a hot summer day.",
              "tokens": [
                50364, 440, 7534, 390, 257, 3743, 4008, 322, 257, 2368, 4266, 786, 13, 50530
              ],
              "temperature": 0.0,
              "avg_logprob": -0.2860786020755768,
              "compression_ratio": 1.2363636493682861,
              "no_speech_prob": 0.00985979475080967
            },
            ...
          ]
        }
      group: audio
      name: The transcription object
  CreateTranslationRequest:
    additionalProperties: false
    properties:
      file:
        description: >
          The audio file object (not file name) translate, in one of these
          formats: flac, mp3, mp4, mpeg, mpga, m4a, ogg, wav, or webm.
        format: binary
        type: string
        x-oaiTypeLabel: file
      model:
        description: >
          ID of the model to use. Only `whisper-1` (which is powered by our open
          source Whisper V2 model) is currently available.
        example: whisper-1
        x-oaiTypeLabel: string
      prompt:
        description: >
          An optional text to guide the model's style or continue a previous
          audio segment. The [prompt](/docs/guides/speech-to-text/prompting)
          should be in English.
        type: string
      response_format:
        default: json
        description: >
          The format of the transcript output, in one of these options: `json`,
          `text`, `srt`, `verbose_json`, or `vtt`.
        type: string
      temperature:
        default: 0
        description: >
          The sampling temperature, between 0 and 1. Higher values like 0.8 will
          make the output more random, while lower values like 0.2 will make it
          more focused and deterministic. If set to 0, the model will use [log
          probability](https://en.wikipedia.org/wiki/Log_probability) to
          automatically increase the temperature until certain thresholds are
          hit.
        type: number
    required:
      - file
      - model
    type: object
  CreateTranslationResponseJson:
    properties:
      text:
        type: string
    required:
      - text
    type: object
  CreateTranslationResponseVerboseJson:
    properties:
      duration:
        description: The duration of the input audio.
        type: string
      language:
        description: The language of the output translation (always `english`).
        type: string
      segments:
        description: Segments of the translated text and their corresponding details.
        items:
          $ref: '#/definitions/TranscriptionSegment'
        type: array
      text:
        description: The translated text.
        type: string
    required:
      - language
      - duration
      - text
    type: object
  CreateVectorStoreFileBatchRequest:
    additionalProperties: false
    properties:
      file_ids:
        description: >-
          A list of [File](/docs/api-reference/files) IDs that the vector store
          should use. Useful for tools like `file_search` that can access files.
        items:
          type: string
        maxItems: 500
        minItems: 1
        type: array
    required:
      - file_ids
    type: object
  CreateVectorStoreFileRequest:
    additionalProperties: false
    properties:
      file_id:
        description: >-
          A [File](/docs/api-reference/files) ID that the vector store should
          use. Useful for tools like `file_search` that can access files.
        type: string
    required:
      - file_id
    type: object
  CreateVectorStoreRequest:
    additionalProperties: false
    properties:
      expires_after:
        $ref: '#/definitions/VectorStoreExpirationAfter'
      file_ids:
        description: >-
          A list of [File](/docs/api-reference/files) IDs that the vector store
          should use. Useful for tools like `file_search` that can access files.
        items:
          type: string
        maxItems: 500
        type: array
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      name:
        description: The name of the vector store.
        type: string
    type: object
  DeleteAssistantResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - assistant.deleted
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteFileResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - file
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteMessageResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - thread.message.deleted
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteModelResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteThreadResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - thread.deleted
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteVectorStoreFileResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - vector_store.file.deleted
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DeleteVectorStoreResponse:
    properties:
      deleted:
        type: boolean
      id:
        type: string
      object:
        enum:
          - vector_store.deleted
        type: string
    required:
      - id
      - object
      - deleted
    type: object
  DoneEvent:
    description: Occurs when a stream ends.
    properties:
      data:
        enum:
          - '[DONE]'
        type: string
      event:
        enum:
          - done
        type: string
    required:
      - event
      - data
    type: object
    x-oaiMeta:
      dataDescription: '`data` is `[DONE]`'
  Embedding:
    description: |
      Represents an embedding vector returned by embedding endpoint.
    properties:
      embedding:
        description: >
          The embedding vector, which is a list of floats. The length of vector
          depends on the model as listed in the [embedding
          guide](/docs/guides/embeddings).
        items:
          type: number
        type: array
      index:
        description: The index of the embedding in the list of embeddings.
        type: integer
      object:
        description: 'The object type, which is always "embedding".'
        enum:
          - embedding
        type: string
    required:
      - index
      - object
      - embedding
    type: object
    x-oaiMeta:
      example: |
        {
          "object": "embedding",
          "embedding": [
            0.0023064255,
            -0.009327292,
            .... (1536 floats total for ada-002)
            -0.0028842222,
          ],
          "index": 0
        }
      name: The embedding object
  Error:
    properties:
      code:
        type: string
        x-nullable: true
      message:
        nullable: false
        type: string
      param:
        type: string
        x-nullable: true
      type:
        nullable: false
        type: string
    required:
      - type
      - message
      - param
      - code
    type: object
  ErrorEvent:
    description: >-
      Occurs when an [error](/docs/guides/error-codes/api-errors) occurs. This
      can happen due to an internal server error or a timeout.
    properties:
      data:
        $ref: '#/definitions/Error'
      event:
        enum:
          - error
        type: string
    required:
      - event
      - data
    type: object
    x-oaiMeta:
      dataDescription: '`data` is an [error](/docs/guides/error-codes/api-errors)'
  ErrorResponse:
    properties:
      error:
        $ref: '#/definitions/Error'
    required:
      - error
    type: object
  FineTuningIntegration:
    properties:
      type:
        description: The type of the integration being enabled for the fine-tuning job
        enum:
          - wandb
        type: string
      wandb:
        description: >
          The settings for your integration with Weights and Biases. This
          payload specifies the project that

          metrics will be sent to. Optionally, you can set an explicit display
          name for your run, add tags

          to your run, and set a default entity (team, username, etc) to be
          associated with your run.
        properties:
          tags:
            description: >
              A list of tags to be attached to the newly created run. These tags
              are passed through directly to WandB. Some

              default tags are generated by OpenAI: "openai/finetune",
              "openai/{base-model}", "openai/{ftjob-abcdef}".
            items:
              example: custom-tag
              type: string
            type: array
          entity:
            description: >
              The entity to use for the run. This allows you to set the team or
              username of the WandB user that you would

              like associated with the run. If not set, the default entity for
              the registered WandB API key is used.
            type: string
            x-nullable: true
          name:
            description: >
              A display name to set for the run. If not set, we will use the Job
              ID as the name.
            type: string
            x-nullable: true
          project:
            description: |
              The name of the project that the new run will be created under.
            example: my-wandb-project
            type: string
        required:
          - project
        type: object
    required:
      - type
      - wandb
    title: Fine-Tuning Job Integration
    type: object
  FineTuningJob:
    description: >
      The `fine_tuning.job` object represents a fine-tuning job that has been
      created through the API.
    properties:
      created_at:
        description: >-
          The Unix timestamp (in seconds) for when the fine-tuning job was
          created.
        type: integer
      error:
        description: >-
          For fine-tuning jobs that have `failed`, this will contain more
          information on the cause of the failure.
        properties:
          code:
            description: A machine-readable error code.
            type: string
          message:
            description: A human-readable error message.
            type: string
          param:
            description: >-
              The parameter that was invalid, usually `training_file` or
              `validation_file`. This field will be null if the failure was not
              parameter-specific.
            type: string
            x-nullable: true
        required:
          - code
          - message
          - param
        type: object
        x-nullable: true
      estimated_finish:
        description: >-
          The Unix timestamp (in seconds) for when the fine-tuning job is
          estimated to finish. The value will be null if the fine-tuning job is
          not running.
        type: integer
        x-nullable: true
      fine_tuned_model:
        description: >-
          The name of the fine-tuned model that is being created. The value will
          be null if the fine-tuning job is still running.
        type: string
        x-nullable: true
      finished_at:
        description: >-
          The Unix timestamp (in seconds) for when the fine-tuning job was
          finished. The value will be null if the fine-tuning job is still
          running.
        type: integer
        x-nullable: true
      hyperparameters:
        description: >-
          The hyperparameters used for the fine-tuning job. See the [fine-tuning
          guide](/docs/guides/fine-tuning) for more details.
        properties:
          n_epochs:
            default: auto
            description: >-
              The number of epochs to train the model for. An epoch refers to
              one full cycle through the training dataset.

              "auto" decides the optimal number of epochs based on the size of
              the dataset. If setting the number manually, we support any number
              between 1 and 50 epochs.
        required:
          - n_epochs
        type: object
      id:
        description: 'The object identifier, which can be referenced in the API endpoints.'
        type: string
      integrations:
        description: A list of integrations to enable for this fine-tuning job.
        items:
          x-oaiExpandable: true
        maxItems: 5
        type: array
        x-nullable: true
      model:
        description: The base model that is being fine-tuned.
        type: string
      object:
        description: 'The object type, which is always "fine_tuning.job".'
        enum:
          - fine_tuning.job
        type: string
      organization_id:
        description: The organization that owns the fine-tuning job.
        type: string
      result_files:
        description: >-
          The compiled results file ID(s) for the fine-tuning job. You can
          retrieve the results with the [Files
          API](/docs/api-reference/files/retrieve-contents).
        items:
          example: file-abc123
          type: string
        type: array
      seed:
        description: The seed used for the fine-tuning job.
        type: integer
      status:
        description: >-
          The current status of the fine-tuning job, which can be either
          `validating_files`, `queued`, `running`, `succeeded`, `failed`, or
          `cancelled`.
        enum:
          - validating_files
          - queued
          - running
          - succeeded
          - failed
          - cancelled
        type: string
      trained_tokens:
        description: >-
          The total number of billable tokens processed by this fine-tuning job.
          The value will be null if the fine-tuning job is still running.
        type: integer
        x-nullable: true
      training_file:
        description: >-
          The file ID used for training. You can retrieve the training data with
          the [Files API](/docs/api-reference/files/retrieve-contents).
        type: string
      validation_file:
        description: >-
          The file ID used for validation. You can retrieve the validation
          results with the [Files
          API](/docs/api-reference/files/retrieve-contents).
        type: string
        x-nullable: true
    required:
      - created_at
      - error
      - finished_at
      - fine_tuned_model
      - hyperparameters
      - id
      - model
      - object
      - organization_id
      - result_files
      - status
      - trained_tokens
      - training_file
      - validation_file
      - seed
    title: FineTuningJob
    type: object
    x-oaiMeta:
      example: |
        {
          "object": "fine_tuning.job",
          "id": "ftjob-abc123",
          "model": "davinci-002",
          "created_at": 1692661014,
          "finished_at": 1692661190,
          "fine_tuned_model": "ft:davinci-002:my-org:custom_suffix:7q8mpxmy",
          "organization_id": "org-123",
          "result_files": [
              "file-abc123"
          ],
          "status": "succeeded",
          "validation_file": null,
          "training_file": "file-abc123",
          "hyperparameters": {
              "n_epochs": 4,
              "batch_size": 1,
              "learning_rate_multiplier": 1.0
          },
          "trained_tokens": 5768,
          "integrations": [],
          "seed": 0,
          "estimated_finish": 0
        }
      name: The fine-tuning job object
  FineTuningJobCheckpoint:
    description: >
      The `fine_tuning.job.checkpoint` object represents a model checkpoint for
      a fine-tuning job that is ready to use.
    properties:
      created_at:
        description: The Unix timestamp (in seconds) for when the checkpoint was created.
        type: integer
      fine_tuned_model_checkpoint:
        description: The name of the fine-tuned checkpoint model that is created.
        type: string
      fine_tuning_job_id:
        description: The name of the fine-tuning job that this checkpoint was created from.
        type: string
      id:
        description: >-
          The checkpoint identifier, which can be referenced in the API
          endpoints.
        type: string
      metrics:
        description: Metrics at the step number during the fine-tuning job.
        properties:
          full_valid_loss:
            type: number
          full_valid_mean_token_accuracy:
            type: number
          step:
            type: number
          train_loss:
            type: number
          train_mean_token_accuracy:
            type: number
          valid_loss:
            type: number
          valid_mean_token_accuracy:
            type: number
        type: object
      object:
        description: 'The object type, which is always "fine_tuning.job.checkpoint".'
        enum:
          - fine_tuning.job.checkpoint
        type: string
      step_number:
        description: The step number that the checkpoint was created at.
        type: integer
    required:
      - created_at
      - fine_tuning_job_id
      - fine_tuned_model_checkpoint
      - id
      - metrics
      - object
      - step_number
    title: FineTuningJobCheckpoint
    type: object
    x-oaiMeta:
      example: |
        {
          "object": "fine_tuning.job.checkpoint",
          "id": "ftckpt_qtZ5Gyk4BLq1SfLFWp3RtO3P",
          "created_at": 1712211699,
          "fine_tuned_model_checkpoint": "ft:gpt-3.5-turbo-0125:my-org:custom_suffix:9ABel2dg:ckpt-step-88",
          "fine_tuning_job_id": "ftjob-fpbNQ3H1GrMehXRf8cO97xTN",
          "metrics": {
            "step": 88,
            "train_loss": 0.478,
            "train_mean_token_accuracy": 0.924,
            "valid_loss": 10.112,
            "valid_mean_token_accuracy": 0.145,
            "full_valid_loss": 0.567,
            "full_valid_mean_token_accuracy": 0.944
          },
          "step_number": 88
        }
      name: The fine-tuning job checkpoint object
  FineTuningJobEvent:
    description: Fine-tuning job event object
    properties:
      created_at:
        type: integer
      id:
        type: string
      level:
        enum:
          - info
          - warn
          - error
        type: string
      message:
        type: string
      object:
        enum:
          - fine_tuning.job.event
        type: string
    required:
      - id
      - object
      - created_at
      - level
      - message
    type: object
    x-oaiMeta:
      example: |
        {
          "object": "fine_tuning.job.event",
          "id": "ftevent-abc123"
          "created_at": 1677610602,
          "level": "info",
          "message": "Created fine-tuning job"
        }
      name: The fine-tuning job event object
  FunctionObject:
    properties:
      parameters:
        $ref: '#/definitions/FunctionParameters'
      description:
        description: >-
          A description of what the function does, used by the model to choose
          when and how to call the function.
        type: string
      name:
        description: >-
          The name of the function to be called. Must be a-z, A-Z, 0-9, or
          contain underscores and dashes, with a maximum length of 64.
        type: string
    required:
      - name
    type: object
  FunctionParameters:
    additionalProperties: true
    description: >-
      The parameters the functions accepts, described as a JSON Schema object.
      See the [guide](/docs/guides/text-generation/function-calling) for
      examples, and the [JSON Schema
      reference](https://json-schema.org/understanding-json-schema/) for
      documentation about the format.


      Omitting `parameters` defines a function with an empty parameter list.
    type: object
  Image:
    description: Represents the url or the content of an image generated by the OpenAI API.
    properties:
      b64_json:
        description: >-
          The base64-encoded JSON of the generated image, if `response_format`
          is `b64_json`.
        type: string
      revised_prompt:
        description: >-
          The prompt that was used to generate the image, if there was any
          revision to the prompt.
        type: string
      url:
        description: >-
          The URL of the generated image, if `response_format` is `url`
          (default).
        type: string
    type: object
    x-oaiMeta:
      example: |
        {
          "url": "...",
          "revised_prompt": "..."
        }
      name: The image object
  ImagesResponse:
    properties:
      created:
        type: integer
      data:
        items:
          $ref: '#/definitions/Image'
        type: array
    required:
      - created
      - data
  ListAssistantsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/AssistantObject'
        type: array
      first_id:
        example: asst_abc123
        type: string
        x-nullable: true
      has_more:
        example: false
        type: boolean
      last_id:
        example: asst_abc456
        type: string
        x-nullable: true
      object:
        example: list
        type: string
        x-nullable: true
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    type: object
    x-oaiMeta:
      example: |
        {
          "object": "list",
          "data": [
            {
              "id": "asst_abc123",
              "object": "assistant",
              "created_at": 1698982736,
              "name": "Coding Tutor",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are a helpful assistant designed to make me better at coding!",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            },
            {
              "id": "asst_abc456",
              "object": "assistant",
              "created_at": 1698982718,
              "name": "My Assistant",
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": "You are a helpful assistant designed to make me better at coding!",
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            },
            {
              "id": "asst_abc789",
              "object": "assistant",
              "created_at": 1698982643,
              "name": null,
              "description": null,
              "model": "gpt-4-turbo",
              "instructions": null,
              "tools": [],
              "tool_resources": {},
              "metadata": {},
              "top_p": 1.0,
              "temperature": 1.0,
              "response_format": "auto"
            }
          ],
          "first_id": "asst_abc123",
          "last_id": "asst_abc789",
          "has_more": false
        }
      group: chat
      name: List assistants response object
  ListBatchesResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/Batch'
        type: array
      first_id:
        example: batch_abc123
        type: string
      has_more:
        type: boolean
      last_id:
        example: batch_abc456
        type: string
      object:
        enum:
          - list
        type: string
    required:
      - object
      - data
      - has_more
    type: object
  ListFilesResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/OpenAIFile'
        type: array
      object:
        enum:
          - list
        type: string
      has_more:
        type: boolean
    required:
      - object
      - data
    type: object
  ListFineTuningJobCheckpointsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/FineTuningJobCheckpoint'
        type: array
      first_id:
        type: string
        x-nullable: true
      has_more:
        type: boolean
      last_id:
        type: string
        x-nullable: true
      object:
        enum:
          - list
        type: string
    required:
      - object
      - data
      - has_more
    type: object
  ListFineTuningJobEventsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/FineTuningJobEvent'
        type: array
      object:
        enum:
          - list
        type: string
    required:
      - object
      - data
    type: object
  ListMessagesResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/MessageObject'
        type: array
      first_id:
        example: msg_abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: msg_abc123
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
  ListModelsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/Model'
        type: array
      object:
        enum:
          - list
        type: string
    required:
      - object
      - data
    type: object
  ListPaginatedFineTuningJobsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/FineTuningJob'
        type: array
      has_more:
        type: boolean
      object:
        enum:
          - list
        type: string
    required:
      - object
      - data
      - has_more
    type: object
  ListRunStepsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/RunStepObject'
        type: array
      first_id:
        example: step_abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: step_abc456
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
  ListRunsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/RunObject'
        type: array
      first_id:
        example: run_abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: run_abc456
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
    type: object
  ListThreadsResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/ThreadObject'
        type: array
      first_id:
        example: asst_abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: asst_abc456
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
  ListVectorStoreFilesResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/VectorStoreFileObject'
        type: array
      first_id:
        example: file-abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: file-abc456
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
  ListVectorStoresResponse:
    properties:
      data:
        items:
          $ref: '#/definitions/VectorStoreObject'
        type: array
      first_id:
        example: vs_abc123
        type: string
      has_more:
        example: false
        type: boolean
      last_id:
        example: vs_abc456
        type: string
      object:
        example: list
        type: string
    required:
      - object
      - data
      - first_id
      - last_id
      - has_more
  MessageContentImageFileObject:
    description: >-
      References an image [File](/docs/api-reference/files) in the content of a
      message.
    properties:
      image_file:
        properties:
          detail:
            default: auto
            description: >-
              Specifies the detail level of the image if specified by the user.
              `low` uses fewer tokens, you can opt in to high resolution using
              `high`.
            enum:
              - auto
              - low
              - high
            type: string
          file_id:
            description: >-
              The [File](/docs/api-reference/files) ID of the image in the
              message content. Set `purpose="vision"` when uploading the File if
              you need to later display the file content.
            type: string
        required:
          - file_id
        type: object
      type:
        description: Always `image_file`.
        enum:
          - image_file
        type: string
    required:
      - type
      - image_file
    title: Image file
    type: object
  MessageContentImageUrlObject:
    description: References an image URL in the content of a message.
    properties:
      image_url:
        properties:
          detail:
            default: auto
            description: >-
              Specifies the detail level of the image. `low` uses fewer tokens,
              you can opt in to high resolution using `high`. Default value is
              `auto`
            enum:
              - auto
              - low
              - high
            type: string
          url:
            description: >-
              The external URL of the image, must be a supported image types:
              jpeg, jpg, png, gif, webp.
            format: uri
            type: string
        required:
          - url
        type: object
      type:
        description: The type of the content part.
        enum:
          - image_url
        type: string
    required:
      - type
      - image_url
    title: Image URL
    type: object
  MessageContentTextAnnotationsFileCitationObject:
    description: >-
      A citation within the message that points to a specific quote from a
      specific File associated with the assistant or the message. Generated when
      the assistant uses the "file_search" tool to search files.
    properties:
      end_index:
        minimum: 0
        type: integer
      file_citation:
        properties:
          file_id:
            description: The ID of the specific File the citation is from.
            type: string
          quote:
            description: The specific quote in the file.
            type: string
        required:
          - file_id
          - quote
        type: object
      start_index:
        minimum: 0
        type: integer
      text:
        description: The text in the message content that needs to be replaced.
        type: string
      type:
        description: Always `file_citation`.
        enum:
          - file_citation
        type: string
    required:
      - type
      - text
      - file_citation
      - start_index
      - end_index
    title: File citation
    type: object
  MessageContentTextAnnotationsFilePathObject:
    description: >-
      A URL for the file that's generated when the assistant used the
      `code_interpreter` tool to generate a file.
    properties:
      end_index:
        minimum: 0
        type: integer
      file_path:
        properties:
          file_id:
            description: The ID of the file that was generated.
            type: string
        required:
          - file_id
        type: object
      start_index:
        minimum: 0
        type: integer
      text:
        description: The text in the message content that needs to be replaced.
        type: string
      type:
        description: Always `file_path`.
        enum:
          - file_path
        type: string
    required:
      - type
      - text
      - file_path
      - start_index
      - end_index
    title: File path
    type: object
  MessageContentTextObject:
    description: The text content that is part of a message.
    properties:
      text:
        properties:
          annotations:
            items:
              x-oaiExpandable: true
            type: array
          value:
            description: The data that makes up the text.
            type: string
        required:
          - value
          - annotations
        type: object
      type:
        description: Always `text`.
        enum:
          - text
        type: string
    required:
      - type
      - text
    title: Text
    type: object
  MessageDeltaContentImageFileObject:
    description: >-
      References an image [File](/docs/api-reference/files) in the content of a
      message.
    properties:
      image_file:
        properties:
          detail:
            default: auto
            description: >-
              Specifies the detail level of the image if specified by the user.
              `low` uses fewer tokens, you can opt in to high resolution using
              `high`.
            enum:
              - auto
              - low
              - high
            type: string
          file_id:
            description: >-
              The [File](/docs/api-reference/files) ID of the image in the
              message content. Set `purpose="vision"` when uploading the File if
              you need to later display the file content.
            type: string
        type: object
      index:
        description: The index of the content part in the message.
        type: integer
      type:
        description: Always `image_file`.
        enum:
          - image_file
        type: string
    required:
      - index
      - type
    title: Image file
    type: object
  MessageDeltaContentImageUrlObject:
    description: References an image URL in the content of a message.
    properties:
      image_url:
        properties:
          detail:
            default: auto
            description: >-
              Specifies the detail level of the image. `low` uses fewer tokens,
              you can opt in to high resolution using `high`.
            enum:
              - auto
              - low
              - high
            type: string
          url:
            description: >-
              The URL of the image, must be a supported image types: jpeg, jpg,
              png, gif, webp.
            type: string
        type: object
      index:
        description: The index of the content part in the message.
        type: integer
      type:
        description: Always `image_url`.
        enum:
          - image_url
        type: string
    required:
      - index
      - type
    title: Image URL
    type: object
  MessageDeltaContentTextAnnotationsFileCitationObject:
    description: >-
      A citation within the message that points to a specific quote from a
      specific File associated with the assistant or the message. Generated when
      the assistant uses the "file_search" tool to search files.
    properties:
      end_index:
        minimum: 0
        type: integer
      file_citation:
        properties:
          file_id:
            description: The ID of the specific File the citation is from.
            type: string
          quote:
            description: The specific quote in the file.
            type: string
        type: object
      index:
        description: The index of the annotation in the text content part.
        type: integer
      start_index:
        minimum: 0
        type: integer
      text:
        description: The text in the message content that needs to be replaced.
        type: string
      type:
        description: Always `file_citation`.
        enum:
          - file_citation
        type: string
    required:
      - index
      - type
    title: File citation
    type: object
  MessageDeltaContentTextAnnotationsFilePathObject:
    description: >-
      A URL for the file that's generated when the assistant used the
      `code_interpreter` tool to generate a file.
    properties:
      end_index:
        minimum: 0
        type: integer
      file_path:
        properties:
          file_id:
            description: The ID of the file that was generated.
            type: string
        type: object
      index:
        description: The index of the annotation in the text content part.
        type: integer
      start_index:
        minimum: 0
        type: integer
      text:
        description: The text in the message content that needs to be replaced.
        type: string
      type:
        description: Always `file_path`.
        enum:
          - file_path
        type: string
    required:
      - index
      - type
    title: File path
    type: object
  MessageDeltaContentTextObject:
    description: The text content that is part of a message.
    properties:
      index:
        description: The index of the content part in the message.
        type: integer
      text:
        properties:
          annotations:
            items:
              x-oaiExpandable: true
            type: array
          value:
            description: The data that makes up the text.
            type: string
        type: object
      type:
        description: Always `text`.
        enum:
          - text
        type: string
    required:
      - index
      - type
    title: Text
    type: object
  MessageDeltaObject:
    description: >
      Represents a message delta i.e. any changed fields on a message during
      streaming.
    properties:
      delta:
        description: The delta containing the fields that have changed on the Message.
        properties:
          content:
            description: The content of the message in array of text and/or images.
            items:
              x-oaiExpandable: true
            type: array
          role:
            description: >-
              The entity that produced the message. One of `user` or
              `assistant`.
            enum:
              - user
              - assistant
            type: string
        type: object
      id:
        description: >-
          The identifier of the message, which can be referenced in API
          endpoints.
        type: string
      object:
        description: 'The object type, which is always `thread.message.delta`.'
        enum:
          - thread.message.delta
        type: string
    required:
      - id
      - object
      - delta
    title: Message delta object
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "msg_123",
          "object": "thread.message.delta",
          "delta": {
            "content": [
              {
                "index": 0,
                "type": "text",
                "text": { "value": "Hello", "annotations": [] }
              }
            ]
          }
        }
      name: The message delta object
  MessageObject:
    description: 'Represents a message within a [thread](/docs/api-reference/threads).'
    properties:
      assistant_id:
        description: >-
          If applicable, the ID of the
          [assistant](/docs/api-reference/assistants) that authored this
          message.
        type: string
        x-nullable: true
      attachments:
        description: >-
          A list of files attached to the message, and the tools they were added
          to.
        items:
          properties:
            file_id:
              description: The ID of the file to attach to the message.
              type: string
            tools:
              description: The tools to add this file to.
              items:
                x-oaiExpandable: true
              type: array
          type: object
        type: array
        x-nullable: true
      completed_at:
        description: The Unix timestamp (in seconds) for when the message was completed.
        type: integer
        x-nullable: true
      content:
        description: The content of the message in array of text and/or images.
        items:
          x-oaiExpandable: true
        type: array
      created_at:
        description: The Unix timestamp (in seconds) for when the message was created.
        type: integer
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      incomplete_at:
        description: >-
          The Unix timestamp (in seconds) for when the message was marked as
          incomplete.
        type: integer
        x-nullable: true
      incomplete_details:
        description: 'On an incomplete message, details about why the message is incomplete.'
        properties:
          reason:
            description: The reason the message is incomplete.
            enum:
              - content_filter
              - max_tokens
              - run_cancelled
              - run_expired
              - run_failed
            type: string
        required:
          - reason
        type: object
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      object:
        description: 'The object type, which is always `thread.message`.'
        enum:
          - thread.message
        type: string
      role:
        description: The entity that produced the message. One of `user` or `assistant`.
        enum:
          - user
          - assistant
        type: string
      run_id:
        description: >-
          The ID of the [run](/docs/api-reference/runs) associated with the
          creation of this message. Value is `null` when messages are created
          manually using the create message or create thread endpoints.
        type: string
        x-nullable: true
      status:
        description: >-
          The status of the message, which can be either `in_progress`,
          `incomplete`, or `completed`.
        enum:
          - in_progress
          - incomplete
          - completed
        type: string
      thread_id:
        description: >-
          The [thread](/docs/api-reference/threads) ID that this message belongs
          to.
        type: string
    required:
      - id
      - object
      - created_at
      - thread_id
      - status
      - incomplete_details
      - completed_at
      - incomplete_at
      - role
      - content
      - assistant_id
      - run_id
      - attachments
      - metadata
    title: The message object
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "msg_abc123",
          "object": "thread.message",
          "created_at": 1698983503,
          "thread_id": "thread_abc123",
          "role": "assistant",
          "content": [
            {
              "type": "text",
              "text": {
                "value": "Hi! How can I help you today?",
                "annotations": []
              }
            }
          ],
          "assistant_id": "asst_abc123",
          "run_id": "run_abc123",
          "attachments": [],
          "metadata": {}
        }
      name: The message object
  MessageRequestContentTextObject:
    description: The text content that is part of a message.
    properties:
      text:
        description: Text content to be sent to the model
        type: string
      type:
        description: Always `text`.
        enum:
          - text
        type: string
    required:
      - type
      - text
    title: Text
    type: object
  MessageStreamEvent: {}
  Model:
    description: Describes an OpenAI model offering that can be used with the API.
    properties:
      created:
        description: The Unix timestamp (in seconds) when the model was created.
        type: integer
      id:
        description: 'The model identifier, which can be referenced in the API endpoints.'
        type: string
      object:
        description: 'The object type, which is always "model".'
        enum:
          - model
        type: string
      owned_by:
        description: The organization that owns the model.
        type: string
    required:
      - id
      - object
      - created
      - owned_by
    title: Model
    x-oaiMeta:
      example: |
        {
          "id": "VAR_model_id",
          "object": "model",
          "created": 1686935002,
          "owned_by": "openai"
        }
      name: The model object
  ModifyAssistantRequest:
    additionalProperties: false
    properties:
      description:
        description: >
          The description of the assistant. The maximum length is 512
          characters.
        maxLength: 512
        type: string
        x-nullable: true
      instructions:
        description: >
          The system instructions that the assistant uses. The maximum length is
          256,000 characters.
        maxLength: 256000
        type: string
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >
          ID of the model to use. You can use the [List
          models](/docs/api-reference/models/list) API to see all of your
          available models, or see our [Model overview](/docs/models/overview)
          for descriptions of them.
      name:
        description: |
          The name of the assistant. The maximum length is 256 characters.
        maxLength: 256
        type: string
        x-nullable: true
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      temperature:
        default: 1
        description: >
          What sampling temperature to use, between 0 and 2. Higher values like
          0.8 will make the output more random, while lower values like 0.2 will
          make it more focused and deterministic.
        example: 1
        maximum: 2
        minimum: 0
        type: number
        x-nullable: true
      tool_resources:
        description: >
          A set of resources that are used by the assistant's tools. The
          resources are specific to the type of tool. For example, the
          `code_interpreter` tool requires a list of file IDs, while the
          `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  Overrides the list of [file](/docs/api-reference/files) IDs
                  made available to the `code_interpreter` tool. There can be a
                  maximum of 20 files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  Overrides the [vector
                  store](/docs/api-reference/vector-stores/object) attached to
                  this assistant. There can be a maximum of 1 vector store
                  attached to the assistant.
                items:
                  type: string
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
      tools:
        default: []
        description: >
          A list of tool enabled on the assistant. There can be a maximum of 128
          tools per assistant. Tools can be of types `code_interpreter`,
          `file_search`, or `function`.
        items:
          x-oaiExpandable: true
        maxItems: 128
        type: array
      top_p:
        default: 1
        description: >
          An alternative to sampling with temperature, called nucleus sampling,
          where the model considers the results of the tokens with top_p
          probability mass. So 0.1 means only the tokens comprising the top 10%
          probability mass are considered.


          We generally recommend altering this or temperature but not both.
        example: 1
        maximum: 1
        minimum: 0
        type: number
        x-nullable: true
    type: object
  ModifyMessageRequest:
    additionalProperties: false
    properties:
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
    type: object
  ModifyRunRequest:
    additionalProperties: false
    properties:
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
    type: object
  ModifyThreadRequest:
    additionalProperties: false
    properties:
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      tool_resources:
        description: >
          A set of resources that are made available to the assistant's tools in
          this thread. The resources are specific to the type of tool. For
          example, the `code_interpreter` tool requires a list of file IDs,
          while the `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The [vector store](/docs/api-reference/vector-stores/object)
                  attached to this thread. There can be a maximum of 1 vector
                  store attached to the thread.
                items:
                  type: string
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
    type: object
  OpenAIFile:
    description: The `File` object represents a document that has been uploaded to OpenAI.
    properties:
      bytes:
        description: 'The size of the file, in bytes.'
        type: integer
      created_at:
        description: The Unix timestamp (in seconds) for when the file was created.
        type: integer
      filename:
        description: The name of the file.
        type: string
      id:
        description: 'The file identifier, which can be referenced in the API endpoints.'
        type: string
      object:
        description: 'The object type, which is always `file`.'
        enum:
          - file
        type: string
      purpose:
        description: >-
          The intended purpose of the file. Supported values are `assistants`,
          `assistants_output`, `batch`, `batch_output`, `fine-tune`,
          `fine-tune-results` and `vision`.
        enum:
          - assistants
          - assistants_output
          - batch
          - batch_output
          - fine-tune
          - fine-tune-results
          - vision
        type: string
      status:
        deprecated: true
        description: >-
          Deprecated. The current status of the file, which can be either
          `uploaded`, `processed`, or `error`.
        enum:
          - uploaded
          - processed
          - error
        type: string
        x-nullable: true
      status_details:
        deprecated: true
        description: >-
          Deprecated. For details on why a fine-tuning training file failed
          validation, see the `error` field on `fine_tuning.job`.
        type: string
        x-nullable: true
    required:
      - id
      - object
      - bytes
      - created_at
      - filename
      - purpose
      - status
    title: OpenAIFile
    x-oaiMeta:
      example: |
        {
          "id": "file-abc123",
          "object": "file",
          "bytes": 120000,
          "created_at": 1677610602,
          "filename": "salesOverview.pdf",
          "purpose": "assistants",
        }
      name: The file object
  RunCompletionUsage:
    description: >-
      Usage statistics related to the run. This value will be `null` if the run
      is not in a terminal state (i.e. `in_progress`, `queued`, etc.).
    properties:
      completion_tokens:
        description: Number of completion tokens used over the course of the run.
        type: integer
      prompt_tokens:
        description: Number of prompt tokens used over the course of the run.
        type: integer
      total_tokens:
        description: Total number of tokens used (prompt + completion).
        type: integer
    required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
    type: object
    x-nullable: true
  RunObject:
    description: 'Represents an execution run on a [thread](/docs/api-reference/threads).'
    properties:
      assistant_id:
        description: >-
          The ID of the [assistant](/docs/api-reference/assistants) used for
          execution of this run.
        type: string
      cancelled_at:
        description: The Unix timestamp (in seconds) for when the run was cancelled.
        type: integer
        x-nullable: true
      completed_at:
        description: The Unix timestamp (in seconds) for when the run was completed.
        type: integer
        x-nullable: true
      created_at:
        description: The Unix timestamp (in seconds) for when the run was created.
        type: integer
      expires_at:
        description: The Unix timestamp (in seconds) for when the run will expire.
        type: integer
        x-nullable: true
      failed_at:
        description: The Unix timestamp (in seconds) for when the run failed.
        type: integer
        x-nullable: true
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      incomplete_details:
        description: >-
          Details on why the run is incomplete. Will be `null` if the run is not
          incomplete.
        properties:
          reason:
            description: >-
              The reason why the run is incomplete. This will point to which
              specific token limit was reached over the course of the run.
            enum:
              - max_completion_tokens
              - max_prompt_tokens
            type: string
        type: object
        x-nullable: true
      instructions:
        description: >-
          The instructions that the [assistant](/docs/api-reference/assistants)
          used for this run.
        type: string
      last_error:
        description: >-
          The last error associated with this run. Will be `null` if there are
          no errors.
        properties:
          code:
            description: 'One of `server_error`, `rate_limit_exceeded`, or `invalid_prompt`.'
            enum:
              - server_error
              - rate_limit_exceeded
              - invalid_prompt
            type: string
          message:
            description: A human-readable description of the error.
            type: string
        required:
          - code
          - message
        type: object
        x-nullable: true
      max_completion_tokens:
        description: >
          The maximum number of completion tokens specified to have been used
          over the course of the run.
        minimum: 256
        type: integer
        x-nullable: true
      max_prompt_tokens:
        description: >
          The maximum number of prompt tokens specified to have been used over
          the course of the run.
        minimum: 256
        type: integer
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      model:
        description: >-
          The model that the [assistant](/docs/api-reference/assistants) used
          for this run.
        type: string
      object:
        description: 'The object type, which is always `thread.run`.'
        enum:
          - thread.run
        type: string
      required_action:
        description: >-
          Details on the action required to continue the run. Will be `null` if
          no action is required.
        properties:
          submit_tool_outputs:
            description: Details on the tool outputs needed for this run to continue.
            properties:
              tool_calls:
                description: A list of the relevant tool calls.
                items:
                  $ref: '#/definitions/RunToolCallObject'
                type: array
            required:
              - tool_calls
            type: object
          type:
            description: 'For now, this is always `submit_tool_outputs`.'
            enum:
              - submit_tool_outputs
            type: string
        required:
          - type
          - submit_tool_outputs
        type: object
        x-nullable: true
      response_format:
        $ref: '#/definitions/AssistantsApiResponseFormatOption'
        x-nullable: true
      started_at:
        description: The Unix timestamp (in seconds) for when the run was started.
        type: integer
        x-nullable: true
      status:
        description: >-
          The status of the run, which can be either `queued`, `in_progress`,
          `requires_action`, `cancelling`, `cancelled`, `failed`, `completed`,
          `incomplete`, or `expired`.
        enum:
          - queued
          - in_progress
          - requires_action
          - cancelling
          - cancelled
          - failed
          - completed
          - incomplete
          - expired
        type: string
      temperature:
        description: 'The sampling temperature used for this run. If not set, defaults to 1.'
        type: number
        x-nullable: true
      thread_id:
        description: >-
          The ID of the [thread](/docs/api-reference/threads) that was executed
          on as a part of this run.
        type: string
      tool_choice:
        $ref: '#/definitions/AssistantsApiToolChoiceOption'
        x-nullable: true
      tools:
        default: []
        description: >-
          The list of tools that the [assistant](/docs/api-reference/assistants)
          used for this run.
        items:
          x-oaiExpandable: true
        maxItems: 20
        type: array
      top_p:
        description: >-
          The nucleus sampling value used for this run. If not set, defaults to
          1.
        type: number
        x-nullable: true
      truncation_strategy:
        $ref: '#/definitions/TruncationObject'
        x-nullable: true
      usage:
        $ref: '#/definitions/RunCompletionUsage'
    required:
      - id
      - object
      - created_at
      - thread_id
      - assistant_id
      - status
      - required_action
      - last_error
      - expires_at
      - started_at
      - cancelled_at
      - failed_at
      - completed_at
      - model
      - instructions
      - tools
      - metadata
      - usage
      - incomplete_details
      - max_prompt_tokens
      - max_completion_tokens
      - truncation_strategy
      - tool_choice
      - response_format
    title: A run on a thread
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "run_abc123",
          "object": "thread.run",
          "created_at": 1698107661,
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "status": "completed",
          "started_at": 1699073476,
          "expires_at": null,
          "cancelled_at": null,
          "failed_at": null,
          "completed_at": 1699073498,
          "last_error": null,
          "model": "gpt-4-turbo",
          "instructions": null,
          "tools": [{"type": "file_search"}, {"type": "code_interpreter"}],
          "metadata": {},
          "incomplete_details": null,
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          },
          "temperature": 1.0,
          "top_p": 1.0,
          "max_prompt_tokens": 1000,
          "max_completion_tokens": 1000,
          "truncation_strategy": {
            "type": "auto",
            "last_messages": null
          },
          "response_format": "auto",
          "tool_choice": "auto"
        }
      name: The run object
  RunStepCompletionUsage:
    description: >-
      Usage statistics related to the run step. This value will be `null` while
      the run step's status is `in_progress`.
    properties:
      completion_tokens:
        description: Number of completion tokens used over the course of the run step.
        type: integer
      prompt_tokens:
        description: Number of prompt tokens used over the course of the run step.
        type: integer
      total_tokens:
        description: Total number of tokens used (prompt + completion).
        type: integer
    required:
      - prompt_tokens
      - completion_tokens
      - total_tokens
    type: object
    x-nullable: true
  RunStepDeltaObject:
    description: >
      Represents a run step delta i.e. any changed fields on a run step during
      streaming.
    properties:
      delta:
        description: The delta containing the fields that have changed on the run step.
        properties:
          step_details:
            description: The details of the run step.
            type: object
            x-oaiExpandable: true
        type: object
      id:
        description: >-
          The identifier of the run step, which can be referenced in API
          endpoints.
        type: string
      object:
        description: 'The object type, which is always `thread.run.step.delta`.'
        enum:
          - thread.run.step.delta
        type: string
    required:
      - id
      - object
      - delta
    title: Run step delta object
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "step_123",
          "object": "thread.run.step.delta",
          "delta": {
            "step_details": {
              "type": "tool_calls",
              "tool_calls": [
                {
                  "index": 0,
                  "id": "call_123",
                  "type": "code_interpreter",
                  "code_interpreter": { "input": "", "outputs": [] }
                }
              ]
            }
          }
        }
      name: The run step delta object
  RunStepDeltaStepDetailsMessageCreationObject:
    description: Details of the message creation by the run step.
    properties:
      message_creation:
        properties:
          message_id:
            description: The ID of the message that was created by this run step.
            type: string
        type: object
      type:
        description: Always `message_creation`.
        enum:
          - message_creation
        type: string
    required:
      - type
    title: Message creation
    type: object
  RunStepDeltaStepDetailsToolCallsCodeObject:
    description: Details of the Code Interpreter tool call the run step was involved in.
    properties:
      code_interpreter:
        description: The Code Interpreter tool call definition.
        properties:
          input:
            description: The input to the Code Interpreter tool call.
            type: string
          outputs:
            description: >-
              The outputs from the Code Interpreter tool call. Code Interpreter
              can output one or more items, including text (`logs`) or images
              (`image`). Each of these are represented by a different object
              type.
            items:
              type: object
              x-oaiExpandable: true
            type: array
        type: object
      id:
        description: The ID of the tool call.
        type: string
      index:
        description: The index of the tool call in the tool calls array.
        type: integer
      type:
        description: >-
          The type of tool call. This is always going to be `code_interpreter`
          for this type of tool call.
        enum:
          - code_interpreter
        type: string
    required:
      - index
      - type
    title: Code interpreter tool call
    type: object
  RunStepDeltaStepDetailsToolCallsCodeOutputImageObject:
    properties:
      image:
        properties:
          file_id:
            description: 'The [file](/docs/api-reference/files) ID of the image.'
            type: string
        type: object
      index:
        description: The index of the output in the outputs array.
        type: integer
      type:
        description: Always `image`.
        enum:
          - image
        type: string
    required:
      - index
      - type
    title: Code interpreter image output
    type: object
  RunStepDeltaStepDetailsToolCallsCodeOutputLogsObject:
    description: Text output from the Code Interpreter tool call as part of a run step.
    properties:
      index:
        description: The index of the output in the outputs array.
        type: integer
      logs:
        description: The text output from the Code Interpreter tool call.
        type: string
      type:
        description: Always `logs`.
        enum:
          - logs
        type: string
    required:
      - index
      - type
    title: Code interpreter log output
    type: object
  RunStepDeltaStepDetailsToolCallsFileSearchObject:
    properties:
      file_search:
        description: 'For now, this is always going to be an empty object.'
        type: object
        x-oaiTypeLabel: map
      id:
        description: The ID of the tool call object.
        type: string
      index:
        description: The index of the tool call in the tool calls array.
        type: integer
      type:
        description: >-
          The type of tool call. This is always going to be `file_search` for
          this type of tool call.
        enum:
          - file_search
        type: string
    required:
      - index
      - type
      - file_search
    title: File search tool call
    type: object
  RunStepDeltaStepDetailsToolCallsFunctionObject:
    properties:
      function:
        description: The definition of the function that was called.
        properties:
          arguments:
            description: The arguments passed to the function.
            type: string
          name:
            description: The name of the function.
            type: string
          output:
            description: >-
              The output of the function. This will be `null` if the outputs
              have not been
              [submitted](/docs/api-reference/runs/submitToolOutputs) yet.
            type: string
            x-nullable: true
        type: object
      id:
        description: The ID of the tool call object.
        type: string
      index:
        description: The index of the tool call in the tool calls array.
        type: integer
      type:
        description: >-
          The type of tool call. This is always going to be `function` for this
          type of tool call.
        enum:
          - function
        type: string
    required:
      - index
      - type
    title: Function tool call
    type: object
  RunStepDeltaStepDetailsToolCallsObject:
    description: Details of the tool call.
    properties:
      tool_calls:
        description: >
          An array of tool calls the run step was involved in. These can be
          associated with one of three types of tools: `code_interpreter`,
          `file_search`, or `function`.
        items:
          x-oaiExpandable: true
        type: array
      type:
        description: Always `tool_calls`.
        enum:
          - tool_calls
        type: string
    required:
      - type
    title: Tool calls
    type: object
  RunStepDetailsMessageCreationObject:
    description: Details of the message creation by the run step.
    properties:
      message_creation:
        properties:
          message_id:
            description: The ID of the message that was created by this run step.
            type: string
        required:
          - message_id
        type: object
      type:
        description: Always `message_creation`.
        enum:
          - message_creation
        type: string
    required:
      - type
      - message_creation
    title: Message creation
    type: object
  RunStepDetailsToolCallsCodeObject:
    description: Details of the Code Interpreter tool call the run step was involved in.
    properties:
      code_interpreter:
        description: The Code Interpreter tool call definition.
        properties:
          input:
            description: The input to the Code Interpreter tool call.
            type: string
          outputs:
            description: >-
              The outputs from the Code Interpreter tool call. Code Interpreter
              can output one or more items, including text (`logs`) or images
              (`image`). Each of these are represented by a different object
              type.
            items:
              type: object
              x-oaiExpandable: true
            type: array
        required:
          - input
          - outputs
        type: object
      id:
        description: The ID of the tool call.
        type: string
      type:
        description: >-
          The type of tool call. This is always going to be `code_interpreter`
          for this type of tool call.
        enum:
          - code_interpreter
        type: string
    required:
      - id
      - type
      - code_interpreter
    title: Code Interpreter tool call
    type: object
  RunStepDetailsToolCallsCodeOutputImageObject:
    properties:
      image:
        properties:
          file_id:
            description: 'The [file](/docs/api-reference/files) ID of the image.'
            type: string
        required:
          - file_id
        type: object
      type:
        description: Always `image`.
        enum:
          - image
        type: string
    required:
      - type
      - image
    title: Code Interpreter image output
    type: object
  RunStepDetailsToolCallsCodeOutputLogsObject:
    description: Text output from the Code Interpreter tool call as part of a run step.
    properties:
      logs:
        description: The text output from the Code Interpreter tool call.
        type: string
      type:
        description: Always `logs`.
        enum:
          - logs
        type: string
    required:
      - type
      - logs
    title: Code Interpreter log output
    type: object
  RunStepDetailsToolCallsFileSearchObject:
    properties:
      file_search:
        description: 'For now, this is always going to be an empty object.'
        type: object
        x-oaiTypeLabel: map
      id:
        description: The ID of the tool call object.
        type: string
      type:
        description: >-
          The type of tool call. This is always going to be `file_search` for
          this type of tool call.
        enum:
          - file_search
        type: string
    required:
      - id
      - type
      - file_search
    title: File search tool call
    type: object
  RunStepDetailsToolCallsFunctionObject:
    properties:
      function:
        description: The definition of the function that was called.
        properties:
          arguments:
            description: The arguments passed to the function.
            type: string
          name:
            description: The name of the function.
            type: string
          output:
            description: >-
              The output of the function. This will be `null` if the outputs
              have not been
              [submitted](/docs/api-reference/runs/submitToolOutputs) yet.
            type: string
            x-nullable: true
        required:
          - name
          - arguments
          - output
        type: object
      id:
        description: The ID of the tool call object.
        type: string
      type:
        description: >-
          The type of tool call. This is always going to be `function` for this
          type of tool call.
        enum:
          - function
        type: string
    required:
      - id
      - type
      - function
    title: Function tool call
    type: object
  RunStepDetailsToolCallsObject:
    description: Details of the tool call.
    properties:
      tool_calls:
        description: >
          An array of tool calls the run step was involved in. These can be
          associated with one of three types of tools: `code_interpreter`,
          `file_search`, or `function`.
        items:
          x-oaiExpandable: true
        type: array
      type:
        description: Always `tool_calls`.
        enum:
          - tool_calls
        type: string
    required:
      - type
      - tool_calls
    title: Tool calls
    type: object
  RunStepObject:
    description: |
      Represents a step in execution of a run.
    properties:
      assistant_id:
        description: >-
          The ID of the [assistant](/docs/api-reference/assistants) associated
          with the run step.
        type: string
      cancelled_at:
        description: The Unix timestamp (in seconds) for when the run step was cancelled.
        type: integer
        x-nullable: true
      completed_at:
        description: The Unix timestamp (in seconds) for when the run step completed.
        type: integer
        x-nullable: true
      created_at:
        description: The Unix timestamp (in seconds) for when the run step was created.
        type: integer
      expired_at:
        description: >-
          The Unix timestamp (in seconds) for when the run step expired. A step
          is considered expired if the parent run is expired.
        type: integer
        x-nullable: true
      failed_at:
        description: The Unix timestamp (in seconds) for when the run step failed.
        type: integer
        x-nullable: true
      id:
        description: >-
          The identifier of the run step, which can be referenced in API
          endpoints.
        type: string
      last_error:
        description: >-
          The last error associated with this run step. Will be `null` if there
          are no errors.
        properties:
          code:
            description: One of `server_error` or `rate_limit_exceeded`.
            enum:
              - server_error
              - rate_limit_exceeded
            type: string
          message:
            description: A human-readable description of the error.
            type: string
        required:
          - code
          - message
        type: object
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      object:
        description: 'The object type, which is always `thread.run.step`.'
        enum:
          - thread.run.step
        type: string
      run_id:
        description: >-
          The ID of the [run](/docs/api-reference/runs) that this run step is a
          part of.
        type: string
      status:
        description: >-
          The status of the run step, which can be either `in_progress`,
          `cancelled`, `failed`, `completed`, or `expired`.
        enum:
          - in_progress
          - cancelled
          - failed
          - completed
          - expired
        type: string
      step_details:
        description: The details of the run step.
        type: object
        x-oaiExpandable: true
      thread_id:
        description: 'The ID of the [thread](/docs/api-reference/threads) that was run.'
        type: string
      type:
        description: >-
          The type of run step, which can be either `message_creation` or
          `tool_calls`.
        enum:
          - message_creation
          - tool_calls
        type: string
      usage:
        $ref: '#/definitions/RunStepCompletionUsage'
    required:
      - id
      - object
      - created_at
      - assistant_id
      - thread_id
      - run_id
      - type
      - status
      - step_details
      - last_error
      - expired_at
      - cancelled_at
      - failed_at
      - completed_at
      - metadata
      - usage
    title: Run steps
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "step_abc123",
          "object": "thread.run.step",
          "created_at": 1699063291,
          "run_id": "run_abc123",
          "assistant_id": "asst_abc123",
          "thread_id": "thread_abc123",
          "type": "message_creation",
          "status": "completed",
          "cancelled_at": null,
          "completed_at": 1699063291,
          "expired_at": null,
          "failed_at": null,
          "last_error": null,
          "step_details": {
            "type": "message_creation",
            "message_creation": {
              "message_id": "msg_abc123"
            }
          },
          "usage": {
            "prompt_tokens": 123,
            "completion_tokens": 456,
            "total_tokens": 579
          }
        }
      name: The run step object
  RunStepStreamEvent: {}
  RunStreamEvent: {}
  RunToolCallObject:
    description: Tool call objects
    properties:
      function:
        description: The function definition.
        properties:
          arguments:
            description: The arguments that the model expects you to pass to the function.
            type: string
          name:
            description: The name of the function.
            type: string
        required:
          - name
          - arguments
        type: object
      id:
        description: >-
          The ID of the tool call. This ID must be referenced when you submit
          the tool outputs in using the [Submit tool outputs to
          run](/docs/api-reference/runs/submitToolOutputs) endpoint.
        type: string
      type:
        description: >-
          The type of tool call the output is required for. For now, this is
          always `function`.
        enum:
          - function
        type: string
    required:
      - id
      - type
      - function
    type: object
  SubmitToolOutputsRunRequest:
    additionalProperties: false
    properties:
      stream:
        description: >
          If `true`, returns a stream of events that happen during the Run as
          server-sent events, terminating when the Run enters a terminal state
          with a `data: [DONE]` message.
        type: boolean
        x-nullable: true
      tool_outputs:
        description: A list of tools for which the outputs are being submitted.
        items:
          properties:
            output:
              description: The output of the tool call to be submitted to continue the run.
              type: string
            tool_call_id:
              description: >-
                The ID of the tool call in the `required_action` object within
                the run object the output is being submitted for.
              type: string
          type: object
        type: array
    required:
      - tool_outputs
    type: object
  ThreadObject:
    description: >-
      Represents a thread that contains
      [messages](/docs/api-reference/messages).
    properties:
      created_at:
        description: The Unix timestamp (in seconds) for when the thread was created.
        type: integer
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      object:
        description: 'The object type, which is always `thread`.'
        enum:
          - thread
        type: string
      tool_resources:
        description: >
          A set of resources that are made available to the assistant's tools in
          this thread. The resources are specific to the type of tool. For
          example, the `code_interpreter` tool requires a list of file IDs,
          while the `file_search` tool requires a list of vector store IDs.
        properties:
          code_interpreter:
            properties:
              file_ids:
                default: []
                description: >
                  A list of [file](/docs/api-reference/files) IDs made available
                  to the `code_interpreter` tool. There can be a maximum of 20
                  files associated with the tool.
                items:
                  type: string
                maxItems: 20
                type: array
            type: object
          file_search:
            properties:
              vector_store_ids:
                description: >
                  The [vector store](/docs/api-reference/vector-stores/object)
                  attached to this thread. There can be a maximum of 1 vector
                  store attached to the thread.
                items:
                  type: string
                maxItems: 1
                type: array
            type: object
        type: object
        x-nullable: true
    required:
      - id
      - object
      - created_at
      - tool_resources
      - metadata
    title: Thread
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "thread_abc123",
          "object": "thread",
          "created_at": 1698107661,
          "metadata": {}
        }
      name: The thread object
  ThreadStreamEvent: {}
  TranscriptionSegment:
    properties:
      avg_logprob:
        description: >-
          Average logprob of the segment. If the value is lower than -1,
          consider the logprobs failed.
        format: float
        type: number
      compression_ratio:
        description: >-
          Compression ratio of the segment. If the value is greater than 2.4,
          consider the compression failed.
        format: float
        type: number
      end:
        description: End time of the segment in seconds.
        format: float
        type: number
      id:
        description: Unique identifier of the segment.
        type: integer
      no_speech_prob:
        description: >-
          Probability of no speech in the segment. If the value is higher than
          1.0 and the `avg_logprob` is below -1, consider this segment silent.
        format: float
        type: number
      seek:
        description: Seek offset of the segment.
        type: integer
      start:
        description: Start time of the segment in seconds.
        format: float
        type: number
      temperature:
        description: Temperature parameter used for generating the segment.
        format: float
        type: number
      text:
        description: Text content of the segment.
        type: string
      tokens:
        description: Array of token IDs for the text content.
        items:
          type: integer
        type: array
    required:
      - id
      - seek
      - start
      - end
      - text
      - tokens
      - temperature
      - avg_logprob
      - compression_ratio
      - no_speech_prob
    type: object
  TranscriptionWord:
    properties:
      end:
        description: End time of the word in seconds.
        format: float
        type: number
      start:
        description: Start time of the word in seconds.
        format: float
        type: number
      word:
        description: The text content of the word.
        type: string
    required:
      - word
      - start
      - end
    type: object
  TruncationObject:
    description: >-
      Controls for how a thread will be truncated prior to the run. Use this to
      control the intial context window of the run.
    properties:
      last_messages:
        description: >-
          The number of most recent messages from the thread when constructing
          the context for the run.
        minimum: 1
        type: integer
        x-nullable: true
      type:
        description: >-
          The truncation strategy to use for the thread. The default is `auto`.
          If set to `last_messages`, the thread will be truncated to the n most
          recent messages in the thread. When set to `auto`, messages in the
          middle of the thread will be dropped to fit the context length of the
          model, `max_prompt_tokens`.
        enum:
          - auto
          - last_messages
        type: string
    required:
      - type
    title: Thread Truncation Controls
    type: object
  UpdateVectorStoreRequest:
    additionalProperties: false
    properties:
      expires_after:
        $ref: '#/definitions/VectorStoreExpirationAfter'
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      name:
        description: The name of the vector store.
        type: string
        x-nullable: true
    type: object
  VectorStoreExpirationAfter:
    description: The expiration policy for a vector store.
    properties:
      anchor:
        description: >-
          Anchor timestamp after which the expiration policy applies. Supported
          anchors: `last_active_at`.
        enum:
          - last_active_at
        type: string
      days:
        description: >-
          The number of days after the anchor time that the vector store will
          expire.
        maximum: 365
        minimum: 1
        type: integer
    required:
      - anchor
      - days
    title: Vector store expiration policy
    type: object
  VectorStoreFileBatchObject:
    description: A batch of files attached to a vector store.
    properties:
      created_at:
        description: >-
          The Unix timestamp (in seconds) for when the vector store files batch
          was created.
        type: integer
      file_counts:
        properties:
          cancelled:
            description: The number of files that where cancelled.
            type: integer
          completed:
            description: The number of files that have been processed.
            type: integer
          failed:
            description: The number of files that have failed to process.
            type: integer
          in_progress:
            description: The number of files that are currently being processed.
            type: integer
          total:
            description: The total number of files.
            type: integer
        required:
          - in_progress
          - completed
          - cancelled
          - failed
          - total
        type: object
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      object:
        description: 'The object type, which is always `vector_store.file_batch`.'
        enum:
          - vector_store.files_batch
        type: string
      status:
        description: >-
          The status of the vector store files batch, which can be either
          `in_progress`, `completed`, `cancelled` or `failed`.
        enum:
          - in_progress
          - completed
          - cancelled
          - failed
        type: string
      vector_store_id:
        description: >-
          The ID of the [vector store](/docs/api-reference/vector-stores/object)
          that the [File](/docs/api-reference/files) is attached to.
        type: string
    required:
      - id
      - object
      - created_at
      - vector_store_id
      - status
      - file_counts
    title: Vector store file batch
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "vsfb_123",
          "object": "vector_store.files_batch",
          "created_at": 1698107661,
          "vector_store_id": "vs_abc123",
          "status": "completed",
          "file_counts": {
            "in_progress": 0,
            "completed": 100,
            "failed": 0,
            "cancelled": 0,
            "total": 100
          }
        }
      name: The vector store files batch object
  VectorStoreFileObject:
    description: A list of files attached to a vector store.
    properties:
      created_at:
        description: >-
          The Unix timestamp (in seconds) for when the vector store file was
          created.
        type: integer
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      last_error:
        description: >-
          The last error associated with this vector store file. Will be `null`
          if there are no errors.
        properties:
          code:
            description: One of `server_error` or `rate_limit_exceeded`.
            enum:
              - internal_error
              - file_not_found
              - parsing_error
              - unhandled_mime_type
            type: string
          message:
            description: A human-readable description of the error.
            type: string
        required:
          - code
          - message
        type: object
        x-nullable: true
      object:
        description: 'The object type, which is always `vector_store.file`.'
        enum:
          - vector_store.file
        type: string
      status:
        description: >-
          The status of the vector store file, which can be either
          `in_progress`, `completed`, `cancelled`, or `failed`. The status
          `completed` indicates that the vector store file is ready for use.
        enum:
          - in_progress
          - completed
          - cancelled
          - failed
        type: string
      usage_bytes:
        description: >-
          The total vector store usage in bytes. Note that this may be different
          from the original file size.
        type: integer
      vector_store_id:
        description: >-
          The ID of the [vector store](/docs/api-reference/vector-stores/object)
          that the [File](/docs/api-reference/files) is attached to.
        type: string
    required:
      - id
      - object
      - usage_bytes
      - created_at
      - vector_store_id
      - status
      - last_error
    title: Vector store files
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "file-abc123",
          "object": "vector_store.file",
          "usage_bytes": 1234,
          "created_at": 1698107661,
          "vector_store_id": "vs_abc123",
          "status": "completed",
          "last_error": null
        }
      name: The vector store file object
  VectorStoreObject:
    description: >-
      A vector store is a collection of processed files can be used by the
      `file_search` tool.
    properties:
      created_at:
        description: The Unix timestamp (in seconds) for when the vector store was created.
        type: integer
      expires_after:
        $ref: '#/definitions/VectorStoreExpirationAfter'
      expires_at:
        description: The Unix timestamp (in seconds) for when the vector store will expire.
        type: integer
        x-nullable: true
      file_counts:
        properties:
          cancelled:
            description: The number of files that were cancelled.
            type: integer
          completed:
            description: The number of files that have been successfully processed.
            type: integer
          failed:
            description: The number of files that have failed to process.
            type: integer
          in_progress:
            description: The number of files that are currently being processed.
            type: integer
          total:
            description: The total number of files.
            type: integer
        required:
          - in_progress
          - completed
          - failed
          - cancelled
          - total
        type: object
      id:
        description: 'The identifier, which can be referenced in API endpoints.'
        type: string
      last_active_at:
        description: >-
          The Unix timestamp (in seconds) for when the vector store was last
          active.
        type: integer
        x-nullable: true
      metadata:
        description: >
          Set of 16 key-value pairs that can be attached to an object. This can
          be useful for storing additional information about the object in a
          structured format. Keys can be a maximum of 64 characters long and
          values can be a maxium of 512 characters long.
        type: object
        x-nullable: true
        x-oaiTypeLabel: map
      name:
        description: The name of the vector store.
        type: string
      object:
        description: 'The object type, which is always `vector_store`.'
        enum:
          - vector_store
        type: string
      status:
        description: >-
          The status of the vector store, which can be either `expired`,
          `in_progress`, or `completed`. A status of `completed` indicates that
          the vector store is ready for use.
        enum:
          - expired
          - in_progress
          - completed
        type: string
      usage_bytes:
        description: The total number of bytes used by the files in the vector store.
        type: integer
    required:
      - id
      - object
      - usage_bytes
      - created_at
      - status
      - last_active_at
      - name
      - file_counts
      - metadata
    title: Vector store
    type: object
    x-oaiMeta:
      beta: true
      example: |
        {
          "id": "vs_123",
          "object": "vector_store",
          "created_at": 1698107661,
          "usage_bytes": 123456,
          "last_active_at": 1698107661,
          "name": "my_vector_store",
          "status": "completed",
          "file_counts": {
            "in_progress": 0,
            "completed": 100,
            "cancelled": 0,
            "failed": 0,
            "total": 100
          },
          "metadata": {},
          "last_used_at": 1698107661
        }
      name: The vector store object
securityDefinitions:
  ApiKeyAuth:
    in: header
    name: Authorization
    type: apiKey
security:
  - ApiKeyAuth: []
tags:
  - description: Build Assistants that can call models and use tools.
    name: Assistants
  - description: Learn how to turn audio into text or text into audio.
    name: Audio
  - description: >-
      Given a list of messages comprising a conversation, the model will return
      a response.
    name: Chat
  - description: >-
      Given a prompt, the model will return one or more predicted completions,
      and can also return the probabilities of alternative tokens at each
      position.
    name: Completions
  - description: >-
      Get a vector representation of a given input that can be easily consumed
      by machine learning models and algorithms.
    name: Embeddings
  - description: Manage fine-tuning jobs to tailor a model to your specific training data.
    name: Fine-tuning
  - description: Create large batches of API requests to run asynchronously.
    name: Batch
  - description: >-
      Files are used to upload documents that can be used with features like
      Assistants and Fine-tuning.
    name: Files
  - description: 'Given a prompt and/or an input image, the model will generate a new image.'
    name: Images
  - description: List and describe the various models available in the API.
    name: Models
  - description: >-
      Given a input text, outputs if the model classifies it as potentially
      harmful.
    name: Moderations
x-components: {}
x-oaiMeta:
  groups:
    - description: |
        Learn how to turn audio into text or text into audio.

        Related guide: [Speech to text](/docs/guides/speech-to-text)
      id: audio
      navigationGroup: endpoints
      sections:
        - key: createSpeech
          path: createSpeech
          type: endpoint
        - key: createTranscription
          path: createTranscription
          type: endpoint
        - key: createTranslation
          path: createTranslation
          type: endpoint
        - key: CreateTranscriptionResponseJson
          path: json-object
          type: object
        - key: CreateTranscriptionResponseVerboseJson
          path: verbose-json-object
          type: object
      title: Audio
    - description: >
        Given a list of messages comprising a conversation, the model will
        return a response.


        Related guide: [Chat Completions](/docs/guides/text-generation)
      id: chat
      navigationGroup: endpoints
      sections:
        - key: createChatCompletion
          path: create
          type: endpoint
        - key: CreateChatCompletionResponse
          path: object
          type: object
        - key: CreateChatCompletionStreamResponse
          path: streaming
          type: object
      title: Chat
    - description: >
        Get a vector representation of a given input that can be easily consumed
        by machine learning models and algorithms.


        Related guide: [Embeddings](/docs/guides/embeddings)
      id: embeddings
      navigationGroup: endpoints
      sections:
        - key: createEmbedding
          path: create
          type: endpoint
        - key: Embedding
          path: object
          type: object
      title: Embeddings
    - description: >
        Manage fine-tuning jobs to tailor a model to your specific training
        data.


        Related guide: [Fine-tune models](/docs/guides/fine-tuning)
      id: fine-tuning
      navigationGroup: endpoints
      sections:
        - key: createFineTuningJob
          path: create
          type: endpoint
        - key: listPaginatedFineTuningJobs
          path: list
          type: endpoint
        - key: listFineTuningEvents
          path: list-events
          type: endpoint
        - key: listFineTuningJobCheckpoints
          path: list-checkpoints
          type: endpoint
        - key: retrieveFineTuningJob
          path: retrieve
          type: endpoint
        - key: cancelFineTuningJob
          path: cancel
          type: endpoint
        - key: FineTuningJob
          path: object
          type: object
        - key: FineTuningJobEvent
          path: event-object
          type: object
        - key: FineTuningJobCheckpoint
          path: checkpoint-object
          type: object
      title: Fine-tuning
    - description: >
        Create large batches of API requests for asynchronous processing. The
        Batch API returns completions within 24 hours for a 50% discount.


        Related guide: [Batch](/docs/guides/batch)
      id: batch
      navigationGroup: endpoints
      sections:
        - key: createBatch
          path: create
          type: endpoint
        - key: retrieveBatch
          path: retrieve
          type: endpoint
        - key: cancelBatch
          path: cancel
          type: endpoint
        - key: listBatches
          path: list
          type: endpoint
        - key: Batch
          path: object
          type: object
        - key: BatchRequestInput
          path: requestInput
          type: object
        - key: BatchRequestOutput
          path: requestOutput
          type: object
      title: Batch
    - description: >
        Files are used to upload documents that can be used with features like
        [Assistants](/docs/api-reference/assistants),
        [Fine-tuning](/docs/api-reference/fine-tuning), and [Batch
        API](/docs/guides/batch).
      id: files
      navigationGroup: endpoints
      sections:
        - key: createFile
          path: create
          type: endpoint
        - key: listFiles
          path: list
          type: endpoint
        - key: retrieveFile
          path: retrieve
          type: endpoint
        - key: deleteFile
          path: delete
          type: endpoint
        - key: downloadFile
          path: retrieve-contents
          type: endpoint
        - key: OpenAIFile
          path: object
          type: object
      title: Files
    - description: >
        Given a prompt and/or an input image, the model will generate a new
        image.


        Related guide: [Image generation](/docs/guides/images)
      id: images
      navigationGroup: endpoints
      sections:
        - key: createImage
          path: create
          type: endpoint
        - key: createImageEdit
          path: createEdit
          type: endpoint
        - key: createImageVariation
          path: createVariation
          type: endpoint
        - key: Image
          path: object
          type: object
      title: Images
    - description: >
        List and describe the various models available in the API. You can refer
        to the [Models](/docs/models) documentation to understand what models
        are available and the differences between them.
      id: models
      navigationGroup: endpoints
      sections:
        - key: listModels
          path: list
          type: endpoint
        - key: retrieveModel
          path: retrieve
          type: endpoint
        - key: deleteModel
          path: delete
          type: endpoint
        - key: Model
          path: object
          type: object
      title: Models
    - description: >
        Given some input text, outputs if the model classifies it as potentially
        harmful across several categories.


        Related guide: [Moderations](/docs/guides/moderation)
      id: moderations
      navigationGroup: endpoints
      sections:
        - key: createModeration
          path: create
          type: endpoint
        - key: CreateModerationResponse
          path: object
          type: object
      title: Moderations
    - beta: true
      description: |
        Build assistants that can call models and use tools to perform tasks.

        [Get started with the Assistants API](/docs/assistants)
      id: assistants
      navigationGroup: assistants
      sections:
        - key: createAssistant
          path: createAssistant
          type: endpoint
        - key: listAssistants
          path: listAssistants
          type: endpoint
        - key: getAssistant
          path: getAssistant
          type: endpoint
        - key: modifyAssistant
          path: modifyAssistant
          type: endpoint
        - key: deleteAssistant
          path: deleteAssistant
          type: endpoint
        - key: AssistantObject
          path: object
          type: object
      title: Assistants
    - beta: true
      description: |
        Create threads that assistants can interact with.

        Related guide: [Assistants](/docs/assistants/overview)
      id: threads
      navigationGroup: assistants
      sections:
        - key: createThread
          path: createThread
          type: endpoint
        - key: getThread
          path: getThread
          type: endpoint
        - key: modifyThread
          path: modifyThread
          type: endpoint
        - key: deleteThread
          path: deleteThread
          type: endpoint
        - key: ThreadObject
          path: object
          type: object
      title: Threads
    - beta: true
      description: |
        Create messages within threads

        Related guide: [Assistants](/docs/assistants/overview)
      id: messages
      navigationGroup: assistants
      sections:
        - key: createMessage
          path: createMessage
          type: endpoint
        - key: listMessages
          path: listMessages
          type: endpoint
        - key: getMessage
          path: getMessage
          type: endpoint
        - key: modifyMessage
          path: modifyMessage
          type: endpoint
        - key: deleteMessage
          path: deleteMessage
          type: endpoint
        - key: MessageObject
          path: object
          type: object
      title: Messages
    - beta: true
      description: |
        Represents an execution run on a thread.

        Related guide: [Assistants](/docs/assistants/overview)
      id: runs
      navigationGroup: assistants
      sections:
        - key: createRun
          path: createRun
          type: endpoint
        - key: createThreadAndRun
          path: createThreadAndRun
          type: endpoint
        - key: listRuns
          path: listRuns
          type: endpoint
        - key: getRun
          path: getRun
          type: endpoint
        - key: modifyRun
          path: modifyRun
          type: endpoint
        - key: submitToolOuputsToRun
          path: submitToolOutputs
          type: endpoint
        - key: cancelRun
          path: cancelRun
          type: endpoint
        - key: RunObject
          path: object
          type: object
      title: Runs
    - beta: true
      description: |
        Represents the steps (model and tool calls) taken during the run.

        Related guide: [Assistants](/docs/assistants/overview)
      id: run-steps
      navigationGroup: assistants
      sections:
        - key: listRunSteps
          path: listRunSteps
          type: endpoint
        - key: getRunStep
          path: getRunStep
          type: endpoint
        - key: RunStepObject
          path: step-object
          type: object
      title: Run Steps
    - beta: true
      description: |
        Vector stores are used to store files for use by the `file_search` tool.

        Related guide: [File Search](/docs/assistants/tools/file-search)
      id: vector-stores
      navigationGroup: assistants
      sections:
        - key: createVectorStore
          path: create
          type: endpoint
        - key: listVectorStores
          path: list
          type: endpoint
        - key: getVectorStore
          path: retrieve
          type: endpoint
        - key: modifyVectorStore
          path: modify
          type: endpoint
        - key: deleteVectorStore
          path: delete
          type: endpoint
        - key: VectorStoreObject
          path: object
          type: object
      title: Vector Stores
    - beta: true
      description: |
        Vector store files represent files inside a vector store.

        Related guide: [File Search](/docs/assistants/tools/file-search)
      id: vector-stores-files
      navigationGroup: assistants
      sections:
        - key: createVectorStoreFile
          path: createFile
          type: endpoint
        - key: listVectorStoreFiles
          path: listFiles
          type: endpoint
        - key: getVectorStoreFile
          path: getFile
          type: endpoint
        - key: deleteVectorStoreFile
          path: deleteFile
          type: endpoint
        - key: VectorStoreFileObject
          path: file-object
          type: object
      title: Vector Store Files
    - beta: true
      description: >
        Vector store file batches represent operations to add multiple files to
        a vector store.


        Related guide: [File Search](/docs/assistants/tools/file-search)
      id: vector-stores-file-batches
      navigationGroup: assistants
      sections:
        - key: createVectorStoreFileBatch
          path: createBatch
          type: endpoint
        - key: getVectorStoreFileBatch
          path: getBatch
          type: endpoint
        - key: cancelVectorStoreFileBatch
          path: cancelBatch
          type: endpoint
        - key: listFilesInVectorStoreBatch
          path: listBatchFiles
          type: endpoint
        - key: VectorStoreFileBatchObject
          path: batch-object
          type: object
      title: Vector Store File Batches
    - beta: true
      description: >
        Stream the result of executing a Run or resuming a Run after submitting
        tool outputs.


        You can stream events from the [Create Thread and
        Run](/docs/api-reference/runs/createThreadAndRun),

        [Create Run](/docs/api-reference/runs/createRun), and [Submit Tool
        Outputs](/docs/api-reference/runs/submitToolOutputs)

        endpoints by passing `"stream": true`. The response will be a
        [Server-Sent
        events](https://html.spec.whatwg.org/multipage/server-sent-events.html#server-sent-events)
        stream.


        Our Node and Python SDKs provide helpful utilities to make streaming
        easy. Reference the

        [Assistants API quickstart](/docs/assistants/overview) to learn more.
      id: assistants-streaming
      navigationGroup: assistants
      sections:
        - key: MessageDeltaObject
          path: message-delta-object
          type: object
        - key: RunStepDeltaObject
          path: run-step-delta-object
          type: object
        - key: AssistantStreamEvent
          path: events
          type: object
      title: Streaming
    - description: >
        Given a prompt, the model will return one or more predicted completions
        along with the probabilities of alternative tokens at each position.
        Most developer should use our [Chat Completions
        API](/docs/guides/text-generation/text-generation-models) to leverage
        our best and newest models.
      id: completions
      legacy: true
      navigationGroup: legacy
      sections:
        - key: createCompletion
          path: create
          type: endpoint
        - key: CreateCompletionResponse
          path: object
          type: object
      title: Completions
  navigationGroups:
    - id: endpoints
      title: Endpoints
    - id: assistants
      title: Assistants
    - id: legacy
      title: Legacy


#!/usr/bin/env qore
# -*- mode: qore; indent-tabs-mode: nil -*-

%new-style
%enable-all-warnings
%require-types
%strict-args

module SqlUtilTestBase {
    version = "1.0";
    desc = "SqlUtil test base module";
    author = "David Nichols <david@qore.org>";
    url = "http://qore.org";
    license = "MIT";
}

%requires(reexport) ../../../../qlib/Util.qm
%requires(reexport) ../../../../qlib/QUnit.qm
%requires(reexport) ../../../../qlib/Logger.qm
%requires(reexport) ../../../../qlib/DataProvider
%requires(reexport) ../../../../qlib/SqlUtil
%requires(reexport) ../../../../qlib/BulkSqlUtil
%requires(reexport) ../../../../qlib/Schema.qm
%requires(reexport) ../../../../qlib/DbDataProvider
%requires(reexport) ../../../../qlib/Mapper.qm

public class SqlUtilTestSchema inherits AbstractSchema {
    private {
        # see testAnalyticFunctions() for more info.
        # the table is the same everywhere
        const T_TestAnalyticFunctions = {
            "columns": {
                "id": c_number(),
                "row_type": c_varchar(10),
                "row_value": c_number(),
            },
        };
    }

    constructor(AbstractDatasource ds, *string dts, *string its) : AbstractSchema(ds, dts, its) {
    }

    private *hash<auto> doTables(hash<auto> tables, hash<auto> columns) {
        foreach string table in (keys tables) {
            foreach hash<auto> h in (columns.pairIterator()) {
                string type = h.value.type ?? h.key;
                hash<GenericColumnInfo> ch({
                    "native_type": type,
                });
                if (h.value.typeCode() == NT_HASH)
                    ch += (h.value - ("value", "bind", "expect", "type", "soft"));
                tables{table}.columns{SqlTestBase::getColumnName(h.key)} = ch;
            }
        }
        return tables;
    }

    log(string fmt) {
        delete argv;
    }

    logpf(string fmt) {
        delete argv;
    }

    logProgress(string fmt) {
        delete argv;
    }
}

public class SqlTestBase inherits QUnit::Test {
    private {
        AbstractSchema schema;
        AbstractTable table;

        const MyOpts = Opts + (
            "connstr": "c,conn=s",
        );

        const OptionColumn = 22;

        hash expect_data;
        hash<string, bool> softmap;

        list insert_data;
        list upsert_data;

        Logger logger;
    }

    constructor(string testName, string testVer, any args, *hash mopts) : Test(testName, testVer, \args, mopts) {
        {
            LoggerLevel level;
            if (m_options.verbose > 3) {
                level = LoggerLevel::getLevelDebug();
            } else if (m_options.verbose > 2) {
                level = LoggerLevel::getLevelInfo();
            } else {
                level = LoggerLevel::getLevelError();
            }
            logger = new Logger("test", level);
        }
        logger.addAppender(new TestAppender());

        addTestCase("driver name", \driverNameTest());
        addTestCase("db provider", \dbProviderTest());
        addTestCase("db table provider", \dbTableProviderTest());
        addTestCase("Insert", \insertTest());
        addTestCase("Select", \selectTest());
        addTestCase("Column Operators", \columnOperatorTest());
        addTestCase("Update Operators", \updateOperatorTest());
        addTestCase("Where Operators", \whereOperatorTest());
        addTestCase("Group By", \groupByTest());
        addTestCase("Order By", \orderByTest());
        addTestCase("Offset / Limit", \offsetLimitTest());
        addTestCase("Update", \updateTest());
        addTestCase("Upsert", \upsertTest());
        # Cannot delete because additional tests in the module-specific .qtest files
        # are too inter-connected (tightly coupled) to these tests' DB modifications.
        addTestCase("BulkInsert", \bulkInsertTest());
        addTestCase("BulkUpsert", \bulkUpsertTest());
        addTestCase("fetchColumns", \fetchColumnsTest());
        addTestCase("Delete", \deleteTest());
        addTestCase("result set placeholder", \resultSetPlaceholderTest());
        addTestCase("Serialization", \serializationTest());
        addTestCase("wrong schema", \test2358SqlutilSchema());
        addTestCase("get DB size #3385", \testGetPhysicalSize());
    }

    globalTearDown() {
        # drop the test schema
        if (schema) {
            schema.drop(True, m_options.verbose);
        }
    }

    driverNameTest() {
        assertEq(getExpectedDriverName(), table ? table.getDatasource().getDriverRealName() : "");
    }

    serializationTest() {
        if (!table) testSkip("no DB connection");

        hash<SerializationInfo> h = table.serializeToData();
        AbstractTable t = AbstractTable::deserialize(h);
        assertTrue(t instanceof AbstractTable);
        # test that the table object works
        string sql = t.getSelectSql(("columns": "id", "limit": 1));
        assertEq(Type::String, sql.type());
    }

    dbProviderTest() {
        if (!table) testSkip("no DB connection");

        DbDataProvider db(table.getDatasource());
        db.setLogger(logger);
        assertTrue(db.supportsCreateChild());
        assertTrue(db.supportsDeleteChild());

        string name = "test_table_" + get_random_string();
        hash<string, QoreDataField> fields = {
            "id": new QoreDataField("id", "id field", IntType),
            "name": new QoreDataField("name", "name field",
                new QoreStringDataType({"string.max_size_chars": 30})),
            "desc": new QoreDataField("desc", "desc field", StringOrNothingType),
            "date": new QoreDataField("date", "date field", DateType),
            "data": new QoreDataField("data", "data field", BinaryOrNothingType),
            "float": new QoreDataField("float", "float field", FloatType),
            "number": new QoreDataField("number", "number field", NumberType),
        };
        hash<auto> table_opts = {
            "primary_key": "id",
            "indexes": {
                "sk1_" + name: {
                    "columns": "name",
                    "unique": True,
                },
            },
        };
        AbstractDataProvider dp = db.createChildProvider(name, fields, table_opts);
        on_exit {
            db.deleteChildProvider(dp.getName());
        }
        assertTrue(dp.requiresTransactionManagement());
        hash<auto> record = {
            "id": rand(),
            "name": get_random_string(),
            "desc": NULL,
            "date": now(),
            "data": <abcd>,
            "float": 1.1,
            "number": 1.1n,
        };
        dp.createRecord(record);
        assertEq(record - "float", dp.searchSingleRecord({"id": record.id}) - "float");
        assertThrows("DUPLICATE-RECORD", \dp.createRecord(), record);
        {
            hash<auto> record2 = record;
            record2.id = rand();
            assertThrows("DUPLICATE-RECORD", \dp.createRecord(), record2);
        }

        # create a dependent table
        string name2 = "test_table_" + get_random_string();
        fields = {
            "id": new QoreDataField("id", "id field", IntType),
            "name2": new QoreDataField("name2", "name2 field",
                new QoreStringDataType({"string.max_size_chars": 20})),
        };
        table_opts = {
            "indexes": {
                "sk1_" + name2: {
                    "columns": "name2",
                },
                "sk2_" + name2: {
                    "columns": ("id", "name2"),
                    "unique": True,
                },
            },
            "foreign_constraints": {
                "fk1_" + name2: {
                    "columns": "id",
                    "table": dp.getName(),
                },
            },
        };
        AbstractDataProvider dp2 = db.createChildProvider(name2, fields, table_opts);
        on_exit {
            db.deleteChildProvider(dp2.getName());
        }
        assertTrue(dp2.requiresTransactionManagement());
        hash<auto> child_record = {
            "id": record.id,
            "name2": get_random_string(),
        };
        dp2.createRecord(child_record);
        assertEq(child_record, dp2.searchSingleRecord({"id": record.id}));
        child_record.name2 = get_random_string();
        dp2.createRecord(child_record);
        assertEq(child_record, dp2.searchSingleRecord({"id": record.id, "name2": child_record.name2}));
        assertThrows("DUPLICATE-RECORD", \dp2.createRecord(), child_record);
        {
            child_record.id = rand();
            assertThrows("CREATE-RECORD-ERROR", \dp2.createRecord(), child_record);
        }

        dp2.addField(new QoreDataField("comment", "comment field",
            new QoreStringOrNothingDataType({"string.max_size_chars": 30})));
        child_record = {
            "id": record.id,
            "name2": get_random_string(),
            "comment": get_random_string(),
        };
        dp2.createRecord(child_record);
        assertEq(child_record, dp2.searchSingleRecord({"id": record.id, "name2": child_record.name2}));

        child_record.comment = get_random_string(50);
        assertThrows("UPDATE-RECORDS-ERROR", \dp2.updateRecords(), ({"comment": child_record.comment},
            child_record{"id", "name2"}));

        # update field
        dp2.updateField("comment", new QoreDataField("comment2", "comment2 field",
            new QoreStringOrNothingDataType({"string.max_size_chars": 60})));
        child_record.comment2 = remove child_record.comment;
        dp2.updateRecords({"comment2": child_record.comment2}, child_record{"id", "name2"});
        assertEq(child_record, dp2.searchSingleRecord({"id": record.id, "name2": child_record.name2}));

        # delete field
        dp2.deleteField("comment2");
        remove child_record.comment2;
        assertEq(child_record, dp2.searchSingleRecord({"id": record.id, "name2": child_record.name2}));
    }

    dbTableProviderTest() {
        if (!table) testSkip("no DB connection");

        {
            DbTableDataProvider dp(table);

            assertTrue(dp.requiresTransactionManagement());

            AbstractDataProviderBulkOperation inserter = dp.getBulkInserter();
            on_error {
                inserter.discard();
                inserter.rollback();
            }
            on_success {
                inserter.flush();
                inserter.commit();
            }

            map inserter.queueData($1), insert_data;

            hash<string, hash<MapperRuntimeKeyInfo>> mapper_keys = dp.getInfo().mapper_keys;
            assertEq(("value",), mapper_keys.name.unique_roles);
            assertEq(("*",), mapper_keys.constant.unique_roles);
        }

        on_exit {
            on_error table.rollback();
            on_success table.commit();

            table.truncate();
        }

        assertFalse(table.empty());

        {
            DbTableDataProvider dp(table);

            {
                hash<DataProviderInfo> info = dp.getInfo();
                assertTrue(info.has_record);
                assertTrue(info.supports_bulk_read);
            }

            list<hash<auto>> table_rows;
            {
                table_rows = map $1, dp.searchRecords();
                assertEq(2, table_rows.size());

                hash<auto> row = dp.searchSingleRecord({"id": 1});
                assertEq(Type::Int, row.id.type());
            }

            {
                AbstractDataProviderBulkRecordInterface i = dp.getBulkRecordInterface();
                hash<auto> q = i.getValue();
                assertEq(Type::List, q.firstValue().type());
                assertEq(2, q.firstValue().lsize());
            }

            assertThrows("RUNTIME-TYPE-ERROR", \dp.searchSingleRecord(), {"id": <00>});

            # get first string column
            string fname;
            foreach QoreDataField field in (dp.getRecordType().iterator()) {
                if (field.getType().getReturnTypeHash().string) {
                    fname = field.getName();
                    break;
                }
            }

            if (fname) {
                # test update API
                AbstractDatasource ds = table.getDatasource();
                assertFalse(ds.currentThreadInTransaction());
                string rstr = get_random_string();
                assertTrue(dp.updateSingleRecord({fname: rstr}, {"id": 1}));
                assertFalse(ds.currentThreadInTransaction());

                hash<auto> row = dp.searchSingleRecord({"id": 1});
                assertEq(rstr, row{fname});

                list<hash<auto>> rows = map $1, dp.searchRecords();
                assertEq(2, rows.size());

                assertEq(1, dp.deleteRecords({"id": 1}));
                ds.beginTransaction();
                on_error ds.rollback();
                on_success ds.commit();
                assertTrue(ds.currentThreadInTransaction());

                {
                    AbstractSavepointHelper sph = table.getSavepointHelper();
                    on_exit {
                        sph.rollback();
                        assertTrue(ds.currentThreadInTransaction());
                    }
                    assertThrows("UPDATE-RECORDS-ERROR", \dp.updateSingleRecord(), ({"id": <00>}, {"id": 1}));
                    assertThrows("UPDATE-RECORDS-ERROR", \dp.updateSingleRecord(), ({"id": NULL}, {"id": 1}));
                }

                # get not null columns for upsert output
                hash<auto> not_null_map = map {$1.name: $1.name}, table.describe().iterator(), !$1.nullable;

                # test mappers with data providers
                {
                    Mapper m({"new_id": "id"}, {"input_provider": dp, "input_provider_search": {"id": 2}});
                    MapperOutputRecordIterator i = m.getOutputIterator();
                    list<hash<auto>> recs = map $1, i;
                    assertEq(1, recs.size());
                    assertEq(2, recs[0].new_id);
                }

                # NOTE: we cannot use the same datasource for input and output data providers
                # get row with id = 2
                hash<auto> row_id_2;
                foreach hash<auto> table_row in (table_rows) {
                    if (table_row.id == 2) {
                        row_id_2 = table_row;
                        break;
                    }
                }
                assertEq(2, row_id_2.id);

                {
                    Mapper m(not_null_map + {fname: {"code": string sub (*string fname, hash<auto> rec) { return fname + "-x"; }}}, {
                        "input": dp.getRecordType(),
                        "output_provider": dp,
                        "output_provider_upsert": True,
                    });
                    list<hash<auto>> recs;
                    {
                        on_error {
                            m.rollback();
                        }
                        on_success {
                            m.commit();
                        }
                        recs = m.mapAll(row_id_2);
                    }
                    assertEq(1, recs.size());
                    assertEq(row_id_2{fname} + "-x", recs[0]{fname});
                }

                {
                    Mapper m({"new_id": "id", fname: fname}, {"input_provider": dp, "input_provider_search": {"id": 2}});
                    MapperOutputRecordIterator i = m.getOutputIterator();
                    list<hash<auto>> recs = map $1, i;
                    assertEq(1, recs.size());
                    assertEq(2, recs[0].new_id);
                    assertEq(row_id_2{fname} + "-x", recs[0]{fname});
                }

                {
                    Mapper m(not_null_map + {fname: {"code": string sub (*string fname, hash<auto> rec) { return fname + "-x-y"; }}}, {
                        "input": dp.getRecordType(),
                        "output_provider": dp,
                        "output_provider_upsert": True,
                        "output_provider_bulk": True,
                    });
                    list<hash<auto>> recs;
                    {
                        on_error {
                            m.discardOutput();
                            m.rollback();
                        }
                        on_success {
                            m.flushOutput();
                            m.commit();
                        }
                        recs = m.mapAll(row_id_2);
                    }
                    assertEq(1, recs.size());
                    assertEq(row_id_2{fname} + "-x-y", recs[0]{fname});
                }

                {
                    Mapper m({"new_id": "id", fname: fname}, {"input_provider": dp, "input_provider_search": {"id": 2}});
                    MapperOutputRecordIterator i = m.getOutputIterator();
                    list<hash<auto>> recs = map $1, i;
                    assertEq(1, recs.size());
                    assertEq(2, recs[0].new_id);
                    assertEq(row_id_2{fname} + "-x-y", recs[0]{fname});
                }
            }
        }
    }

    insertTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql;
        on_error printf("SQL: %s\n", sql);

        foreach hash data in (insert_data)
            assertEq(NOTHING, table.insert(data, \sql));
    }

    selectTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql;
        on_error printf("SQL: %s\n", sql);

        *list<auto> rows = table.selectRows({}, \sql);
        assertEq(2, rows.size());
        {
            list<auto> columns = (
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": OP_SUBSTR,
                            "args": (
                                <DataProviderFieldReference>{"field": "char_f"},
                                1,
                                2,
                            ),
                        },
                        "substr",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_PREPEND,
                            "args": (
                                <DataProviderFieldReference>{"field": "null_f"},
                                "x-",
                            ),
                        },
                        "prepend",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_APPEND,
                            "args": (
                                <DataProviderFieldReference>{"field": "null_f"},
                                "-x",
                            ),
                        },
                        "append",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_UPPER,
                            "args": (
                                "upper",
                            ),
                        },
                        "upper",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_LOWER,
                            "args": (
                                "LOWER",
                            ),
                        },
                        "lower",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_MINUS,
                            "args": (
                                2,
                                1,
                            ),
                        },
                        "minus",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_PLUS,
                            "args": (
                                1,
                                1,
                            ),
                        },
                        "plus",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_DIVIDE,
                            "args": (
                                4,
                                2,
                            ),
                        },
                        "divide",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_MULTIPLY,
                            "args": (
                                2,
                                2,
                            ),
                        },
                        "multiply",
                    ),
                },
                "*",
            );
            hash<DataProviderExpression> cond = <DataProviderExpression>{
                "exp": DP_OP_OR,
                "args": (
                    <DataProviderExpression>{
                        "exp": DP_SEARCH_OP_EQ,
                        "args": (
                            <DataProviderFieldReference>{"field": "id"},
                            1,
                        ),
                    },
                    <DataProviderExpression>{
                        "exp": DP_SEARCH_OP_EQ,
                        "args": (
                            <DataProviderFieldReference>{"field": "id"},
                            2,
                        ),
                    },
                )
            };
            hash<auto> sh = {
                "columns": columns,
                "where": cond,
                "orderby": "id",
            };
            rows = table.selectRows(sh, \sql);
            on_error printf("rows: %N\n", rows);
            assertEq(2, rows.size());
            assertEq(1, rows[0].id);
            assertEq("he", rows[0].substr);
            assertEq("x-abc", rows[0].prepend);
            assertEq("abc-x", rows[0].append);
            assertEq("UPPER", rows[0].upper);
            assertEq("lower", rows[0].lower);
            assertEq(1, rows[0].minus);
            assertEq(2, rows[0].plus);
            assertEq(2, rows[0].divide);
            assertEq(4, rows[0].multiply);
            assertEq(2, rows[1].id);
            assertEq("he", rows[1].substr);

            columns = (
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_AVG,
                            "args": (
                                1,
                            ),
                        },
                        "avg",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_SUM,
                            "args": (
                                1,
                            ),
                        },
                        "sum",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_MIN,
                            "args": (
                                <DataProviderFieldReference>{"field": "id"},
                            ),
                        },
                        "min",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_MAX,
                            "args": (
                                <DataProviderFieldReference>{"field": "id"},
                            ),
                        },
                        "max",
                    ),
                },
                <DataProviderExpression>{
                    "exp": COP_AS,
                    "args": (
                        <DataProviderExpression>{
                            "exp": COP_COUNT,
                        },
                        "count",
                    ),
                },
            );
            sh = {
                "columns": columns,
            };
            hash<auto> row = table.selectRow(sh, \sql);
            on_error printf("row: %y\n", row);
            assertEq(1, row.avg);
            assertEq(2, row.sum);
            assertEq(1, row.min);
            assertEq(2, row.max);
            assertEq(2, row.count);
        }

        # check date/time literals
        {
            date now = now_us();
            hash<auto> date_check = {
                "columns": (cop_as(cop_value(now), "now")),
                "limit": 1,
            };
            date dbnow = table.selectRow(date_check, \sql).now;
            assertEq(now, dbnow);
        }

        foreach hash<auto> e in (expect_data.pairIterator()) {
            # printf("* %s\n", e.key);
            # printf("  I: %s: %N\n", insert_data[0]{e.key}.type(), insert_data[0]{e.key});
            # printf("  R: %s: %N\n", rows[0]{e.key}.type(), rows[0]{e.key});
            if (e.value === NOTHING) {
                assertSkip("checking data in column " + e.key);
            } else {
                on_error printf("v: %y (%d %s) r: %y (%d %s)\n", e.value, e.value.size(), e.value.encoding(),
                    rows[0]{e.key}, rows[0]{e.key}.size(), rows[0]{e.key}.encoding());
                if (softmap{e.key}) {
                    assertEq(e.value, rows[0]{e.key}, "checking data in column " + e.key);
                } else {
                    assertEq(e.value, rows[0]{e.key}, "checking data in column " + e.key);
                }
            }
        }

        # select a single column and then asterisk
        string col = table.describe().firstKey();
        hash<auto> sh = (
            "columns": (cop_as(col, "table"), "*"),
            # issue #2163: make sure we can reference aliases that are keywords
            "where": ("table": op_ceq(col)),
            "limit": 1,
        );

        assertEq(Type::Hash, table.selectRow(sh, \sql).type());
        sh = {
            "join": join_inner(table, "t", ("id": "id")),
            "limit": 1,
        };

        assertEq(("id", "id_1"), table.select(sh).("id", "id_1").keys());
        assertEq(("id", "id_1"), table.selectRows(sh)[0].("id", "id_1").keys());
        assertEq(("id", "id_1"), table.selectRow(sh).("id", "id_1").keys());

        # tests for issue #1909
        sh = {
            "columns": "t0.*",
            "join": join_inner(table, "t1", ("id": "id")),
            "limit": 1,
            "alias": "t0",
        };
        {
            list<string> cols = table.describe().keys();
            assertEq(cols, table.select(sh).keys());
            assertEq(cols, table.selectRows(sh)[0].keys());
            assertEq(cols, table.selectRow(sh).keys());
        }

        # issue #3371
        {
            sh = {
                "columns": "id",
                "where": {
                    "id": op_in_select(table, {
                        "columns": "id",
                        "where": {
                            "id": 1,
                        },
                    }),
                },
            };
            assertEq(1, table.selectRow(sh, \sql).id);
        }
    }

    updateTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        map assertEq(1, table.update($1 - "id", ("id": $1.id), \sql)), insert_data;
    }

    upsertTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        code upsert = table.getUpsertClosure(upsert_data[0]);
        assertEq(AbstractTable::UR_Verified, upsert(upsert_data[0]));
        # upsert can return UR_Verified even when rows are upserted when there is an optimized upsert implementation used in the driver-specific SqlUtil module
        assertEq(True, inlist(upsert(upsert_data[1]), (AbstractTable::UR_Inserted, AbstractTable::UR_Verified)));

        # test the omit_update upsert option
        softlist ud = upsert_data[upsert_data.size() - 1];
        ud += ud[0];
        ud[0]."id_" = 4;
        ud[1]."id" = 4;
        ud[1]."id_" = 4;
        upsert = table.getUpsertClosure(ud[0], AbstractTable::UpsertAuto, ("omit_update": "id_"));
        assertEq(AbstractTable::UR_Verified, upsert(ud[0]));
        # upsert can return UR_Verified even when rows are upserted when there is an optimized upsert implementation used in the driver-specific SqlUtil module
        assertEq(True, inlist(upsert(ud[1]), (AbstractTable::UR_Inserted, AbstractTable::UR_Verified)));
        assertEq(2, table.selectRow(("columns": ("id_"), "where": ("id": 3)))."id_");
        hash<SqlResultInfo> info = table.selectRowWithInfo(("columns": ("id_"), "where": ("id": 4)));
        assertEq(4, info.result."id_");
        assertEq(Type::String, info.sql.type());
        assertTrue(info.sql =~ /^select id_ from /);
        assertEq((4,), info.args);

        # test UpsertUpdateOnly
        ud[0]."id" = 4;
        ud[0]."id_" = -4;
        ud[1]."id" = 5;
        ud[1]."id_" = 4;
        upsert = table.getUpsertClosure(ud[0], AbstractTable::UpsertUpdateOnly);
        assertEq(AbstractTable::UR_Verified, upsert(ud[0]));
        assertEq(AbstractTable::UR_Unchanged, upsert(ud[1]));
        assertEq(-4, table.selectRow(("columns": ("id_"), "where": ("id": 4)))."id_");
        assertEq(NOTHING, table.selectRow(("columns": ("id_"), "where": ("id": 5))));

        # test UpsertInsertOnly
        ud[0]."id" = 4;
        ud[0]."id_" = 4;
        ud[1]."id" = 5;
        ud[1]."id_" = 5;
        upsert = table.getUpsertClosure(ud[0], AbstractTable::UpsertInsertOnly);
        assertEq(AbstractTable::UR_Unchanged, upsert(ud[0]));
        assertEq("inserted", AbstractTable::UpsertResultMap{upsert(ud[1])});
        assertEq(-4, table.selectRow(("columns": ("id_"), "where": ("id": 4)))."id_");
        assertEq(5, table.selectRow(("columns": ("id_"), "where": ("id": 5)))."id_");

        # test the omit_update upsert option with bulk upserts
        ud += ud[0];
        ud[1]."id_" = -5;
        # create hash of lists for bulk upsert
        hash uh;
        map (map uh{$1.key} += ($1.value,), $1.pairIterator()), ud;

        upsert = table.getBulkUpsertClosure(ud[0], AbstractTable::UpsertAuto, ("omit_update": "id_"));
        assertEq(AbstractTable::UR_Verified, upsert(uh));
        assertEq(-4, table.selectRow(("columns": ("id_"), "where": ("id": 4)))."id_");
        assertEq(5, table.selectRow(("columns": ("id_"), "where": ("id": 5)))."id_");

        # test UpsertUpdateOnly with bulk upsert
        ud[0]."id" = 5;
        ud[0]."id_" = -5;
        ud[1]."id" = 6;
        ud[1]."id_" = 6;
        upsert = table.getBulkUpsertClosure(ud[0], AbstractTable::UpsertUpdateOnly);
        # create hash of lists for bulk upsert
        delete uh;
        map (map uh{$1.key} += ($1.value,), $1.pairIterator()), ud;
        assertEq(AbstractTable::UR_Verified, upsert(uh));
        assertEq(-5, table.selectRow(("columns": ("id_"), "where": ("id": 5)))."id_");
        assertEq(NOTHING, table.selectRow(("columns": ("id_"), "where": ("id": 6))));

        # test UpsertInsertOnly with bulk upsert
        ud[0]."id_" = 5;
        upsert = table.getBulkUpsertClosure(ud[0], AbstractTable::UpsertInsertOnly);
        # create hash of lists for bulk upsert
        delete uh;
        map (map uh{$1.key} += ($1.value,), $1.pairIterator()), ud;
        assertEq(AbstractTable::UR_Verified, upsert(uh));
        assertEq(-5, table.selectRow(("columns": ("id_"), "where": ("id": 5)))."id_");
        assertEq(6, table.selectRow(("columns": ("id_"), "where": ("id": 6)))."id_");
    }

    bulkInsertTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        table.del();

        BulkInsertOperation insert(table);
        on_success insert.flush();
        on_error insert.discard();

        foreach hash data in (insert_data)
            assertEq(NOTHING, insert.queueData(data));
    }

    bulkUpsertTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        table.del();

        BulkUpsertOperation insert(table);
        on_success insert.flush();
        on_error insert.discard();

        foreach hash data in (upsert_data)
            assertEq(NOTHING, insert.queueData(data));
    }

    columnOperatorTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        Columns cols = table.describe();
        string vc = cols.hasKey("varchar_f") ? "varchar_f" : "varchar2_f";

        hash soh = (
            "columns": (
                cop_as(cop_cast("id", "string"), "cop_cast"),
                cop_as(cop_value(0), "cop_value"), # triggers bug #511 (GitHub)
                cop_as(cop_lower(cop_value ("Ahoj")), "cop_lower"),
                cop_as(cop_upper(cop_value ("Ahoj")), "cop_upper"),
                cop_as(cop_prepend(cop_value ("abc"), "def"), "cop_prepend"),
                cop_as(cop_append(cop_value ("abc"), "def"), "cop_append"),
                cop_as(cop_substr(cop_value ("honeymoon"), 6), "cop_substr_1"),
                cop_as(cop_substr(cop_value ("hematology"), 3, 4), "cop_substr_2"),
                cop_as(cop_minus("id", "id"), "cop_minus"),
                cop_as(cop_plus("id", "id"), "cop_plus"),
                cop_as(cop_divide("id", "id"), "cop_divide"),
                cop_as(cop_multiply("id", "id"), "cop_multiply"),
                cop_as(cop_coalesce("null_f", vc, "char_f"), "cop_coalesce"),
                cop_as(cop_coalesce("null_f", cop_value("test")), "cop_coalesce2"),
                cop_as(cop_length(cop_value("hi")), "cop_length"),
                cop_as(cop_minus("id", cop_value(2)), "cop_minus_value"),
                cop_as(cop_plus("id", cop_value(2)), "cop_plus_value"),
                cop_as(cop_divide("id", cop_value(2)), "cop_divide_value"),
                cop_as(cop_multiply("id", cop_value(10)), "cop_multiply_value"),
                cop_as(cop_value(1), "cop_as_ok"), # cop_as with any word
                cop_as(cop_value(1), "from"), # cop_as with reserved word
            ),
            "where": ("id": 2, "cop_lower": cop_lower("cop_upper")),
        );

        *hash row = table.selectRow (soh, \sql);

        hash expect = (
            "cop_cast": "2",
            "cop_value": 0,
            "cop_lower": "ahoj",
            "cop_upper": "AHOJ",
            "cop_prepend": "defabc",
            "cop_append": "abcdef",
            "cop_substr_1": "moon",
            "cop_substr_2": "mato",
            "cop_minus": 0,
            "cop_plus": 4,
            "cop_divide": 1,
            "cop_multiply": 4,
            "cop_coalesce": "hello",
            "cop_length": 2,
            "cop_minus_value": 0,
            "cop_plus_value": 4,
            "cop_divide_value": 1,
            "cop_multiply_value": 20,
            "cop_as_ok": 1,
            "from": 1,
        );

        map assertEq($1.value, row{$1.key}, "checking column operator " + $1.key), expect.pairIterator();

        soh = (
            "columns": (
                cop_as("char_f", "pivo"),
                cop_as(cop_min("id"), "cop_min"),
                cop_as(cop_max("id"), "cop_max"),
                cop_as(cop_avg("id"), "cop_avg"),
                cop_as(cop_sum("id"), "cop_sum"),
                cop_as(cop_count("char_f"), "cop_count"),
                cop_as(cop_count(cop_distinct("char_f")), "cop_distinct"),
            ),
            "groupby": ("char_f")
        );

        row = table.selectRow (soh, \sql);

        expect = (
            "cop_min": 1,
            "cop_max": 2,
            "cop_avg": 1.5n,
            "cop_sum": 3,
            "cop_count": 2,
            "cop_distinct": 1,
        );

        foreach hash e in (expect.pairIterator())
            assertEq(e.value, row{e.key}, "checking column operator " + e.key);

        # feature #2032: sqlutil: new operator to allow transparent datetime truncation across various DBMS
        # negative args first
        try {
            cop_trunc_date("dt", "foobar");
            assertEq(False, True, "The call above must throw and exception");
        } catch (hash<ExceptionInfo> ex) {
            assertEq("COP-TRUNC-DATE-ERROR", ex.err, "Excaption COP-TRUNC-DATE-ERROR is expected here");
            assertEq(True, ex.desc =~ /Not allowed format argument: "foobar"/, "Expected ex description must be received");
        }

        # real data test - using timestamp (timestamp_f) from driver's test
        hash test_cases = (
            DT_YEAR     : 2016-01-01T00:00:00,
            DT_MONTH    : 2016-02-01T00:00:00,
            DT_DAY      : 2016-02-11T00:00:00,
            DT_HOUR     : 2016-02-11T09:00:00,
            DT_MINUTE   : 2016-02-11T09:26:00,
            DT_SECOND   : 2016-02-11T09:26:14,
        );

        HashIterator it(test_cases);
        while (it.next()) {
            hash sh = (
                    "columns" : cop_as(cop_trunc_date("timestamp_f", it.getKey()), "ret"),
                    "where" : ( "id" : 1),
            );
            date r = table.selectRow(sh, \sql).ret;
            assertEq(it.getValue(), r, sprintf("cop_trunc_date for mask: '%s'", it.getKey()));
        }
        # end of feature #2032

    }

    updateOperatorTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        hash test_set = (
            "uop_prepend": (
                "set": ("null_f": uop_prepend ("123")),
                "out": ("null_f": "123abc"),
                ),
            "uop_append": (
                "set": ("null_f": uop_append ("123")),
                "out": ("null_f": "123abc123"),
                ),
            "uop_upper": (
                "set": ("null_f": uop_upper()),
                "out": ("null_f": "123ABC123"),
                ),
            "uop_lower": (
                "set": ("null_f": uop_lower()),
                "out": ("null_f": "123abc123"),
                ),
            "uop_append(uop_upper)": (
                "set": ("null_f": uop_append ("abc", uop_upper())),
                "out": ("null_f": "123ABC123abc"),
                ),
            "uop_lower(uop_append)": (
                "set": ("null_f": uop_lower (uop_append ("DEF"))),
                "out": ("null_f": "123abc123abcdef"),
                ),
            "uop_substr": (
                "set": ("null_f": uop_substr (4, 6)),
                "out": ("null_f": "abc123"),
                ),
            "uop_plus": (
                "set": ("id_": uop_plus(3)),
                "out": ("id_": 2+3),
                ),
            "uop_minus": (
                "set": ("id_": uop_minus(3)),
                "out": ("id_": 5-3),
                ),
            "uop_multiply": (
                "set": ("id_": uop_multiply(3)),
                "out": ("id_": 2*3),
                ),
            "uop_divide": (
                "set": ("id_": uop_divide(3)),
                "out": ("id_": 6/3),
                ),
        );

        hash<auto> cond = ("id": 1);

        foreach hash<auto> t in (test_set.pairIterator()) {
            table.update(t.value.set, cond, \sql);
            hash row = table.selectRow (("where": cond), \sql);

            foreach hash d in (t.value.out.pairIterator())
                assertEq(d.value, row{d.key}, sprintf ("checking update operator %s column %s", t.key, d.key));
        }

        # reset the row to what it was before this test
        table.update (("null_f": "abc"), cond);
    }

    whereOperatorTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        hash test_set = (
            "op_lt": (
                "in": (
                    "where": ("id": op_lt(2)),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                    ),
                ),
            "op_le": (
                "in": (
                    "where": ("id": op_le(2)),
                    "orderby": ("id",)
                    ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                    ),
                ),
            "op_gt": (
                "in": (
                    "where": ("id": op_gt(1)),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 2),),
                    ),
                ),
            "op_ge": (
                "in": (
                    "where": ("id": op_ge(1)),
                    "orderby": ("id",)
                    ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                    ),
                ),
            "op_eq": (
                "in": (
                    "where": ("id": op_eq(2)),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 2),),
                    ),
                ),
            "op_ne": (
                "in": (
                    "where": ("id": op_ne(1)),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 2),),
                    ),
                ),
            "op_ne_null": (
                "in": (
                    "where": ("null_f": op_ne("abc")),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 2, "null_f": NULL),),
                    ),
                ),
            "op_between": (
                "in": (
                    "where": ("id": op_between(0,1)),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                    ),
                ),
            "op_in": (
                "in": (
                    "where": ("id": op_in((0,1,3))),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                    ),
                ),
            "op_in_empty": (
                "in": (
                    "where": ("id": op_in(list())),
                    ),
                "out": (
                    "count": 0,
                    "data": (),
                    ),
                ),
            "op_in_large": (
                "in": (
                    "where": ("id": op_in(range(32767))), # value 32767 is enough to trigger Oracle's ORA-22165
                    "orderby": ("id",)
                    ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                    ),
                "skip_for": ("FreetdsTest"), # TODO: remove once support is implemented in FreetdsSqlUtil.qm
                ),
            "op_not": (
                "in": (
                    "where": ("id": op_not (op_in((0,1,3)))),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 2),),
                    ),
                ),
            "op_like": (
                "in": (
                    "where": ("char_f": op_like (insert_data[0].char_f + "%")),
                    ),
                "out": (
                    "count": 2,
                    "data": (("char_f": expect_data.char_f), ("char_f": expect_data.char_f)),
                    ),
                ),
            "op_substr_1": (
                "in": (
                    "where": ("char_f": op_substr (2, expect_data.char_f.substr(1))),
                    ),
                "out": (
                    "count": 2,
                    "data": (("char_f": expect_data.char_f), ("char_f": expect_data.char_f)),
                    ),
                ),
            "op_substr_2": (
                "in": (
                    "where": ("char_f": op_substr (1, 4, expect_data.char_f.substr(0,4))),
                    ),
                "out": (
                    "count": 2,
                    "data": (("char_f": expect_data.char_f), ("char_f": expect_data.char_f)),
                    ),
                ),
            "op_clt": (
                "in": (
                    "where": ("id": op_clt("id_")),
                    ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                    ),
                ),
            "op_cle": (
                "in": (
                    "where": ("id": op_cle("id_")),
                    "orderby": ("id",)
                    ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                    ),
                ),
            "op_cgt": (
                "in": (
                    "where": ("id_": op_cgt("id")),
                ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                ),
            ),
            "op_cge": (
                "in": (
                    "where": ("id_": op_cge("id")),
                    "orderby": ("id",)
                ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                ),
            ),
            "op_cne": (
                "in": (
                    "where": ("id": op_cne("id_")),
                ),
                "out": (
                    "count": 1,
                    "data": (("id": 1),),
                ),
            ),
            "op_ceq": (
                "in": (
                    "where": ("id": op_ceq("id_")),
                ),
                "out": (
                    "count": 1,
                    "data": (("id": 2),),
                ),
            ),
            "wop_or": (
                "in": (
                    "where": wop_or (("id": op_eq(1)), ("id": op_eq(2))),
                    "orderby": ("id",)
                ),
                "out": (
                    "count": 2,
                    "data": (("id": 1), ("id": 2)),
                ),
            ),
        );

        foreach hash t in (test_set.pairIterator()) {
            if (inlist(self.className(), t.value.skip_for)) {
                assertSkip (t.value.skip_for + " might fail this test");
                continue;
            }
            *list rows = table.selectRows (t.value.in, \sql);
            hash out = t.value.out;
            assertEq(out.count, rows.size(), "checking where operator " + t.key);

            foreach hash row in (rows) {
                int rn = $#;
                foreach hash d in (out.data[rn].pairIterator())
                    assertEq(d.value, row{d.key}, sprintf("checking where operator %s row %s column %s", t.key,
                        rn, d.key));
            }
        }
    }

    groupByTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        hash soh = (
            "columns": (
                cop_as ("char_f", "pivo"),
                cop_as (cop_count(), "cop_count"),
            ),
            "groupby": (1),
        );
        *hash row = table.selectRow (soh, \sql);
        assertEq (2, row.cop_count, "checking group by 1");

        soh = (
            "columns": (
                cop_as ("char_f", "pivo"),
                cop_as (cop_count(), "cop_count"),
            ),
            "groupby": ("pivo")
        );
        row = table.selectRow (soh, \sql);
        assertEq (2, row.cop_count, "checking group by alias");
    }

    orderByTest() {
        if (!table) testSkip("no DB connection");

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        hash soh = ("columns": ("id",), "orderby": (1,));
        *list rows = table.selectRows (soh, \sql);
        assertEq((("id": 1), ("id": 2)), rows, "checking order by 1");

        soh = ("columns": ("id",), "orderby": ("-id",));
        rows = table.selectRows (soh, \sql);
        assertEq((("id": 2), ("id": 1)), rows, "checking order by id desc");

        soh = ("columns": (cop_as ("id", "alias"),), "orderby": ("alias",));
        rows = table.selectRows (soh, \sql);
        assertEq((("alias": 1), ("alias": 2)), rows, "checking order by alias");
    }

    offsetLimitTest() {
        if (!table) testSkip("no DB connection");

        if (table.getDriverName() == "sybase") {
            testSkip("FreetdsSqlUtil does not support offset with sybase");
        }

        on_success table.commit();
        on_error table.rollback();

        string sql; on_error printf ("SQL: %s\n", sql);

        hash test_set = {
            "case_1": (
                "in": ( "columns": ("id",), "limit": 1 ),
                "out": ( "count": 1 ),
            ),
            "case_2": (
                "in": ( "columns": ("id",), "offset": 1, "limit": 2 ),
                "out": ( "count": 1 ),
            ),
            "case_3": (
                "in": ( "columns": ("id",), "orderby": ("id",), "limit": 1 ),
                "out": ( "count": 1, "data": (("id": 1),) ),
            ),
            "case_4": (
                "in": ( "columns": ("id",), "orderby": ("id",), "limit": 2 ),
                "out": ( "count": 2, "data": (("id": 1), ("id": 2)) ),
            ),
            "case_5": (
                "in": ( "columns": ("id",), "orderby": ("id",), "offset": 1, "limit": 2 ),
                "out": ( "count": 1, "data": (("id": 2),) ),
            ),
            "case_6": ( # triggers bug #749 (GitHub)
                "in": ( "columns": ("id",), "orderby": (1,), "offset": 1, "limit": 2 ),
                "out": ( "count": 1, "data": (("id": 2),) ),
                "skip": True, # TODO: remove this line once the bug is fixed
            ),
        };

        foreach hash t in (test_set.pairIterator()) {
            if (t.value.skip) {
                assertSkip ("checking offset / limit " + t.key);
                continue;
            }
            *list rows = table.selectRows (t.value.in, \sql);
            assertEq(t.value.out.count, rows.size(), "checking offset / limit " + t.key);

            foreach hash row in (rows) {
                int rn = $#;
                foreach hash d in (t.value.out.data[rn].pairIterator())
                    assertEq (d.value, row{d.key}, sprintf ("checking offset / limit %s row %s column %s", t.key, rn, d.key));
            }
        }

        # issue #1880: queries with offset = 0 and no orderby key must be ordered by the table's PK
        sql = table.getSelectSql(("offset": 0, "limit": 1));
        assertEq(True, sql =~ /order by/);
    }

    fetchColumnsTest() {
        if (!table) testSkip("no DB connection");

        hash sh = ("columns": "id", "where": ("id": op_cne("id")));
        SQLStatement stmt = table.getRowIterator(sh);
        assertEq({}, stmt.fetchColumns(10));
        # sanity select test
        assertEq(("id": ()), table.select(sh));
    }

    static string getColumnName(string n) {
        n =~ s/ //g;
        return n + "_f";
    }

    initTestData(hash<auto> custom_columns) {
        hash<auto> row;

        foreach hash<auto> h in (custom_columns.pairIterator()) {
            string cn = getColumnName(h.key);
            row{cn} = h.value.bind ?? h.value.value ?? h.value;

            if (h.value.typeCode() == NT_HASH && h.value.hasKey('expect')) {
                expect_data{cn} = h.value.expect;
            } else {
                expect_data{cn} = h.value.bind.'^value^' ?? h.value.value ?? h.value;
            }
            if (h.value.soft) {
                softmap{cn} = True;
            }
        }
        insert_data = (
            ("id": 1, "id_": 2, "null_f": "abc", "blob_f": <cafe01>, "clob_f": "test1") + row,
            ("id": 2, "id_": 2, "null_f": NULL, "blob_f": <cafe02>, "clob_f": "test2") + row,
        );
        upsert_data = (
            ("id": 2, "id_": 2, "null_f": "abc", "blob_f": <cafe02>, "clob_f": "test2") + row,
            ("id": 3, "id_": 2, "null_f": NULL, "blob_f": <cafe03>, "clob_f": "test3") + row,
        );
    }

    deleteTest() {
        if (!table) testSkip("no DB connection");

        int count = table.del();
        assertEq(insert_data.size(), count, "del()");

        map table.insert($1), insert_data;

        hash<SqlResultInfo> info = table.delWithInfo({});
        count = info.result;
        assertEq(insert_data.size(), count, "del({})");
        assertEq(Type::String, info.sql.type());
        assertNothing(info.args);

        table.del();
        map table.insertWithInfo($1), insert_data;

        count = table.del(("id" : 1));
        assertEq(insert_data.size() - 1, count, "del(('id' : 1))");
        table.del();

        map table.insert($1), insert_data;

        count = table.del(("id" : -1));
        assertEq(0, count, "del(('id' : -1))");
    }

    private abstract string getResultSetSql();

    resultSetPlaceholderTest() {
        if (!table)
            testSkip("no DB connection");

        if (!(dbi_get_driver_capabilities(table.getDriverName()) & DBI_CAP_HAS_RESULTSET_OUTPUT))
            testSkip("does not support result set output binds");

        # test with a Datasource
        Datasource ds = table.getDatasource();
        ds.commit();

        placeholderTest(ds, "DATASOURCE-TRANSACTION-EXCEPTION");

        # repeat tests with a DatasourcePool
        DatasourcePool dsp;
        {
            # create the pool with min = max = 1
            hash ch = ds.getConfigHash();
            ch.options += (
                "min": 1,
                "max": 1,
            );
            dsp = new DatasourcePool(ch);
        }

        placeholderTest(dsp, "DATASOURCEPOOL-LOCK-EXCEPTION");
    }

    private placeholderTest(AbstractDatasource ds, string err) {
        string resultSetSql = getResultSetSql();

        # test capabilities
        assertEq(DBI_CAP_HAS_RESULTSET_OUTPUT, dbi_get_driver_capabilities(ds.getDriverName()) & DBI_CAP_HAS_RESULTSET_OUTPUT);
        assertEq("HasResultsetOutput", (map $1, dbi_get_driver_capability_list(ds.getDriverName()), $1 == "HasResultsetOutput")[0]);

        assertEq(False, ds.currentThreadInTransaction());
        {
            hash h = ds.select(resultSetSql, RESULTSET);
            assertEq(Type::Object, h.rs.type());
            # make sure we got an SQLStatement output variable
            assertEq(True, h.rs instanceof SQLStatement);
            # make sure the transaction lock has been acquired
            assertEq(True, ds.currentThreadInTransaction());
            # make sure the statement is marked active
            assertEq(True, h.rs.active());
            # make sure a thread resource has been acquired
            assertThrows(err, \throw_thread_resource_exceptions());
        }

        {
            on_exit ds.rollback();

            SQLStatement stmt = ds.select(resultSetSql, RESULTSET).rs;
            # make sure there is no output
            assertEq({}, stmt.getOutput());
            list l = stmt.fetchRows();
            # test output of select
            assertEq(2, l.size());
            # verify that no SQL is present for the statement
            assertEq(NOTHING, stmt.getSQL());
            # cannot get output - status = "defined"
            assertThrows("SQLSTATEMENT-ERROR", \stmt.getOutput());
            # cannot execute such a statement again; there is no SQL
            assertThrows("SQLSTATEMENT-ERROR", \stmt.exec());
        }

        {
            on_exit ds.rollback();

            SQLStatement stmt = ds.select(resultSetSql, RESULTSET).rs;
            # check iterator
            int cnt = foldl $1 + $2, (map $1.id.toInt(), stmt);
            assertEq(3, cnt);
            # ensure that statement is active
            assertEq(True, stmt.active());
            # ensure that the statement is registered with the datasource and is closed when the transaction is committed
            ds.commit();
            assertEq(False, stmt.active());
        }
    }

    # analytic/window functions should behave exactly the same across various DB server implementations.
    # That's the reason why is the test here, in the base class, called only from child classes
    # on demand.
    testAnalyticFunctions() {
        # prepare data
        list data = (
                ( "id": 1, "row_type": "type1", "row_value": 10, "cume_dist": 0.1n, "dense_rank": 1, "first_value": 10, "last_value": 10, "ntile": 1, "percent_rank": 0, "rank": 1, "row_number": 1, ),
                ( "id": 2, "row_type": "type1", "row_value": 20, "cume_dist": 0.2n, "dense_rank": 2, "first_value": 10, "last_value": 20, "ntile": 2, "percent_rank": 0.1111111111111111111111111111111111111111n, "rank": 2, "row_number": 2, ),
                ( "id": 3, "row_type": "type1", "row_value": 30, "cume_dist": 0.3n, "dense_rank": 3, "first_value": 10, "last_value": 30, "ntile": 3, "percent_rank": 0.2222222222222222222222222222222222222222n, "rank": 3, "row_number": 3, ),
                ( "id": 4, "row_type": "type1", "row_value": 40,"cume_dist": 0.4n, "dense_rank": 4, "first_value": 10, "last_value": 40, "ntile": 4, "percent_rank": 0.3333333333333333333333333333333333333333n, "rank": 4, "row_number": 4, ),
                ( "id": 5, "row_type": "type1", "row_value": 50, "cume_dist": 0.5n, "dense_rank": 5, "first_value": 10, "last_value": 50, "ntile": 5, "percent_rank": 0.4444444444444444444444444444444444444444n, "rank": 5, "row_number": 5, ),
                ( "id": 6, "row_type": "type1", "row_value": 60, "cume_dist": 0.6n, "dense_rank": 6, "first_value": 10, "last_value": 60, "ntile": 6, "percent_rank": 0.5555555555555555555555555555555555555556n, "rank": 6, "row_number": 6, ),
                ( "id": 7, "row_type": "type1", "row_value": 70, "cume_dist": 0.7n, "dense_rank": 7, "first_value": 10, "last_value": 70, "ntile": 7, "percent_rank": 0.6666666666666666666666666666666666666667n, "rank": 7, "row_number": 7, ),
                ( "id": 8, "row_type": "type1", "row_value": 80, "cume_dist": 0.8n, "dense_rank": 8, "first_value": 10, "last_value": 80, "ntile": 8, "percent_rank": 0.7777777777777777777777777777777777777778n, "rank": 8, "row_number": 8, ),
                ( "id": 9, "row_type": "type1", "row_value": 90, "cume_dist": 0.9n, "dense_rank": 9, "first_value": 10, "last_value": 90, "ntile": 9, "percent_rank": 0.8888888888888888888888888888888888888889n, "rank": 9, "row_number": 9, ),
                ( "id": 10, "row_type": "type1", "row_value": 100, "cume_dist": 1, "dense_rank": 10, "first_value": 10, "last_value": 100, "ntile": 10, "percent_rank": 1,                 "rank": 10, "row_number": 10, ),
                ( "id": 11, "row_type": "type2", "row_value": 10, "cume_dist": 0.05n, "dense_rank": 1, "first_value": 10, "last_value": 10, "ntile": 1, "percent_rank": 0,                 "rank": 1, "row_number": 1, ),
                ( "id": 12, "row_type": "type2", "row_value": 20, "cume_dist": 0.1n, "dense_rank": 2, "first_value": 10, "last_value": 20, "ntile": 1, "percent_rank": 0.0526315789473684210526315789473684210526n, "rank": 2, "row_number": 2, ),
                ( "id": 13, "row_type": "type2", "row_value": 30, "cume_dist": 0.15n, "dense_rank": 3, "first_value": 10, "last_value": 30, "ntile": 2, "percent_rank": 0.1052631578947368421052631578947368421053n, "rank": 3, "row_number": 3, ),
                ( "id": 14, "row_type": "type2", "row_value": 40, "cume_dist": 0.2n, "dense_rank": 4, "first_value": 10, "last_value": 40, "ntile": 2, "percent_rank": 0.1578947368421052631578947368421052631579n, "rank": 4, "row_number": 4, ),
                ( "id": 15, "row_type": "type2", "row_value": 50, "cume_dist": 0.25n, "dense_rank": 5, "first_value": 10, "last_value": 50, "ntile": 3, "percent_rank": 0.2105263157894736842105263157894736842105n, "rank": 5, "row_number": 5, ),
                ( "id": 16, "row_type": "type2", "row_value": 60, "cume_dist": 0.3n, "dense_rank": 6, "first_value": 10, "last_value": 60, "ntile": 3, "percent_rank": 0.2631578947368421052631578947368421052632n, "rank": 6, "row_number": 6, ),
                ( "id": 17, "row_type": "type2", "row_value": 70, "cume_dist": 0.35n, "dense_rank": 7, "first_value": 10, "last_value": 70, "ntile": 4, "percent_rank": 0.3157894736842105263157894736842105263158n, "rank": 7, "row_number": 7, ),
                ( "id": 18, "row_type": "type2", "row_value": 80, "cume_dist": 0.4n, "dense_rank": 8, "first_value": 10, "last_value": 80, "ntile": 4, "percent_rank": 0.3684210526315789473684210526315789473684n, "rank": 8, "row_number": 8, ),
                ( "id": 19, "row_type": "type2", "row_value": 90, "cume_dist": 0.45n, "dense_rank": 9, "first_value": 10, "last_value": 90, "ntile": 5, "percent_rank": 0.4210526315789473684210526315789473684211n, "rank": 9, "row_number": 9, ),
                ( "id": 20, "row_type": "type2", "row_value": 100, "cume_dist": 0.5n, "dense_rank": 10, "first_value": 10, "last_value": 100, "ntile": 5, "percent_rank": 0.4736842105263157894736842105263157894737n, "rank": 10, "row_number": 10, ),
                ( "id": 21, "row_type": "type2", "row_value": 110, "cume_dist": 0.55n, "dense_rank": 11, "first_value": 10, "last_value": 110, "ntile": 6, "percent_rank": 0.5263157894736842105263157894736842105263n, "rank": 11, "row_number": 11, ),
                ( "id": 22, "row_type": "type2", "row_value": 120, "cume_dist": 0.6n, "dense_rank": 12, "first_value": 10, "last_value": 120, "ntile": 6, "percent_rank": 0.5789473684210526315789473684210526315789n, "rank": 12, "row_number": 12, ),
                ( "id": 23, "row_type": "type2", "row_value": 130, "cume_dist": 0.65n, "dense_rank": 13, "first_value": 10, "last_value": 130, "ntile": 7, "percent_rank": 0.6315789473684210526315789473684210526316n, "rank": 13, "row_number": 13, ),
                ( "id": 24, "row_type": "type2", "row_value": 140, "cume_dist": 0.7n, "dense_rank": 14, "first_value": 10, "last_value": 140, "ntile": 7, "percent_rank": 0.6842105263157894736842105263157894736842n, "rank": 14, "row_number": 14, ),
                ( "id": 25, "row_type": "type2", "row_value": 150, "cume_dist": 0.75n, "dense_rank": 15, "first_value": 10, "last_value": 150, "ntile": 8, "percent_rank": 0.7368421052631578947368421052631578947368n, "rank": 15, "row_number": 15, ),
                ( "id": 26, "row_type": "type2", "row_value": 160, "cume_dist": 0.8n, "dense_rank": 16, "first_value": 10, "last_value": 160, "ntile": 8, "percent_rank": 0.7894736842105263157894736842105263157895n, "rank": 16, "row_number": 16, ),
                ( "id": 27, "row_type": "type2", "row_value": 170, "cume_dist": 0.85n, "dense_rank": 17, "first_value": 10, "last_value": 170, "ntile": 9, "percent_rank": 0.8421052631578947368421052631578947368421n, "rank": 17, "row_number": 17, ),
                ( "id": 28, "row_type": "type2", "row_value": 180, "cume_dist": 0.9n, "dense_rank": 18, "first_value": 10, "last_value": 180, "ntile": 9, "percent_rank": 0.8947368421052631578947368421052631578947n, "rank": 18, "row_number": 18, ),
                ( "id": 29, "row_type": "type2", "row_value": 190, "cume_dist": 0.95n, "dense_rank": 19, "first_value": 10, "last_value": 190, "ntile": 10, "percent_rank": 0.9473684210526315789473684210526315789474n, "rank": 19, "row_number": 19, ),
                ( "id": 30, "row_type": "type2", "row_value": 100, "cume_dist": 1, "dense_rank": 20, "first_value": 10, "last_value": 100, "ntile": 10, "percent_rank": 1, "rank": 20, "row_number": 20, ),
            );

        Table t(table.getDatasource(), "test_analytic_functions");

        {
            ListIterator it(data);
            while (it.next()) {
                t.insert(it.getValue().("id", "row_type", "row_value"));
            }
            t.commit();
        }

        # real tests
        hash sh = {
            "columns": (
                "id", "row_type", "row_value",
                cop_as(cop_over(cop_cume_dist(), "row_type", "id"), "cume_dist"),
                cop_as(cop_over(cop_dense_rank(), "row_type", "id"), "dense_rank"),
                cop_as(cop_over(cop_first_value("row_value"), "row_type", "id"), "first_value"),
                cop_as(cop_over(cop_last_value("row_value"), "row_type", "id"), "last_value"),
                cop_as(cop_over(cop_ntile(10), "row_type", "id"), "ntile"),
                cop_as(cop_over(cop_percent_rank(), "row_type", "id"), "percent_rank"),
                cop_as(cop_over(cop_rank(), "row_type", "id"), "rank"),
                cop_as(cop_over(cop_row_number(), "row_type", "id"), "row_number"),
            ),
            "orderby": "id",
        };
        string sql;
        list res = t.selectRows(sh, \sql);

        ListIterator it(res);
        int ix = 0; # teh current list index (id is 'ix + 1')
        while (it.next()) {
            hash line = it.getValue();
            hash ref = data[ix];

            foreach string i in (line.keys()) {
                switch (line{i}.typeCode()) {
                    case NT_FLOAT:
                    case NT_NUMBER:
                        assertNumberEq(ref{i}, line{i}, 0.0000000001, sprintf("Comparing column '%s' for index '%d'", i, ix));
                        break;
                    default:
                        assertEq(ref{i}, line{i}, sprintf("Comparing column '%s' for index '%d'", i, ix));
                        break;
                }
            }

            ix++;
        }

        # 2227: sqlutil: cop_over is broken in statements with join
        # or superquery. partitionby and orderby clauses are not
        # expanded to fully qualified column names
        hash sh2227 = {
            "columns": (
                "row_value",
                cop_as(cop_over(cop_max("row_value"), "row_type"), "max_value"),
            ),
            "join": join_inner("test_analytic_functions", "t1", ("id" : "id")),
        };
        auto res2227 = t.select(sh2227, \sql);
        assertEq(True, res2227.firstValue().size() > 0, "bug 2227 test must return some data");
    }

    string getExpectedDriverName() {
        return table ? table.getDatasource().getDriverRealName() : "";
    }

    test2358SqlutilSchema() {
        if (!table)
            testSkip("no DB connection");

        Bug2358Schema s(table.getDatasource());

        try {
            s.align();
        } catch (hash<ExceptionInfo> ex) {
            if (ex.err == "ALIGN-TABLE-ERROR") {
                assertEq("ALIGN-TABLE-ERROR", ex.err, "exception must be ALIGN-TABLE-ERROR");
                assertEq(True, ex.desc.regex("table '.*' schema definition has to be hash, but it's string"));
            } else if (ex.err == "SEQUENCE-DESCRIPTION-ERROR") {
                assertEq("SEQUENCE-DESCRIPTION-ERROR", ex.err, "exception must be SEQUENCE-DESCRIPTION-ERROR");
                assertEq(True, ex.desc.regex("sequence '.*' schema definition has to be hash, but it's string"));
            } else {
                rethrow;
            }
        }
    } # test2358SqlutilSchema

    testGetPhysicalSize() {
        if (!table) {
            testSkip("no DB connection");
        }

        Database db(table.getDatasource());
        auto ret = db.getPhysicalSize();
        if (m_options.verbose > 2) {
            printf("    DB size: %n\n", ret);
        }
        assertEq(NT_INT, ret.typeCode(), "result must be int");
    }
}

# a wrongly created schema (object descriptions) for test2358SqlutilSchema()
class Bug2358Schema inherits AbstractSchema {
    constructor(AbstractDatasource ds, *string dts, *string its) :  AbstractSchema(ds, dts, its) {
    }
    private string getNameImpl() {
        return "Bug2358Schema";
    }
    private string getVersionImpl() {
        return "1.0";
    }
    private *hash getTablesImpl() {
        return { "foo" : "bar" };
    }
    private *hash getSequencesImpl() {
        return { "s_foo" : "" };
    }
}

class TestAppender inherits LoggerAppenderWithLayout {
    constructor() : LoggerAppenderWithLayout("test", new LoggerLayoutPattern("%d T%t [%p]: %m%n")) {
        open();
    }

    processEventImpl(int type, auto params) {
        switch (type) {
            case EVENT_LOG:
                print(params);
                break;
        }
    }
}
